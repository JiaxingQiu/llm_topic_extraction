.packages = c("dplyr"),   # Include required packages
.options.snow = opts
) %dopar% {
cb <- combinations_at_least_two[[k]]
llm_list <- llm_full_list[cb]
# ---- ensemble score by PCA ----
score_df_pca <- score_df_gpt4o  # Initiation
for (topic in fea_df$fea) {
pca_df <- NULL
for (llm_name in names(llm_list)) {
llm_dfs <- llm_list[[llm_name]]
pca_df_llm <- data.frame(
"score" = llm_dfs$score_df[, topic],
"label" = llm_dfs$label_df[, topic]
)
colnames(pca_df_llm) <- paste0(colnames(pca_df_llm), "_", llm_name)
if (is.null(pca_df)) {
pca_df <- pca_df_llm
} else {
pca_df <- bind_cols(pca_df, pca_df_llm)
}
}
# PCA on this dataframe, with dimension = 2, keep the first dimension
pca_result <- prcomp(pca_df[, startsWith(colnames(pca_df), "score_")], center = TRUE, scale. = TRUE)
pca_df$pca1 <- pca_result$x[, 1]
# Correction for the sign
if (cor(pca_df$pca1, score_df_gpt4o[, topic]) < 0) {
pca_df$pca1 <- -pca_df$pca1
}
score_df_pca[, topic] <- (pca_df$pca1 - min(pca_df$pca1)) / (max(pca_df$pca1) - min(pca_df$pca1))
}
# ---- ensemble agreement label df ----
label_df_list <- list()
for (llm_name in names(llm_list)) {
label_df_list[[llm_name]] <- llm_list[[llm_name]]$label_df
}
agree_ratio <- 0.1
label_df_ls <- get_label_agreed_by_dfs(label_df_list, agree_ratio)
label_df_agreed_union <- merge(label_df_ls$agreed, info_df, by = "sm_id", all.x = TRUE)
label_df_ls <- get_label_agreed_by_dfs(label_df_list, agree_ratio_inter)
label_df_agreed_inter <- merge(label_df_ls$agreed, info_df, by = "sm_id", all.x = TRUE)
# Find thresholds
t_df <- explore_thresholds(
label_df_agreed_union,
score_df_pca,
fea_df,
label_df_agreed_inter
)
# Adjust union label based on threshold
threshold_df <- t_df %>%
group_by(topic) %>%
summarise(threshold = t[which(f1_score == max(f1_score))][1])
threshold_df$fea <- threshold_df$topic
threshold_df <- as.data.frame(threshold_df)
threshold_df <- merge(threshold_df, fea_df, by = "fea")
adjust_label_df <- adjust_label_by_threshold_score(
label_df_agreed_union,
score_df_pca,
threshold_df
)
# ---- Evaluation ----
eval_pca = eval_llm(score_df_pca, label_true, bal)
eval_pca$llms <- paste0(names(llm_list), collapse = "; ")
eval_pca$llm <- paste0("pca_score (",length(cb)," llms)")
eval_agree_u = eval_llm(label_df_agreed_union, label_true, bal)
eval_agree_u$llms <- paste0(names(llm_list), collapse = "; ")
eval_agree_u$llm <- paste0("union_label (",length(cb)," llms)")
eval_agree_i = eval_llm(label_df_agreed_inter, label_true, bal)
eval_agree_i$llms <- paste0(names(llm_list), collapse = "; ")
eval_agree_i$llm <- paste0("inter_label (",length(cb)," llms)")
eval_agree_adj = eval_llm(adjust_label_df, label_true, bal)
eval_agree_adj$llms <- paste0(names(llm_list), collapse = "; ")
eval_agree_adj$llm <- paste0("pca_label (",length(cb)," llms)")
# ---- get improvement from individual evals ----
eval_label_inds <- list()
eval_score_inds <- list()
for(llm_name in names(llm_list)){
eval_label_inds[[llm_name]] <- eval_ind_ls[[llm_name]]$label[,c("topic", c("auprc", "f1_score", "fb_score", "sensitivity", "specificity", "precision"))]
eval_score_inds[[llm_name]] <- eval_ind_ls[[llm_name]]$score[,c("topic", c("auprc", "f1_score", "fb_score", "sensitivity", "specificity", "precision"))]
}
# Reduce the list of data frames by taking the median for specified columns
eval_label_median <- eval_label_inds %>%
purrr::reduce(function(df1, df2) {
# Ensure consistent structure between data frames
combined <- bind_rows(df1, df2)
# Group by all columns except the metrics, if needed
combined %>%
group_by(across(-c(auprc, f1_score, fb_score, sensitivity, specificity, precision))) %>%
summarise(
across(
c(auprc, f1_score, fb_score, sensitivity, specificity, precision),
~ median(., na.rm = TRUE)
),
.groups = "drop"
)
}) %>% as.data.frame()
eval_score_median <- eval_score_inds %>%
purrr::reduce(function(df1, df2) {
# Ensure consistent structure between data frames
combined <- bind_rows(df1, df2)
# Group by all columns except the metrics, if needed
combined %>%
group_by(across(-c(auprc, f1_score, fb_score, sensitivity, specificity, precision))) %>%
summarise(
across(
c(auprc, f1_score, fb_score, sensitivity, specificity, precision),
~ median(., na.rm = TRUE)
),
.groups = "drop"
)
}) %>% as.data.frame()
# get the deviation
eval_pca_delta <- eval_pca
eval_agree_adj_delta <- eval_agree_adj
for(e in c("auprc", "f1_score", "fb_score", "sensitivity", "specificity", "precision")){
eval_pca_delta[,e] <- eval_pca_delta[,e] - eval_score_median[,e]
eval_agree_adj_delta[,e] <- eval_agree_adj_delta[,e] - eval_label_median[,e]
}
# ---- return ----
list(
eval_pca = eval_pca,
eval_pca_delta = eval_pca_delta,
eval_agree_u = eval_agree_u,
eval_agree_i = eval_agree_i,
eval_agree_adj = eval_agree_adj,
eval_agree_adj_delta = eval_agree_adj_delta
)
}
# Close the progress bar and cluster
close(pb)
stopCluster(cl)
# Combine results
eval_pca <- lapply(results, `[[`, "eval_pca")
eval_pca_delta <- lapply(results, `[[`, "eval_pca_delta")
eval_agree_u <- lapply(results, `[[`, "eval_agree_u")
eval_agree_i <- lapply(results, `[[`, "eval_agree_i")
eval_agree_adj <- lapply(results, `[[`, "eval_agree_adj")
eval_agree_adj_delta <- lapply(results, `[[`, "eval_agree_adj_delta")
save(eval_pca, eval_pca_delta, eval_agree_u, eval_agree_i, eval_agree_adj, eval_agree_adj_delta,
file = res_filename)
}else{
load(res_filename)
}
# summary_eval_df <- function(eval_ls){
#   eval_df_sum <- do.call(rbind, eval_ls)
#   eval_df_sum_summary <- eval_df_sum %>%
#     group_by(llm, topic) %>%
#     summarise(
#       across(c("auprc", "f1_score", "fb_score", "sensitivity", "precision", "specificity"), list(
#         median = ~median(., na.rm=T),
#         q25 = ~quantile(., 0.25, na.rm=T),
#         q75 = ~quantile(., 0.75, na.rm=T),
#         min = ~min(., na.rm=T),
#         max = ~max(., na.rm=T)
#       ), .names = "{.col}_{.fn}")
#     ) %>%
#     mutate(across(everything(), ~ ifelse(is.infinite(.), NA, .)))
#   eval_df_sum_final <- data.frame()
#   for(sub in c("_median", "_q25", "_q75", "_min", "_max")){
#     eval_df_sum_sub <- eval_df_sum_summary[,c("llm","topic",colnames(eval_df_sum_summary)[grepl(sub, colnames(eval_df_sum_summary))])]
#     colnames(eval_df_sum_sub) <- gsub(sub,"",colnames(eval_df_sum_sub))
#     eval_df_sum_sub$llm <- paste0(eval_df_sum_sub$llm, sub)
#     eval_df_sum_final <- bind_rows(eval_df_sum_final, eval_df_sum_sub)
#   }
#   eval_df_sum_final <- eval_df_sum_final[,intersect(colnames(eval_df_sum_final), colnames(eval_mini))]
#   return(eval_df_sum_final)
# }
# # ----- 1. pca score -----
# eval_df_pca_final <- summary_eval_df(eval_pca)
# # ----- 2. pca label -----
# eval_df_agree_adj <- summary_eval_df(eval_agree_adj)
# eval_df <- rbind(eval_df_agree_adj[which(grepl("median", eval_df_agree_adj$llm)),],
#                  eval_df_pca_final[which(grepl("median", eval_df_pca_final$llm)),],
#                  eval_mini, eval_mini_s,
#                  eval_llama, eval_llama_s,
#                  eval_qwen, eval_qwen_s,
#                  eval_vicuna13b, eval_vicuna13b_s,
#                  eval_vicuna7b, eval_vicuna7b_s,
#                  eval_mistral, eval_mistral_s)
# eval_df$llm <- gsub("_median", "", eval_df$llm)
# eval_df_q25 <- rbind(eval_df_agree_adj[which(grepl("_q25", eval_df_agree_adj$llm)),],
#                   eval_df_pca_final[which(grepl("_q25", eval_df_pca_final$llm)),])
# eval_df_q25$llm <- gsub("_q25", "", eval_df_q25$llm)
# ---- plot eval ----
color_scale <- c(
# Warm colors (gradient from dark red to orange)
"ensemble (6 llms)" = "#FF4500", # Dark Red
"ensemble (5 llms)" = "#FF6347", # Firebrick
"ensemble (4 llms)" = "#FFA500", # Orange-Red
"ensemble (3 llms)" = "#FEE08B", # Tomato
"ensemble (2 llms)" = "#D9EF8B", # Orange
# Distinct cold colors for individual models
"gpt-4omini" = "pink2",
"llama-8b" = "green3",
"qwen-7b" = "steelblue2",
"mistral-7b" = "green4",
"vicuna-13b" = "lightblue1",
"vicuna-7b" = "purple1"
)
rm_topics <- c("fearcarb")#c("fearfood", "feargain")
eval_df_pca_final <- do.call(rbind, eval_pca)
eval_df_agree_adj <- do.call(rbind, eval_agree_adj)
eval_df <- rbind(eval_df_agree_adj[,intersect(colnames(eval_df_agree_adj), colnames(eval_mini))],
eval_df_pca_final[,intersect(colnames(eval_df_pca_final), colnames(eval_mini))],
eval_mini, eval_mini_s,
eval_llama, eval_llama_s,
eval_qwen, eval_qwen_s,
# eval_vicuna13b, eval_vicuna13b_s,
eval_vicuna7b, eval_vicuna7b_s,
eval_mistral, eval_mistral_s)
plot_evaluation <- function(eval_df, varname = "f1_score"){
if(varname == "auprc"){
eval_df$y <- eval_df[,varname]
eval_df_summary <- eval_df %>%
filter(grepl("_score", as.character(llm))) %>%
group_by(topic, llm) %>%
summarise(
y_median = quantile(y, 1, na.rm = TRUE),#median(y, na.rm = TRUE),
y_low = quantile(y, 0, na.rm = TRUE),
y_q25 = quantile(y, 0.25, na.rm = TRUE),
y_q75 = quantile(y, 0.75, na.rm = TRUE),
y_up = quantile(y, 1, na.rm = TRUE)
)
eval_df_summary$llm <- factor(eval_df_summary$llm,
levels = c("pca_score (6 llms)",
"pca_score (5 llms)",
"pca_score (4 llms)",
"pca_score (3 llms)",
"pca_score (2 llms)",
"gpt4omini_score",
"llama_score",
"qwen_score",
"mistral_score",
"vicuna13b_score",
"vicuna7b_score"))
}else{
eval_df$y <- eval_df[,varname]
eval_df_summary <- eval_df %>%
filter(grepl("_label", as.character(llm))) %>%
group_by(topic, llm) %>%
summarise(
y_median = quantile(y, 1, na.rm = TRUE),#median(y, na.rm = TRUE),
y_low = quantile(y, 0, na.rm = TRUE),
y_q25 = quantile(y, 0.25, na.rm = TRUE),
y_q75 = quantile(y, 0.75, na.rm = TRUE),
y_up = quantile(y, 1, na.rm = TRUE)
)
eval_df_summary$llm <- factor(eval_df_summary$llm,
levels = c("pca_label (6 llms)",
"pca_label (5 llms)",
"pca_label (4 llms)",
"pca_label (3 llms)",
"pca_label (2 llms)",
"gpt4omini_label",
"llama_label",
"qwen_label",
"mistral_label",
"vicuna13b_label",
"vicuna7b_label"))
}
levels(eval_df_summary$llm) <- c("ensemble (6 llms)",
"ensemble (5 llms)",
"ensemble (4 llms)",
"ensemble (3 llms)",
"ensemble (2 llms)",
"gpt-4omini",
"llama-8b",
"qwen-7b",
"mistral-7b",
"vicuna-13b",
"vicuna-7b")
eval_df_summary[which(!grepl("ensemble",eval_df_summary$llm)),c("y_low", "y_q25","y_q75","y_up")] <- NA
# eval_df_summary <- eval_df_summary[which(!eval_df_summary$llm %in% c("ensemble (6 llms)",
#                                                                      "ensemble (2 llms)")),]
p <- ggplot(eval_df_summary, aes(x = as.factor(topic), y = y_median, fill = llm)) +
geom_bar(stat = "identity", position = "dodge") +
geom_errorbar(
# data=eval_df_summary[which(grepl("ensemble",eval_df_summary$llm)),],
aes(ymin = y_low, ymax = y_up),
position = position_dodge(width = 0.9),
width = 0.3,
linewidth = 0.2
) +
geom_errorbar(
aes(ymin = y_q25, ymax = y_q75),
position = position_dodge(width = 0.9),
width = 0.7,
linewidth = 0.5
) +
theme_minimal() + scale_fill_manual(values = color_scale) +
theme(
axis.text.x = element_text(angle = 35, hjust = 1, size = 8, margin = margin(t = -5)),
legend.key.size = unit(0.5, "cm"),
legend.text = element_text(size = 8)
) +
labs(x = NULL, y = varname)
return(p)
}
eval_df  <- eval_df[which(!eval_df$topic%in%rm_topics),]
p1 <- plot_evaluation(eval_df, "f1_score")
p2 <- plot_evaluation(eval_df, "precision")
p3 <- plot_evaluation(eval_df, "sensitivity")
p4 <- plot_evaluation(eval_df, "auprc")+ ylab("auprc (by score)")
p_eval <- ggarrange(p4, p1,p2,p3, ncol=1, common.legend = T, legend = "right")
p_eval <- annotate_figure(
p_eval,
top = text_grob("Performance Evaluation", size = 12, face = "bold", hjust=0, x=0)
)
# ggarrange(ggarrange(p1,p2,p3, ncol=1, common.legend = T, legend = "right"),
#           p4,
#           ncol=1, common.legend = F,
#           heights = c(3,1))
# ---- plot improvement ----
plot_improve <- function(eval_df_delta, ename = "f1_score"){
eval_df_delta <- as.data.frame(eval_df_delta)
eval_df_delta$yy <- eval_df_delta[,ename]
if(any(grepl("_score", eval_df_delta$llm))){
eval_df_delta$llm <- factor(eval_df_delta$llm,
levels = c("pca_score (6 llms)",
"pca_score (5 llms)",
"pca_score (4 llms)",
"pca_score (3 llms)",
"pca_score (2 llms)"))
}else{
eval_df_delta$llm <- factor(eval_df_delta$llm,
levels = c("pca_label (6 llms)",
"pca_label (5 llms)",
"pca_label (4 llms)",
"pca_label (3 llms)",
"pca_label (2 llms)"))
}
levels(eval_df_delta$llm) <- c("ensemble (6 llms)",
"ensemble (5 llms)",
"ensemble (4 llms)",
"ensemble (3 llms)",
"ensemble (2 llms)")
# eval_df_delta <- eval_df_delta[which(!eval_df_delta$llm %in% c("ensemble (6 llms)",
#                                                                "ensemble (2 llms)")),]
p <- ggplot(eval_df_delta, aes(x=as.factor(topic), y = yy, fill = llm)) + #
geom_boxplot(alpha = 0.3, size = 0.5, aes(color = llm)) +
geom_hline(aes(yintercept=0), color="darkgrey")+
theme_minimal() +
theme(
axis.text.x = element_text(angle = 35, hjust = 1, size = 8, margin = margin(t = -5)),
legend.key.size = unit(0.5, "cm"),
legend.text = element_text(size = 8)
) + scale_fill_manual(values = color_scale) + scale_color_manual(values = color_scale) +
labs(x = NULL, y = ename)
return(p)
}
eval_df_pca_delta <- do.call(rbind, eval_pca_delta)
eval_df_agree_adj_delta <- do.call(rbind, eval_agree_adj_delta)
eval_df_pca_delta  <- eval_df_pca_delta[which(!eval_df_pca_delta$topic%in%rm_topics),]
eval_df_agree_adj_delta  <- eval_df_agree_adj_delta[which(!eval_df_agree_adj_delta$topic%in%rm_topics),]
p1 <- plot_improve(eval_df_pca_delta, "auprc") + ylab("auprc (by score)")
p2 <- plot_improve(eval_df_agree_adj_delta, "f1_score")
p3 <- plot_improve(eval_df_agree_adj_delta, "precision")
p4 <- plot_improve(eval_df_agree_adj_delta, "sensitivity")
p_improve <- ggarrange(p1, p2, p3, p4, ncol=1, common.legend = T, legend = "right")
# add text "Performance Increase" on the top of p_improve
p_improve <- annotate_figure(
p_improve,
top = text_grob("Performance Increase", size = 12, face = "bold", hjust=0, x=0)
)
ggarrange(p_eval, p_improve, nrow=1) %>% ggsave(filename = paste0("./res/",true_set,"_evaluation.png"), width = 14, height = 7, bg="white")
setwd("/Users/joyqiu/Documents/Documents JoyQiu Work/Research/LLMTopicExtraction/llm_topic_extraction")
# example: 104a474
rm(list=ls())
library(dplyr)
library(parallel)
path = paste0("./scripts/data_eng/utils")
flst = list.files(path)
sapply(c(paste(path,flst,sep="/")), source, .GlobalEnv)
fea_df <- read.csv("./data2/fea_df.csv")
# ------ 1. llama 8b -------
if(!file.exists("./data2/results_llama.csv")){
answer_df <- read.csv("./data2/answer_df_llama.csv", stringsAsFactors = F)
answer_df$pat_id <- answer_df$sm_id
answer_df$sm_id <- 1:nrow(answer_df)
answer_df <- answer_df[,c("sm_id", "text_w_eos", "answer_string")]
labeled_df <- get_result_df(answer_df, fea_df$fea)
write.csv(labeled_df, "./data2/results_llama.csv", row.names = F)
}else{
labeled_df_llama8b <- read.csv("./data2/results_llama.csv", stringsAsFactors = F)
}
setwd("/Users/joyqiu/Documents/Documents JoyQiu Work/Research/LLMTopicExtraction/llm_topic_extraction")
# example: 104a474
rm(list=ls())
library(dplyr)
library(parallel)
path = paste0("./scripts/data_eng/utils")
flst = list.files(path)
sapply(c(paste(path,flst,sep="/")), source, .GlobalEnv)
fea_df <- read.csv("./data2/fea_df.csv")
# ------ 1. llama 8b -------
if(!file.exists("./data2/results_llama.csv")){
answer_df <- read.csv("./data2/answer_df_llama.csv", stringsAsFactors = F)
answer_df$pat_id <- answer_df$sm_id
answer_df$sm_id <- 1:nrow(answer_df)
answer_df <- answer_df[,c("sm_id", "text_w_eos", "answer_string")]
labeled_df <- get_result_df(answer_df, fea_df$fea)
write.csv(labeled_df, "./data2/results_llama.csv", row.names = F)
}else{
labeled_df_llama8b <- read.csv("./data2/results_llama.csv", stringsAsFactors = F)
}
# ------ 2. Qwen --------
if(!file.exists("./data2/results_qwen.csv")){
answer_df <- read.csv("./data2/answer_df_qwen.csv", stringsAsFactors = F)
answer_df$pat_id <- answer_df$sm_id
answer_df$sm_id <- 1:nrow(answer_df)
answer_df <- answer_df[,c("sm_id", "text_w_eos", "answer_string")]
labeled_df <- get_result_df(answer_df, fea_df$fea)
write.csv(labeled_df, "./data2/results_qwen.csv", row.names = F)
}else{
labeled_df_qwen <- read.csv("./data2/results_qwen.csv", stringsAsFactors = F)
}
# ------ 3. Vicuna7b --------
if(!file.exists("./data2/results_vicuna.csv")){
answer_df <- read.csv("./data2/answer_df_vicuna.csv", stringsAsFactors = F)
answer_df$pat_id <- answer_df$sm_id
answer_df$sm_id <- 1:nrow(answer_df)
answer_df <- answer_df[,c("sm_id", "text_w_eos", "answer_string")]
labeled_df <- get_result_df(answer_df, fea_df$fea)
write.csv(labeled_df, "./data2/results_vicuna.csv", row.names = F)
}else{
labeled_df_vicuna7b <- read.csv("./data2/results_vicuna.csv", stringsAsFactors = F)
}
# ------ 4. mistral7b --------
if(!file.exists("./data2/results_mistral.csv")){
answer_df <- read.csv("./data2/answer_df_mistral.csv", stringsAsFactors = F)
answer_df$pat_id <- answer_df$sm_id
answer_df$sm_id <- 1:nrow(answer_df)
answer_df <- answer_df[,c("sm_id", "text_w_eos", "answer_string")]
labeled_df <- get_result_df(answer_df, fea_df$fea)
write.csv(labeled_df, "./data2/results_mistral.csv", row.names = F)
}else{
labeled_df_mistral <- read.csv("./data2/results_mistral.csv", stringsAsFactors = F)
}
# ------ viz distribution ------
labeled_df_llama8b[is.na(labeled_df_llama8b)] <- 0
setwd("/Users/joyqiu/Documents/Documents JoyQiu Work/Research/LLMTopicExtraction/llm_topic_extraction")
# example: 104a474
rm(list=ls())
library(dplyr)
library(parallel)
path = paste0("./scripts/data_eng/utils")
flst = list.files(path)
sapply(c(paste(path,flst,sep="/")), source, .GlobalEnv)
fea_df <- read.csv("./data2/fea_df.csv")
# ------ 1. llama 8b -------
if(!file.exists("./data2/results_llama.csv")){
answer_df <- read.csv("./data2/answer_df_llama.csv", stringsAsFactors = F)
answer_df$pat_id <- answer_df$sm_id
answer_df$sm_id <- 1:nrow(answer_df)
answer_df <- answer_df[,c("sm_id", "text_w_eos", "answer_string")]
labeled_df <- get_result_df(answer_df, fea_df$fea)
write.csv(labeled_df, "./data2/results_llama.csv", row.names = F)
}else{
labeled_df_llama8b <- read.csv("./data2/results_llama.csv", stringsAsFactors = F)
}
# ------ 2. Qwen --------
if(!file.exists("./data2/results_qwen.csv")){
answer_df <- read.csv("./data2/answer_df_qwen.csv", stringsAsFactors = F)
answer_df$pat_id <- answer_df$sm_id
answer_df$sm_id <- 1:nrow(answer_df)
answer_df <- answer_df[,c("sm_id", "text_w_eos", "answer_string")]
labeled_df <- get_result_df(answer_df, fea_df$fea)
write.csv(labeled_df, "./data2/results_qwen.csv", row.names = F)
}else{
labeled_df_qwen <- read.csv("./data2/results_qwen.csv", stringsAsFactors = F)
}
# ------ 3. Vicuna7b --------
if(!file.exists("./data2/results_vicuna.csv")){
answer_df <- read.csv("./data2/answer_df_vicuna.csv", stringsAsFactors = F)
answer_df$pat_id <- answer_df$sm_id
answer_df$sm_id <- 1:nrow(answer_df)
answer_df <- answer_df[,c("sm_id", "text_w_eos", "answer_string")]
labeled_df <- get_result_df(answer_df, fea_df$fea)
write.csv(labeled_df, "./data2/results_vicuna.csv", row.names = F)
}else{
labeled_df_vicuna7b <- read.csv("./data2/results_vicuna.csv", stringsAsFactors = F)
}
# ------ 4. mistral7b --------
if(!file.exists("./data2/results_mistral.csv")){
answer_df <- read.csv("./data2/answer_df_mistral.csv", stringsAsFactors = F)
answer_df$pat_id <- answer_df$sm_id
answer_df$sm_id <- 1:nrow(answer_df)
answer_df <- answer_df[,c("sm_id", "text_w_eos", "answer_string")]
labeled_df <- get_result_df(answer_df, fea_df$fea)
write.csv(labeled_df, "./data2/results_mistral.csv", row.names = F)
}else{
labeled_df_mistral <- read.csv("./data2/results_mistral.csv", stringsAsFactors = F)
}
# ------ viz distribution ------
labeled_df_llama8b[is.na(labeled_df_llama8b)] <- 0
labeled_df_llama8b$stigma <- ifelse(rowSums(labeled_df_llama8b[,fea_df$fea])>0,1,0)
labeled_df_qwen[is.na(labeled_df_qwen)] <- 0
labeled_df_qwen$stigma <- ifelse(rowSums(labeled_df_qwen[,fea_df$fea])>0,1,0)
labeled_df_vicuna7b[is.na(labeled_df_vicuna7b)] <- 0
labeled_df_vicuna7b$stigma <- ifelse(rowSums(labeled_df_vicuna7b[,fea_df$fea])>0,1,0)
labeled_df_mistral[is.na(labeled_df_mistral)] <- 0
labeled_df_mistral$stigma <- ifelse(rowSums(labeled_df_mistral[,fea_df$fea])>0,1,0)
topic_distribution_df <- data.frame()
for(topic in c("stigma",fea_df$fea) ){
topic_sum <- data.frame(topic = topic,
llama = mean(labeled_df_llama8b[,topic]),
qwen = mean(labeled_df_qwen[,topic]),
vicuna = mean(labeled_df_vicuna7b[,topic]),
mistral = mean(labeled_df_mistral[,topic]) )
topic_distribution_df <- bind_rows(topic_distribution_df, topic_sum)
}
topic_distribution_df
