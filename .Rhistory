label_df_llama8b_new <- label_df_llama8b
label_df_gpt4omini_new <- label_df_gpt4omini
for(topic in fea_df$fea){
llms_df <- data.frame(llm1 = label_df_llama8b[[topic]],
llm2 = label_df_gpt4omini[[topic]] )
llms_df$llm_inter <- ifelse(rowSums(llms_df)==ncol(llms_df),1,0)
adjs_df <- data.frame(llm1_score = score_df_llama8b[[topic]],
llm2_score = score_df_gpt4omini[[topic]] )
table(llms_df[,c("llm1", "llm2")])
for(i in 1:3){
mdl_df <- cbind(llms_df, adjs_df)
opt_cut1 <- pr_opt(mdl_df, score_col = "llm1_score")
print(opt_cut1)
opt_cut2 <- pr_opt(mdl_df, score_col = "llm2_score")
print(opt_cut2)
# llms_df$llm1 <- ifelse(adjs_df$llm1_score>=opt_cut1|llms_df$llm_inter==1, 1, 0) #
# llms_df$llm2 <- ifelse(adjs_df$llm2_score>=opt_cut2|llms_df$llm_inter==1, 1, 0)
llms_df$llm1 <- ifelse(adjs_df$llm1_score<opt_cut1 & llms_df$llm_inter==0, 0, 1) #
llms_df$llm2 <- ifelse(adjs_df$llm2_score<opt_cut2 & llms_df$llm_inter==0, 0, 1) #
adjs_df$llm1_score <- ifelse(adjs_df$llm1_score>=opt_cut1|llms_df$llm_inter==1, adjs_df$llm1_score, 0) #
adjs_df$llm2_score <- ifelse(adjs_df$llm2_score>=opt_cut2|llms_df$llm_inter==1, adjs_df$llm2_score, 0)
llms_df$llm_inter <- ifelse(rowSums(llms_df)==ncol(llms_df),1,0)
print(table(llms_df[,c("llm1", "llm2")]))
}
label_df_llama8b_new[[topic]] <- llms_df$llm1
label_df_gpt4omini_new[[topic]] <- llms_df$llm2
}
# sanity check
plot_distribution <- function(type = "raw"){
# Load necessary libraries
library(ggplot2)
library(tidyr)
library(dplyr)
library(pheatmap)
if(type == "raw"){
label_df_llm1 <- label_df_gpt4omini
label_df_llm2 <- label_df_llama8b
}else{
label_df_llm1 <- label_df_gpt4omini_new
label_df_llm2 <- label_df_llama8b_new
}
distribution_gpt4omini <- label_df_llm1 %>%
group_by(group) %>%
summarise(across(all_of(c(fea_df$fea)), ~ mean(.x, na.rm = TRUE)))
distribution_llama8b <- label_df_llm2 %>%
group_by(group) %>%
summarise(across(all_of(c(fea_df$fea)), ~ mean(.x, na.rm = TRUE)))
tmp1 <- distribution_gpt4omini
tmp2 <- distribution_llama8b
mat1 <- as.matrix(tmp1[, -1])
rownames(mat1) <- tmp1$group
pheatmap(mat1,  # Remove the group column, if it's the first column
cluster_rows = FALSE,
cluster_cols = FALSE,
legend_breaks = seq(-1,1,0.1),
main = "Occurrence rates by GPT 4o-mini")
mat2 <- as.matrix(tmp2[, -1])
rownames(mat2) <- tmp2$group
pheatmap(mat2,  # Remove the group column, if it's the first column
cluster_rows = F,
cluster_cols = F,
legend_breaks = seq(-1,1,0.1),
main = "Occurrence rates by Llama 8b-instruct (need a second run)")
tmp1 <- distribution_gpt4omini %>% mutate(model = "GPT-4o-mini")
tmp2 <- distribution_llama8b %>% mutate(model = "Llama 8b-instruct")
combined_data <- bind_rows(tmp1, tmp2)
long_data <- combined_data  %>%
pivot_longer(cols = -c(group, model), names_to = "category", values_to = "occurrence_rate")
print(ggplot(long_data, aes(x = group, y = occurrence_rate, fill = model)) +
geom_bar(stat = "identity", position = "dodge") +
facet_wrap(~category,ncol=4, scales = "free_x") +
labs(y = "Occurrence Rate",
title = type) +
theme_minimal() +
scale_fill_manual(values = c("GPT-4o-mini" = "skyblue", "Llama 8b-instruct" = "coral")) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "top"))
}
setwd("/Users/joyqiu/Documents/Documents JoyQiu Work/Research/LLMTopicExtraction/llm_topic_extraction")
rm(list = ls())
source("./scripts/data_eng/func_x_transform.R")
library(pROC)
library(PRROC)
library(dplyr)
library(ggplot2)
library(pheatmap)
get_score_df <- function(folder, mdl_name = "stella_en_400M_v5"){
labeled_df <- read.csv(paste0("./",folder,"/results_with_cos_",mdl_name,".csv"))
labeled_df <- labeled_df[,setdiff(colnames(labeled_df), "X")]
labeled_df <- labeled_df %>% arrange(sm_id)
scores_df <- readRDS(paste0("./",folder,"/cos_score_",mdl_name,".RDS"))
scores_df <- scores_df %>% arrange(sm_id)
for(topic in fea_df$fea){
# shift a cutoff at 0, then zero out <0
cutoff <- quantile(scores_df[[topic]][which(scores_df[[topic]]>0)],0)
a0 <- which(scores_df[[topic]]>=cutoff)
be0 <- which(scores_df[[topic]]<=cutoff)
print(min(scores_df[[topic]][a0],na.rm=T))
scores_df[[topic]][a0] <- (scores_df[[topic]][a0] - min(scores_df[[topic]][a0],na.rm=T) ) / (max(scores_df[[topic]][a0],na.rm=T) - min(scores_df[[topic]][a0],na.rm=T))
scores_df[[topic]][be0] <- 0
scores_df[[topic]] <- scores_df[[topic]]*labeled_df[[topic]]
}
text_df <- read.csv("/Users/joyqiu/Documents/Documents JoyQiu Work/Research/ED Media/network/script/llm/sm_eos.csv", stringsAsFactors = FALSE)
info_df <- text_df %>% select(sm_id, group, sr_name, url)
scores_df <- merge(scores_df, info_df)%>% arrange(sm_id)
labeled_df <- merge(labeled_df, info_df)%>% arrange(sm_id)
return(list(labeled_df = labeled_df,
scores_df = scores_df ))
}
pr_opt <- function(mdl_df, score_col = "llm1_score"){
mdl_df$x <- mdl_df[[score_col]]
mdl_score <- glm(llm_inter ~ x, data=mdl_df, family = binomial(link = "logit"))
y_prob <- predict(mdl_score, type = "response")
# find an optimal cutoff of x using the precision recall curve, you can use the point on the precision-recall curve that maximizes the F1 score (the harmonic mean of precision and recall), or you can identify a cutoff based on a specific precision or recall requirement.
# Calculate precision-recall curve
pr_curve <- pr.curve(scores.class0 = y_prob, weights.class0 = mdl_df$llm_inter == 1, curve = TRUE)
precision <- pr_curve$curve[, 2]  # Precision values
recall <- pr_curve$curve[, 1]     # Recall values
cutoffs <- pr_curve$curve[, 3]    # Cutoff values
# Calculate F1 scores and find optimal cutoff
f1_scores <- 2 * (precision * recall) / (precision + recall)  # Calculate F1 scores
optimal_index <- which.max(f1_scores)  # Find index of maximum F1 score
optimal_cutoff <- cutoffs[optimal_index]  # Get the optimal cutoff value
# Prepare data for plotting
pr_data <- data.frame(Recall = recall, Precision = precision, Cutoff = cutoffs)
# Plot the precision-recall curve with the optimal cutoff point
p <- ggplot(pr_data, aes(x = Recall, y = Precision)) +
geom_line(color = "blue") +
geom_point(aes(x = recall[optimal_index], y = precision[optimal_index]),
color = "red", size = 3, shape = 8) +  # Mark optimal cutoff point
geom_text(aes(x = recall[optimal_index], y = precision[optimal_index],
label = paste("F1:", round(f1_scores[optimal_index], 4)) #paste("Optimal Cutoff:", round(optimal_cutoff, 4))
),
hjust = 0.5, vjust = -0.5, color = "red") +
labs(title = paste0("Precision-Recall Curve (", pr_curve$auc.integral,")"), x = "Recall", y = "Precision") +
theme_minimal()
print(p)
return(optimal_cutoff)
}
mdl_name = "stella_en_1.5B_v5"
# mdl_name = "stella_en_400M_v5"
# mdl_name = "all-mpnet-base-v2"
fea_df <- read.csv("./data/fea_df.csv")
# fea_df <- fea_df[which(!fea_df$fea%in%c("nosocialeat", "thinspo", "fearcarb")),]
obj <- get_score_df("gpt_data", mdl_name)
label_df_gpt4omini <- obj$labeled_df
label_df_gpt4omini[is.na(label_df_gpt4omini)] <- 0
score_df_gpt4omini <- obj$scores_df
score_df_gpt4omini[is.na(score_df_gpt4omini)] <- 0
obj <- get_score_df("llama_data", mdl_name)
label_df_llama8b <- obj$labeled_df
label_df_llama8b[is.na(label_df_llama8b)] <- 0
score_df_llama8b <- obj$scores_df
score_df_llama8b[is.na(score_df_llama8b)] <- 0
# find the intersect ture positive tables
label_df_llama8b_new <- label_df_llama8b
label_df_gpt4omini_new <- label_df_gpt4omini
for(topic in fea_df$fea){
llms_df <- data.frame(llm1 = label_df_llama8b[[topic]],
llm2 = label_df_gpt4omini[[topic]] )
llms_df$llm_inter <- ifelse(rowSums(llms_df)==ncol(llms_df),1,0)
adjs_df <- data.frame(llm1_score = score_df_llama8b[[topic]],
llm2_score = score_df_gpt4omini[[topic]] )
table(llms_df[,c("llm1", "llm2")])
for(i in 1:3){
mdl_df <- cbind(llms_df, adjs_df)
opt_cut1 <- pr_opt(mdl_df, score_col = "llm1_score")
print(opt_cut1)
opt_cut2 <- pr_opt(mdl_df, score_col = "llm2_score")
print(opt_cut2)
llms_df$llm1 <- ifelse(adjs_df$llm1_score>=opt_cut1|llms_df$llm_inter==1, 1, 0) #
llms_df$llm2 <- ifelse(adjs_df$llm2_score>=opt_cut2|llms_df$llm_inter==1, 1, 0)
# llms_df$llm1 <- ifelse(adjs_df$llm1_score<opt_cut1 & llms_df$llm_inter==0, 0, 1) #
# llms_df$llm2 <- ifelse(adjs_df$llm2_score<opt_cut2 & llms_df$llm_inter==0, 0, 1) #
adjs_df$llm1_score <- ifelse(adjs_df$llm1_score>=opt_cut1|llms_df$llm_inter==1, adjs_df$llm1_score, 0) #
adjs_df$llm2_score <- ifelse(adjs_df$llm2_score>=opt_cut2|llms_df$llm_inter==1, adjs_df$llm2_score, 0)
llms_df$llm_inter <- ifelse(rowSums(llms_df)==ncol(llms_df),1,0)
print(table(llms_df[,c("llm1", "llm2")]))
}
label_df_llama8b_new[[topic]] <- llms_df$llm1
label_df_gpt4omini_new[[topic]] <- llms_df$llm2
}
# sanity check
plot_distribution <- function(type = "raw"){
# Load necessary libraries
library(ggplot2)
library(tidyr)
library(dplyr)
library(pheatmap)
if(type == "raw"){
label_df_llm1 <- label_df_gpt4omini
label_df_llm2 <- label_df_llama8b
}else{
label_df_llm1 <- label_df_gpt4omini_new
label_df_llm2 <- label_df_llama8b_new
}
distribution_gpt4omini <- label_df_llm1 %>%
group_by(group) %>%
summarise(across(all_of(c(fea_df$fea)), ~ mean(.x, na.rm = TRUE)))
distribution_llama8b <- label_df_llm2 %>%
group_by(group) %>%
summarise(across(all_of(c(fea_df$fea)), ~ mean(.x, na.rm = TRUE)))
tmp1 <- distribution_gpt4omini
tmp2 <- distribution_llama8b
mat1 <- as.matrix(tmp1[, -1])
rownames(mat1) <- tmp1$group
pheatmap(mat1,  # Remove the group column, if it's the first column
cluster_rows = FALSE,
cluster_cols = FALSE,
legend_breaks = seq(-1,1,0.1),
main = "Occurrence rates by GPT 4o-mini")
mat2 <- as.matrix(tmp2[, -1])
rownames(mat2) <- tmp2$group
pheatmap(mat2,  # Remove the group column, if it's the first column
cluster_rows = F,
cluster_cols = F,
legend_breaks = seq(-1,1,0.1),
main = "Occurrence rates by Llama 8b-instruct (need a second run)")
tmp1 <- distribution_gpt4omini %>% mutate(model = "GPT-4o-mini")
tmp2 <- distribution_llama8b %>% mutate(model = "Llama 8b-instruct")
combined_data <- bind_rows(tmp1, tmp2)
long_data <- combined_data  %>%
pivot_longer(cols = -c(group, model), names_to = "category", values_to = "occurrence_rate")
print(ggplot(long_data, aes(x = group, y = occurrence_rate, fill = model)) +
geom_bar(stat = "identity", position = "dodge") +
facet_wrap(~category,ncol=4, scales = "free_x") +
labs(y = "Occurrence Rate",
title = type) +
theme_minimal() +
scale_fill_manual(values = c("GPT-4o-mini" = "skyblue", "Llama 8b-instruct" = "coral")) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "top"))
}
setwd("/Users/joyqiu/Documents/Documents JoyQiu Work/Research/LLMTopicExtraction/llm_topic_extraction")
rm(list = ls())
source("./scripts/data_eng/func_x_transform.R")
library(pROC)
library(PRROC)
library(dplyr)
library(ggplot2)
library(pheatmap)
get_score_df <- function(folder, mdl_name = "stella_en_400M_v5"){
labeled_df <- read.csv(paste0("./",folder,"/results_with_cos_",mdl_name,".csv"))
labeled_df <- labeled_df[,setdiff(colnames(labeled_df), "X")]
labeled_df <- labeled_df %>% arrange(sm_id)
scores_df <- readRDS(paste0("./",folder,"/cos_score_",mdl_name,".RDS"))
scores_df <- scores_df %>% arrange(sm_id)
for(topic in fea_df$fea){
# shift a cutoff at 0, then zero out <0
cutoff <- quantile(scores_df[[topic]][which(scores_df[[topic]]>0)],0)
a0 <- which(scores_df[[topic]]>=cutoff)
be0 <- which(scores_df[[topic]]<=cutoff)
print(min(scores_df[[topic]][a0],na.rm=T))
scores_df[[topic]][a0] <- (scores_df[[topic]][a0] - min(scores_df[[topic]][a0],na.rm=T) ) / (max(scores_df[[topic]][a0],na.rm=T) - min(scores_df[[topic]][a0],na.rm=T))
scores_df[[topic]][be0] <- 0
scores_df[[topic]] <- scores_df[[topic]]*labeled_df[[topic]]
}
text_df <- read.csv("/Users/joyqiu/Documents/Documents JoyQiu Work/Research/ED Media/network/script/llm/sm_eos.csv", stringsAsFactors = FALSE)
info_df <- text_df %>% select(sm_id, group, sr_name, url)
scores_df <- merge(scores_df, info_df)%>% arrange(sm_id)
labeled_df <- merge(labeled_df, info_df)%>% arrange(sm_id)
return(list(labeled_df = labeled_df,
scores_df = scores_df ))
}
pr_opt <- function(mdl_df, score_col = "llm1_score"){
mdl_df$x <- mdl_df[[score_col]]
mdl_score <- glm(llm_inter ~ x, data=mdl_df, family = binomial(link = "logit"))
y_prob <- predict(mdl_score, type = "response")
# find an optimal cutoff of x using the precision recall curve, you can use the point on the precision-recall curve that maximizes the F1 score (the harmonic mean of precision and recall), or you can identify a cutoff based on a specific precision or recall requirement.
# Calculate precision-recall curve
pr_curve <- pr.curve(scores.class0 = y_prob, weights.class0 = mdl_df$llm_inter == 1, curve = TRUE)
precision <- pr_curve$curve[, 2]  # Precision values
recall <- pr_curve$curve[, 1]     # Recall values
cutoffs <- pr_curve$curve[, 3]    # Cutoff values
# Calculate F1 scores and find optimal cutoff
f1_scores <- 2 * (precision * recall) / (precision + recall)  # Calculate F1 scores
optimal_index <- which.max(f1_scores)  # Find index of maximum F1 score
optimal_cutoff <- cutoffs[optimal_index]  # Get the optimal cutoff value
# Prepare data for plotting
pr_data <- data.frame(Recall = recall, Precision = precision, Cutoff = cutoffs)
# Plot the precision-recall curve with the optimal cutoff point
p <- ggplot(pr_data, aes(x = Recall, y = Precision)) +
geom_line(color = "blue") +
geom_point(aes(x = recall[optimal_index], y = precision[optimal_index]),
color = "red", size = 3, shape = 8) +  # Mark optimal cutoff point
geom_text(aes(x = recall[optimal_index], y = precision[optimal_index],
label = paste("F1:", round(f1_scores[optimal_index], 4)) #paste("Optimal Cutoff:", round(optimal_cutoff, 4))
),
hjust = 0.5, vjust = -0.5, color = "red") +
labs(title = paste0("Precision-Recall Curve (", pr_curve$auc.integral,")"), x = "Recall", y = "Precision") +
theme_minimal()
print(p)
return(optimal_cutoff)
}
mdl_name = "stella_en_1.5B_v5"
# mdl_name = "stella_en_400M_v5"
# mdl_name = "all-mpnet-base-v2"
fea_df <- read.csv("./data/fea_df.csv")
# fea_df <- fea_df[which(!fea_df$fea%in%c("nosocialeat", "thinspo", "fearcarb")),]
obj <- get_score_df("gpt_data", mdl_name)
label_df_gpt4omini <- obj$labeled_df
label_df_gpt4omini[is.na(label_df_gpt4omini)] <- 0
score_df_gpt4omini <- obj$scores_df
score_df_gpt4omini[is.na(score_df_gpt4omini)] <- 0
obj <- get_score_df("llama_data", mdl_name)
label_df_llama8b <- obj$labeled_df
label_df_llama8b[is.na(label_df_llama8b)] <- 0
score_df_llama8b <- obj$scores_df
score_df_llama8b[is.na(score_df_llama8b)] <- 0
# find the intersect ture positive tables
label_df_llama8b_new <- label_df_llama8b
label_df_gpt4omini_new <- label_df_gpt4omini
for(topic in fea_df$fea){
llms_df <- data.frame(llm1 = label_df_llama8b[[topic]],
llm2 = label_df_gpt4omini[[topic]] )
llms_df$llm_inter <- ifelse(rowSums(llms_df)==ncol(llms_df),1,0)
adjs_df <- data.frame(llm1_score = score_df_llama8b[[topic]],
llm2_score = score_df_gpt4omini[[topic]] )
table(llms_df[,c("llm1", "llm2")])
for(i in 1:3){
mdl_df <- cbind(llms_df, adjs_df)
opt_cut1 <- pr_opt(mdl_df, score_col = "llm1_score")
print(opt_cut1)
opt_cut2 <- pr_opt(mdl_df, score_col = "llm2_score")
print(opt_cut2)
llms_df$llm1 <- ifelse(adjs_df$llm1_score>=opt_cut1|llms_df$llm_inter==1, 1, 0) #
llms_df$llm2 <- ifelse(adjs_df$llm2_score>=opt_cut2|llms_df$llm_inter==1, 1, 0)
adjs_df$llm1_score <- ifelse(adjs_df$llm1_score>=opt_cut1|llms_df$llm_inter==1, adjs_df$llm1_score, 0) #
adjs_df$llm2_score <- ifelse(adjs_df$llm2_score>=opt_cut2|llms_df$llm_inter==1, adjs_df$llm2_score, 0)
llms_df$llm_inter <- ifelse(rowSums(llms_df)==ncol(llms_df),1,0)
print(table(llms_df[,c("llm1", "llm2")]))
}
label_df_llama8b_new[[topic]] <- llms_df$llm1
label_df_gpt4omini_new[[topic]] <- llms_df$llm2
}
setwd("/Users/joyqiu/Documents/Documents JoyQiu Work/Research/LLMTopicExtraction/llm_topic_extraction")
rm(list = ls())
source("./scripts/data_eng/func_x_transform.R")
get_score_df <- function(folder, mdl_name = "stella_en_400M_v5"){
labeled_df <- read.csv(paste0("./",folder,"/results_with_cos_",mdl_name,".csv"))
labeled_df <- labeled_df[,setdiff(colnames(labeled_df), "X")]
labeled_df <- labeled_df %>% arrange(sm_id)
scores_df <- readRDS(paste0("./",folder,"/cos_score_",mdl_name,".RDS"))
scores_df <- scores_df %>% arrange(sm_id)
# cos_v <- as.numeric(unlist(scores_df[,setdiff(colnames(scores_df),"sm_id")]))
# cos_v <- cos_v[cos_v>-1]
# score_cut = median(cos_v)
par(mfrow=c(4,5))
for(topic in fea_df$fea){
# scores_df[[topic]] <- (scores_df[[topic]] + labeled_df[[topic]])/2 + 0.5
# scores_df[[topic]] <- (scores_df[[topic]] - (-1))/2 # between 0-1
# scores_df[[topic]] <- (scores_df[[topic]] + labeled_df[[topic]])/2
# scores_df[[topic]] <- scores_df[[topic]]*labeled_df[[topic]]
# cos_v <- scores_df[[topic]]
# cos_v <- cos_v[cos_v>-1]
# quantiles <- quantile(cos_v, probs = c(0.25, 0.5, 0.75))
# hist(cos_v, breaks=100, main = topic)
# abline(v = quantiles[1], col = "blue", lwd = 2, lty = 2)  # 25th percentile
# abline(v = quantiles[2], col = "blue", lwd = 2, lty = 2)  # 50th percentile (median)
# abline(v = quantiles[3], col = "blue", lwd = 2, lty = 2)  # 75th percentile
# score_cut <- quantile( scores_df[[topic]][which(scores_df[[topic]]>0)], 0) #0
# scores_df[[topic]] <- ifelse(scores_df[[topic]]<score_cut, score_cut, scores_df[[topic]]) #0
# # recalibrate >0 scores_df[[topic]] between 0 - 1
# a0 <- which(scores_df[[topic]]>0)
# be0 <- which(scores_df[[topic]]<=0)
# print(min(scores_df[[topic]][a0],na.rm=T))
# scores_df[[topic]][a0] <- (scores_df[[topic]][a0] - min(scores_df[[topic]][a0],na.rm=T) ) #/ (max(scores_df[[topic]][a0],na.rm=T) - min(scores_df[[topic]][a0],na.rm=T))
# scores_df[[topic]][be0] <- 0
# shift a cutoff at 0, then zero out <0
cutoff <- quantile(scores_df[[topic]][which(scores_df[[topic]]>0)],0)
a0 <- which(scores_df[[topic]]>=cutoff)
be0 <- which(scores_df[[topic]]<=cutoff)
print(min(scores_df[[topic]][a0],na.rm=T))
scores_df[[topic]][a0] <- (scores_df[[topic]][a0] - min(scores_df[[topic]][a0],na.rm=T) ) / (max(scores_df[[topic]][a0],na.rm=T) - min(scores_df[[topic]][a0],na.rm=T))
scores_df[[topic]][be0] <- 0
scores_df[[topic]] <- scores_df[[topic]]*labeled_df[[topic]]
}
par(mfrow=c(1,1))
text_df <- read.csv("/Users/joyqiu/Documents/Documents JoyQiu Work/Research/ED Media/network/script/llm/sm_eos.csv", stringsAsFactors = FALSE)
info_df <- text_df %>% select(sm_id, group, sr_name, url)
scores_df <- merge(scores_df, info_df)%>% arrange(sm_id)
return(list(labeled_df = labeled_df,
scores_df = scores_df ))
}
mdl_name = "stella_en_1.5B_v5"
# mdl_name = "stella_en_400M_v5"
# mdl_name = "all-mpnet-base-v2"
fea_df <- read.csv("./data/fea_df.csv")
# fea_df <- fea_df[which(!fea_df$fea%in%c("nosocialeat", "thinspo", "fearcarb")),]
obj <- get_score_df("gpt_data", mdl_name)
label_df_gpt4omini <- obj$labeled_df
score_df_gpt4omini <- obj$scores_df
obj <- get_score_df("llama_data", mdl_name)
label_df_llama8b <- obj$labeled_df
score_df_llama8b <- obj$scores_df
# sanity check
distribution_gpt4omini <- score_df_gpt4omini %>%
group_by(group) %>%
summarise(across(all_of(c(fea_df$fea)), ~ mean(.x, na.rm = TRUE)))
distribution_llama8b <- score_df_llama8b %>%
group_by(group) %>%
summarise(across(all_of(c(fea_df$fea)), ~ mean(.x, na.rm = TRUE)))
library(pheatmap)
tmp1 <- distribution_gpt4omini
tmp2 <- distribution_llama8b
mat1 <- as.matrix(tmp1[, -1])
rownames(mat1) <- tmp1$group
pheatmap(mat1,  # Remove the group column, if it's the first column
cluster_rows = FALSE,
cluster_cols = FALSE,
legend_breaks = seq(-1,1,0.1),
main = "Occurrence rates by GPT 4o-mini")
mat2 <- as.matrix(tmp2[, -1])
rownames(mat2) <- tmp2$group
pheatmap(mat2,  # Remove the group column, if it's the first column
cluster_rows = F,
cluster_cols = F,
legend_breaks = seq(-1,1,0.1),
main = "Occurrence rates by Llama 8b-instruct (need a second run)")
# Load necessary libraries
library(ggplot2)
library(tidyr)
library(dplyr)
tmp1 <- distribution_gpt4omini %>% mutate(model = "GPT-4o-mini")
tmp2 <- distribution_llama8b %>% mutate(model = "Llama 8b-instruct")
combined_data <- bind_rows(tmp1, tmp2)
long_data <- combined_data  %>%
pivot_longer(cols = -c(group, model), names_to = "category", values_to = "occurrence_rate")
ggplot(long_data, aes(x = group, y = occurrence_rate, fill = model)) +
geom_bar(stat = "identity", position = "dodge") +
facet_wrap(~category,ncol=4, scales = "free_x") +
labs(y = "Occurrence Rate") +
theme_minimal() +
scale_fill_manual(values = c("GPT-4o-mini" = "skyblue", "Llama 8b-instruct" = "coral")) +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "top")
# ---- get the pearson correlation between two llms -----
library(pROC)
library(PRROC)
correlation_results <- list()
correlation_results_raw <- list()
auroc <- list()
auroc_raw <- list()
auprc <- list()
auprc_raw <- list()
for (topic in fea_df$fea) {
correlation <- cor(score_df_gpt4omini[[topic]], score_df_llama8b[[topic]], use = "complete.obs", method = "pearson")
correlation_raw <- cor(label_df_gpt4omini[[topic]], label_df_llama8b[[topic]], use = "complete.obs", method = "pearson")
correlation_results[[topic]] <- correlation
correlation_results_raw[[topic]] <- correlation_raw
mdl_df <- data.frame(all_label_gpt4 = label_df_gpt4omini[[topic]],
all_label_llama = label_df_llama8b[[topic]],
all_score_gpt4 = score_df_gpt4omini[[topic]],
all_score_llama = score_df_llama8b[[topic]])
mdl_df <- mdl_df[complete.cases(mdl_df),]
mdl_score <- glm(all_label_gpt4 ~ all_score_llama, data=mdl_df, family = binomial(link = "logit"))
predicted_probs <- predict(mdl_score, type = "response")
auroc[[topic]] <- round(auc(roc(mdl_df$all_label_gpt4, predicted_probs)),6)
pr_curve <- pr.curve(scores.class0 = predicted_probs, weights.class0 = mdl_df$all_label_gpt4 == 1, curve = TRUE)
auprc[[topic]] <- pr_curve$auc.integral
mdl_label <- glm(all_label_gpt4 ~ as.factor(all_label_llama), data=mdl_df, family = binomial(link = "logit"))
predicted_probs <- predict(mdl_label, type = "response")
auroc_raw[[topic]] <- round(auc(roc(mdl_df$all_label_gpt4, predicted_probs)),6)
pr_curve <- pr.curve(scores.class0 = predicted_probs, weights.class0 = mdl_df$all_label_gpt4 == 1, curve = TRUE)
auprc_raw[[topic]] <- pr_curve$auc.integral
}
adjust_df <- data.frame(correlation_score = unlist(correlation_results),
correlation_label = unlist(correlation_results_raw),
auprc_score = unlist(auprc),
auprc_label = unlist(auprc_raw))
print(adjust_df)
all_score_gpt4 <- as.numeric(unlist(score_df_gpt4omini[,2:20]))
all_score_llama <- as.numeric(unlist(score_df_llama8b[,2:20]))
all_label_gpt4 <- as.numeric(unlist(label_df_gpt4omini[,4:22]))
all_label_llama <- as.numeric(unlist(label_df_llama8b[,4:22]))
correlation <- cor(all_score_gpt4, all_score_llama, use = "complete.obs", method = "pearson")
correlation_raw <- cor(all_label_gpt4, all_label_llama, use = "complete.obs", method = "pearson")
print(paste0("score corr = ", round(correlation,4),"  label corr = ", round(correlation_raw,4) ))
par(mfrow=c(2,2))
plot(jitter(label_df_gpt4omini$bodyhate), jitter(label_df_llama8b$bodyhate))
plot(score_df_gpt4omini$bodyhate, score_df_llama8b$bodyhate)
# plot(all_score_gpt4, all_score_llama)
# # ----- use score of llama to predict label of gpt -----
# # topic = "fearfood"
# # all_score_gpt4 <- as.numeric(unlist(score_df_gpt4omini[,topic]))
# # all_score_llama <- as.numeric(unlist(score_df_llama8b[,topic]))
# # all_label_gpt4 <- as.numeric(unlist(label_df_gpt4omini[,topic]))
# # all_label_llama <- as.numeric(unlist(label_df_llama8b[,topic]))
#
# library(pROC)
# library(PRROC)
#
# mdl_df <- data.frame(all_label_gpt4 = all_label_gpt4,
#                      all_label_llama = all_label_llama,
#                      all_score_gpt4 = all_score_gpt4,
#                      all_score_llama = all_score_llama)
# mdl_df <- mdl_df[complete.cases(mdl_df),]
# # Fit the logistic regression model
# mdl_score <- glm(all_label_gpt4 ~ all_score_llama, data=mdl_df, family = binomial(link = "logit"))
# predicted_probs <- predict(mdl_score, type = "response")
# roc_curve <- roc(mdl_df$all_label_gpt4, predicted_probs)
# plot(roc_curve, main = paste("adjusted AUROC:", round(auc(roc_curve),6) ))
# # pr_curve <- pr.curve(scores.class0 = predicted_probs, weights.class0 = all_label_gpt4 == 1, curve = TRUE)
# # plot(pr_curve)
#
# # Fit the logistic regression model
# mdl_label <- glm(all_label_gpt4 ~ as.factor(all_label_llama), data=mdl_df, family = binomial(link = "logit"))
# predicted_probs <- predict(mdl_label, type = "response")
# roc_curve <- roc(mdl_df$all_label_gpt4, predicted_probs)
# plot(roc_curve, main = paste("adjusted AUROC:", round(auc(roc_curve),6) ))
# # pr_curve <- pr.curve(scores.class0 = predicted_probs, weights.class0 = all_label_gpt4 == 1, curve = TRUE)
# # plot(pr_curve)
