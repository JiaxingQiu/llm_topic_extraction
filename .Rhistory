daic = aic - min(aic) # the strength of evidence
aw = exp(-daic/2)/(sum( exp(-daic/2)))
plot(aw)
dbic = bic - min(bic) # the strength of evidence
bw = exp(-dbic/2)/(sum( exp(-dbic/2)))
plot(bw)
# winner model: fml = rcs(age,3) + sex + tx + rcs(day,3)
mdl_orm <- orm(y ~ rcs(age,3) + sex + tx + rcs(day,3) + catg(yfirst), data=df_mdl, x=TRUE, y=TRUE)
mdl_rob <- robcov(orm(y ~ rcs(age,3) + sex + tx + rcs(day,3) + catg(yfirst), data=df_mdl, x=TRUE, y=TRUE), cluster = df_mdl$id)
save(mdl_orm, mdl_rob, file = "./rob/orm.RData")
}else{
load("./rob/orm.RData")
}
# with y_prev
if(!file.exists("./cor/orm.RData")){
aic <- c()
bic <- c()
for(fml in list(y ~ age + sex + tx + yprev,
y ~ rcs(age,3) + sex + tx + yprev,
y ~ rcs(age,4) + sex + tx + yprev,
y ~ rcs(age,5) + sex + tx + yprev,
y ~ age + sex + tx + yprev + day,
y ~ rcs(age,3) + sex + tx + yprev + rcs(day,3),
y ~ rcs(age,3) + sex + tx + yprev + rcs(day,4),
y ~ rcs(age,3) + sex + tx + yprev + rcs(day,5), # winner
y ~ rcs(age,4) + sex + tx + yprev + rcs(day,3),
y ~ rcs(age,4) + sex + tx + yprev + rcs(day,4),
y ~ rcs(age,4) + sex + tx + yprev + rcs(day,5),
y ~ rcs(age,5) + sex + tx + yprev + rcs(day,3),
y ~ rcs(age,5) + sex + tx + yprev + rcs(day,4),
y ~ rcs(age,5) + sex + tx + yprev + rcs(day,5)
)){
tryCatch({
anova(orm(fml, data=df_mdl))#, x=TRUE, y=TRUE), test="LR")
},error = function(e){
print(e)
print(fml)
})
aic <- c(aic, AIC(orm(fml, data=df_mdl)))
bic <- c(bic, BIC(orm(fml, data=df_mdl)))
}
plot(aic)
plot(bic)
# calculate Akaike weights
daic = aic - min(aic) # the strength of evidence
aw = exp(-daic/2)/(sum( exp(-daic/2)))
plot(aw)
dbic = bic - min(bic) # the strength of evidence
bw = exp(-dbic/2)/(sum( exp(-dbic/2)))
plot(bw)
# winner model: rcs(age,3) + sex + tx + yprev + rcs(day,5)
# with or without covariance adjustment, we don't see significant negative effect of treatment on the log odds of outcome greater than a level than lower than it.
mdl_orm_cor <- orm(y ~ rcs(age,3) + sex + tx + catg(yprev) + rcs(day,5), data=df_mdl, x=TRUE, y=TRUE)
mdl_rob_cor <- robcov(orm(y ~ rcs(age,3) + sex + tx + catg(yprev) + rcs(day,5), data=df_mdl, x=TRUE, y=TRUE), cluster = df_mdl$id)
save(mdl_orm_cor, mdl_rob_cor, file = "./cor/orm.RData")
}else{
load("./cor/orm.RData")
}
if(!file.exists("./rob/gee.RData")){
# # okay, ordgee function in geepack package has serious convergence issue. This paper https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6838778/ showed that only 444/1000 of "ordgee" converged.
# mdl_gee <- ordgee(y ~ rcs(age,3) + sex + tx + rcs(day,3) + catg(yfirst),
#                   data = df_mdl,
#                   id = df_mdl$id,
#                   mean.link ="logit", # "logit", "cloglog"
#                   corstr = "independence")
# summary(mdl_gee)
# # geese object don't have IC implemented
# switch to multgee package might converge better
mdl_gee <- ordLORgee(y ~ rcs(age,3) + sex + tx + rcs(day,3) + catg(yfirst),
data = df_mdl,
id = df_mdl$id,
link = "logit",
LORstr = "independence"
)
summary(mdl_gee)
save(mdl_gee,file="./rob/gee.RData")
} else{
load("./rob/gee.RData")
}
if(!file.exists("./rob/gee_uniform.RData")){
## experiment different types of cor str in gee
mdl_gee_uniform <- ordLORgee(y ~ rcs(age,3) + sex + tx + rcs(day,3) + catg(yfirst),
data = df_mdl,
id = df_mdl$id,
link = "logit",
LORstr = "uniform"
)
save(mdl_gee_uniform, file="./rob/gee_uniform.RData") #This option assumes that the local odds ratios are the same (uniform) across all categories or time points. It implies a consistent relationship between the outcomes regardless of which specific categories or time points are being compared.
# get local odds ratio
# dim(mdl_gee$local.odds.ratios$theta) # the marginalized local odds ratios structure variables.
# 7*27 = 189 n_states * n_time
# 189 * 189
# #  ---- check residuals ----
# df_mdl$residuals <- rowMeans( mdl_gee_uniform$residuals)
#
# ggplot(df_mdl[df_mdl$id%in%sampled_df$id,], aes(x = as.factor(id), y = residuals)) +
#   geom_boxplot() +
#   theme_minimal() +
#   theme(axis.text.x = element_text(angle = 90, hjust = 1))
# df_mdl$y_pred <- max.col(mdl_gee_uniform$fitted.values, ties.method = "first")
# df_mdl$y_diff <- as.numeric(df_mdl$y_pred) - as.numeric(df_mdl$y)
#
# ggplot(df_mdl[df_mdl$id%in%sampled_df$id,], aes(x = as.factor(id), y = y_diff)) +
#   geom_boxplot() +
#   theme_minimal() +
#   theme(axis.text.x = element_text(angle = 90, hjust = 1))
}else{
load("./rob/gee_uniform.RData")
}
# the following correlation structures don't converge
# mdl_gee_cat_exch <- ordLORgee(y ~ rcs(age,3) + sex + tx + rcs(day,3) + catg(yfirst),
#                     data = df_mdl,
#                     id = df_mdl$id,
#                     link = "logit",
#                     bstart = coef(mdl_gee),
#                     LORstr = "category.exch"
#                     )#This option assumes a category exchangeable structure, meaning the local odds ratios are constant across different categories within the same time point, but they can vary between different time points.
# # bstart a vector that includes an initial estimate for the marginal regression parameter vector.
#
# load("./rob/gee_uniform.RData")
# mdl_gee_tim_exch <- ordLORgee(y ~ rcs(age,3) + sex + tx + rcs(day,3) + catg(yfirst),
#                     data = df_mdl,
#                     id = df_mdl$id,
#                     link = "probit",
#                     bstart = coef(mdl_gee_uniform),
#                     LORstr = "time.exch" ) #This option assumes a time exchangeable structure, where the local odds ratios are constant across different time points for the same category but can vary between different categories.
# ordinal random effects model, account for cluster heterogeneity using random intercept
if(!file.exists("./rob/re.RData")){
mdl_re <- clmm(y ~ rcs(age,3) + sex + tx + rcs(day,3) + (1 | id),
data = df_mdl,
link = "logit") # no hessian
summary(mdl_re)
AIC(mdl_re)  # 50410.32 = -2*mdl_re$logLik + 2*14
# this turns out to be the marginal AIC,
# they don't document which AIC their package is returning, marginal or conditional??!!
# dim(solve(mdl_re$Hessian))
# length(mdl_re$gradient)
# g <- as.matrix(mdl_re$gradient,ncol=14,nrow=1)
# fisher <- g  %*% t(g)
# sum(diag(solve(mdl_re$Hessian) %*% fisher))
mdl_re1 <- clmm(y ~ rcs(age,3) + sex + tx + rcs(day,3) + (1 + rcs(day,3) | id),
data = df_mdl,
link = "probit") # no hessian
summary(mdl_re1)
AIC(mdl_re1)  # 37560.25 yes!
mdl_re2 <- clmm(y ~ rcs(age,5) + sex + tx + rcs(day,5) + (1  + rcs(day,5) | id),
data = df_mdl,
link = "probit") # AIC =  # hessian not available
summary(mdl_re1)
AIC(mdl_re1)  # 37560.25 yes!
# library(brms)
# mdl_bre <- brm(y ~ age + sex + tx + day + (1|id), data=df_mdl, family=cumulative("logit"))
# LOO(mdl_bre)
save(mdl_re, mdl_re1, file="./rob/re.RData")
}else{
load("./rob/re.RData")
}
# ordinal random effects model, account for cluster heterogeneity using random intercept
if(!file.exists("./cor/re.RData")){
mdl_re_cor <- clmm(y ~ rcs(age,3) + sex + tx + yprev + rcs(day,5) + (1 | id),
data = df_mdl,
link = "logit") # no hessian
summary(mdl_re_cor)
AIC(mdl_re_cor)
# 1.01e-06 0.001005 random intercept variance
# this turns out to be the marginal AIC  = -2*mdl_re$logLik + 2*n_param
# they don't document which AIC their package is returning, marginal or conditional??!!
# dim(solve(mdl_re$Hessian))
# length(mdl_re$gradient)
# g <- as.matrix(mdl_re$gradient,ncol=14,nrow=1)
# fisher <- g  %*% t(g)
# sum(diag(solve(mdl_re$Hessian) %*% fisher))
save(mdl_re_cor, file="./cor/re.RData")
}else{
load("./cor/re.RData")
}
mdl_name <- c("Standard PO",
"Standard PO w/ lag1",
"GEE (indepedence)",
"GEE (uniform)",
"GEE (indepedence) w/ lag1",
"RE (1|id)",
"RE (1+rcs(day,3)|id)",
"RE (1|id) w/ lag1")
aic_name <- round(c(AIC(mdl_orm),
AIC(mdl_orm_cor),
AIC(mdl_rob),
NA,
AIC(mdl_rob_cor),
AIC(mdl_re),
AIC(mdl_re1),
AIC(mdl_re_cor)),2)
aic_name[is.na(aic_name)] <- "QIC NA"
treatment_odds_ratio <- c(exp(coef(mdl_orm)[["tx=Active"]]),
exp(coef(mdl_orm_cor)[["tx=Active"]]),
exp(coef(mdl_rob)[["tx=Active"]]),
exp(coef(mdl_gee_uniform)[["txActive"]]),
exp(coef(mdl_rob_cor)[["tx=Active"]]),
exp(coef(mdl_re)[["txActive"]]),
exp(coef(mdl_re1)[["txActive"]]),
exp(coef(mdl_re_cor)[["txActive"]]) )
treatment_p <- c("<0.0001",
0.2385,
0.0037,
0.0426,
0.2372,
0.0084,
0.373,
NA)
treatment_p[is.na(treatment_p)] <- "Hessian NA"
compare_table <- data.frame("Model" = mdl_name,
"AIC" = aic_name,
"Treatment Odds Ratio" = treatment_odds_ratio,
"p-value" = treatment_p)
compare_table <- rbind(compare_table[c(1,3,6),], compare_table[c(4,7),], compare_table[c(2,5,8),])
compare_table$temporal_correlation<-c(rep("none",3),
rep("implicit",2),
rep("explicit",3))
compare_table <- compare_table[,c("adjust_temporal_correlation",setdiff(colnames(compare_table),"temporal_correlation"))]
robcov(orm(y ~ rcs(age,3) + sex + tx*catg(yprev) + rcs(day,5), data=df_mdl, x=TRUE, y=TRUE), cluster = df_mdl$id)
# Generate prediction data
pred_data <- Predict(mdl_rob_cor)
# Create the plot
ggplot(pred_data, aes(x = x, y = yhat)) +
geom_line() +
geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +
facet_wrap(~ variable, scales = "free") +
labs(x = "Predictor Value", y = "Predicted Outcome",
title = "Predicted Relationships with Free Scales") +
theme_minimal()
pred_data
# Create the plot
ggplot(pred_data, aes(x = x, y = yhat)) +
geom_line() +
geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +
facet_wrap(~ .predictor., scales = "free") +
labs(x = "Predictor Value", y = "Predicted Outcome",
title = "Predicted Relationships with Free Scales") +
theme_minimal()
# Create the plot
ggplot(pred_data, aes(x = x, y = yhat)) +
geom_line() +
geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +
facet_wrap(~ predictor, scales = "free") +
labs(x = "Predictor Value", y = "Predicted Outcome",
title = "Predicted Relationships with Free Scales") +
theme_minimal()
pred_data$predictor <- pred_data$.predictor.
# Create the plot
ggplot(pred_data, aes(x = x, y = yhat)) +
geom_line() +
geom_ribbon(aes(ymin = lower, ymax = upper), alpha = 0.2) +
facet_wrap(~ predictor, scales = "free") +
labs(x = "Predictor Value", y = "Predicted Outcome",
title = "Predicted Relationships with Free Scales") +
theme_minimal()
pred_data
ggplot(Predict(mdl_rob_cor))
ggplot(Predict(mdl_rob_cor, age))
p_age <- ggplot(Predict(mdl_rob_cor, age))
p_age <- ggplot(Predict(mdl_rob_cor, age)) + ylim(0,5)
p_age
p_y_prev <- ggplot(Predict(mdl_rob_cor, y_prev))
p_y_prev
p_y_prev <- ggplot(Predict(mdl_rob_cor, y_prev))
p_yprev <- ggplot(Predict(mdl_rob_cor, yprev))
p_yprev
p_age <- ggplot(Predict(mdl_rob_cor, age))
p_day <- ggplot(Predict(mdl_rob_cor, day))
p_yprev <- ggplot(Predict(mdl_rob_cor, yprev))
p_tx <- ggplot(Predict(mdl_rob_cor, tx))
p_sex <- ggplot(Predict(mdl_rob_cor, sex))
ggarrange(p_age,p_day, p_yprev, p_tx, p_sex, ncol=3, nrow=2)
# ggplot(Predict(mdl_rob_cor))
p_age <- ggplot(Predict(mdl_rob_cor, age), ylim. = c(0,5))
p_age
p_age <- ggplot(Predict(mdl_rob_cor, age), ylim. = c(0,2))
p_day <- ggplot(Predict(mdl_rob_cor, day), ylim. = c(0,2))
p_yprev <- ggplot(Predict(mdl_rob_cor, yprev))
p_tx <- ggplot(Predict(mdl_rob_cor, tx))
p_sex <- ggplot(Predict(mdl_rob_cor, sex))
ggarrange(p_age,p_day, p_yprev, p_tx, p_sex, ncol=3, nrow=2)
p1 <- rms::bplot(rms::Predict(mdl_rob_cor, age, yprev), ylabrot=90,adj.subtitle=FALSE)
p2 <- rms::bplot(rms::Predict(mdl_rob_cor, day, yprev), ylabrot=90,adj.subtitle=FALSE)
p3 <- rms::bplot(rms::Predict(mdl_rob_cor, age, day),ylabrot=90,adj.subtitle=FALSE)
ggarrange(p1,p2,p3, ncol=3)
source("~/.active-rstudio-document", echo=TRUE)
# ggplot(Predict(mdl_rob_cor))
p_age <- ggplot(Predict(mdl_rob_cor, age, fun = exp), ylim. = c(0,2))
p_day <- ggplot(Predict(mdl_rob_cor, day, fun = exp), ylim. = c(0,2))
p_yprev <- ggplot(Predict(mdl_rob_cor, yprev, fun = exp))
p_tx <- ggplot(Predict(mdl_rob_cor, tx, fun = exp))
p_sex <- ggplot(Predict(mdl_rob_cor, sex, fun = exp))
ggarrange(p_age,p_day, p_yprev, p_tx, p_sex, ncol=2, nrow=3)
# pred_probs <- predict(mdl_rob, type = "fitted.ind")
# df_mdl$y_pred <- max.col(pred_probs, ties.method = "first")
# table(df_mdl$y_pred, df_mdl$y)
# ggplot(Predict(mdl_rob_cor))
p_age <- ggplot(Predict(mdl_rob_cor, age), ylim. = c(0,2))
p_day <- ggplot(Predict(mdl_rob_cor, day), ylim. = c(0,2))
p_yprev <- ggplot(Predict(mdl_rob_cor, yprev))
p_tx <- ggplot(Predict(mdl_rob_cor, tx))
p_sex <- ggplot(Predict(mdl_rob_cor, sex))
ggarrange(p_age,p_day, p_yprev, p_tx, p_sex, ncol=2, nrow=3)
# pred_probs <- predict(mdl_rob, type = "fitted.ind")
# df_mdl$y_pred <- max.col(pred_probs, ties.method = "first")
# table(df_mdl$y_pred, df_mdl$y)
# ggplot(Predict(mdl_rob_cor))
p_age <- ggplot(Predict(mdl_rob_cor, age), ylim. = c(0,2), ylab = "log odds of a worse outcome")
p_day <- ggplot(Predict(mdl_rob_cor, day), ylim. = c(0,2), ylab = "log odds of a worse outcome")
p_yprev <- ggplot(Predict(mdl_rob_cor, yprev))
p_tx <- ggplot(Predict(mdl_rob_cor, tx))
p_sex <- ggplot(Predict(mdl_rob_cor, sex))
ggarrange(p_age,p_day, p_yprev, p_tx, p_sex, ncol=2, nrow=3)
# pred_probs <- predict(mdl_rob, type = "fitted.ind")
# df_mdl$y_pred <- max.col(pred_probs, ties.method = "first")
# table(df_mdl$y_pred, df_mdl$y)
x <- rnorm(10000, 0,1)
x <- rnorm(10000, 0,1)
y <- 2*x
plot(x,y)
y <- 2*x^2
plot(x,y)
y <- 2*x^2 + rnorm(10000, 0, 0.1)
plot(x,y)
y <- 2*x^2 + rnorm(10000, 0, 0.5)
plot(x,y)
cor(x,y,method="spearman")
cor(x,y,method="pearson")
y <- 2*exp(x) + rnorm(10000, 0, 0.5)
cor(x,y,method="pearson")
cor(x,y,method="spearman")
citation(glmmTMB)
citation("glmmTMB")
?glmmTMB
??glmmTMB
citation("glmmTMB")
citation("R")
citation(R)
# 1. answer_df
# run "~/Documents/Documents JoyQiu Work/Research/ED Media/network/script/llm/data_clean_in_r_with_EOS.R" first
df_llm <- read.csv("/Users/joyqiu/Documents/Documents JoyQiu Work/Research/ED Media/network/script/llm/sm_eos.csv", stringsAsFactors = F)
answer_df <- df_llm[,c("sm_id", "text_w_eos")]
# answer_df1 <- answer_df[1:30000,]
# answer_df2 <- answer_df[30001:nrow(answer_df),]
# stopifnot(nrow(answer_df2) + nrow(answer_df1) == nrow(answer_df))
# setdiff(union(answer_df2$sm_id, answer_df1$sm_id), answer_df$sm_id)
# setdiff(answer_df$sm_id, union(answer_df2$sm_id, answer_df1$sm_id))
#
# write.csv(answer_df1, "/Users/joyqiu/Documents/Documents JoyQiu Work/Research/LLMTopicExtraction/llm_topic_extraction/data/answer_df_raw1.csv", row.names = F)
# write.csv(answer_df2, "/Users/joyqiu/Documents/Documents JoyQiu Work/Research/LLMTopicExtraction/llm_topic_extraction/data/answer_df_raw2.csv", row.names = F)
write.csv(answer_df, "/Users/joyqiu/Documents/Documents JoyQiu Work/Research/LLMTopicExtraction/llm_topic_extraction/data/answer_df_raw.csv", row.names = F)
setwd("/Users/joyqiu/Documents/Documents JoyQiu Work/Research/LLMTopicExtraction/llm_topic_extraction")
rm(list=ls())
source("./scripts/data_eng/func_label_topics.R")
fea_df <- read.csv("./data/fea_df.csv")
# ------ 1. GPT 4o mini --------
# loop through all csv files under "./gpt_data" folder
library(dplyr)
folder_path <- "./gpt_data"
csv_files <- list.files(path = folder_path, pattern = "*.csv", full.names = TRUE)
answer_df <- lapply(csv_files, read.csv) %>% bind_rows()
answer_df$answer_string <- answer_df$responses
labeled_df <- format_answer_df(answer_df, fea_df$fea)
labeled_df_gpt4omini <- labeled_df[complete.cases(labeled_df),]
# ------ 2. llama 8b -------
# answer_df_part1.csv contain first part of llama query results
answer_df_llama1 <- read.csv("./llama_data/answer_df_part1.csv", stringsAsFactors = F)
answer_df_llama2 <- read.csv("./llama_data/answer_df_part2.csv", stringsAsFactors = F)
# part 1
answer_df_llama1$answer_string <- gsub("thinspo","thinny",answer_df_llama1$answer_string)
answer_df <- answer_df_llama1 %>% filter( (!is.na(answer_string)) & (!answer_string=="") &
(!is.na(answer_string2)) & (!answer_string2=="") &
(!is.na(answer_string3)) & (!answer_string3=="") ) %>%
as.data.frame()
answer_df$answer_string <- paste0(answer_df$answer_string, "\n", answer_df$answer_string2, "\n", answer_df$answer_string3 )
answer_df <- answer_df %>% select(sm_id, text_w_eos, answer_string) %>% as.data.frame()
# part 2
answer_df <- bind_rows(answer_df, answer_df_llama2)
labeled_df_llama8b <- format_answer_df(answer_df, fea_df$fea)
colnames(labeled_df_llama8b)
# additional info
text_df <- read.csv("/Users/joyqiu/Documents/Documents JoyQiu Work/Research/ED Media/network/script/llm/sm_eos.csv", stringsAsFactors = FALSE)
info_df <- text_df %>% select(sm_id, group, sr_name, url)
labeled_df_gpt4omini <- merge(labeled_df_gpt4omini, info_df, by = "sm_id", all.x = TRUE)
labeled_df_llama8b <- merge(labeled_df_llama8b, info_df, by = "sm_id", all.x = TRUE)
rm(text_df)
# ------- 4. sample human label data --------
labeled_df_llama8b %>% group_by(sr_name) %>% summarise(nsm = distinct(sm_id))
# ------- 4. sample human label data --------
labeled_df_llama8b %>% group_by(sr_name) %>% summarise(nsm = n_distinct(sm_id))
# ------- 4. sample human label data --------
tmp <- labeled_df_llama8b %>%
group_by(sr_name) %>%
summarise(nsm = n_distinct(sm_id)) %>%
filter(nsm>=10) %>% as.data.frame()
tmp
labeled_df <- labeled_df_llama8b %>% filter(sr_name %in% tmp$sr_name)
# ------- 4. sample human label data --------
tmp <- labeled_df_llama8b %>%
group_by(sr_name) %>%
summarise(nsm = n_distinct(sm_id)) %>%
filter(nsm>=10) %>% as.data.frame()
labeled_df <- labeled_df_llama8b %>% filter(sr_name %in% tmp$sr_name)
setdiff(unique(labeled_df_llama8b$sr_name),)
setdiff(unique(labeled_df_llama8b$sr_name),tmp$sr_name)
labeled_df_llama8b$sr_name
labeled_df_llama8b
tmp$sr_name
setdiff(unique(labeled_df_llama8b$sr_name),tmp$sr_name)
print(setdiff(unique(labeled_df_llama8b$sr_name),tmp$sr_name)) # remember to remove these forums from semantic network
labeled_df
set.seed(333)
sampled_df <- labeled_df %>%
group_by(sr_name) %>%
sample_n(size = 10) %>%
ungroup()  # Remove grouping for further analysis
print(sampled_df$sm_id)
sampled_df_human <- sampled_df[,1:3]
sampled_df_human
colnames(sampled_df)
sampled_df_human$answer_string_human <- paste0(paste0(colnames(sampled_df)[4:22], collapse = ": 0\n"), ": 0\n")
write.csv(sampled_df_human, "human_data/sampled_posts.csv", row.names = F)
# ------- 4. sample human label data --------
tmp <- labeled_df_gpt4omini %>%
group_by(sr_name) %>%
summarise(nsm = n_distinct(sm_id)) %>%
filter(nsm>=10) %>% as.data.frame() #
labeled_df <- labeled_df_gpt4omini %>% filter(sr_name %in% tmp$sr_name)
print(setdiff(unique(labeled_df_gpt4omini$sr_name),tmp$sr_name)) # remember to remove these forums from semantic network
set.seed(333)
sampled_df <- labeled_df %>%
group_by(sr_name) %>%
sample_n(size = 10) %>%
ungroup()  # Remove grouping for further analysis
print(sampled_df$sm_id)
sampled_df_human <- sampled_df[,1:3]
sampled_df_human$answer_string_human <- paste0(paste0(colnames(sampled_df)[4:22], collapse = ": 0\n"), ": 0\n")
write.csv(sampled_df_human, "human_data/sampled_posts.csv", row.names = F)
# ------- 4. sample human label data --------
labeled_df_gpt4omini <- merge(labeled_df_gpt4omini, labeled_df_llama8b[,c("sm_id","text_w_eos")])
tmp <- labeled_df_gpt4omini %>%
group_by(sr_name) %>%
summarise(nsm = n_distinct(sm_id)) %>%
filter(nsm>=10) %>% as.data.frame() #
labeled_df <- labeled_df_gpt4omini %>% filter(sr_name %in% tmp$sr_name)
print(setdiff(unique(labeled_df_gpt4omini$sr_name),tmp$sr_name)) # remember to remove these forums from semantic network
set.seed(333)
sampled_df <- labeled_df %>%
group_by(sr_name) %>%
sample_n(size = 10) %>%
ungroup()  # Remove grouping for further analysis
print(sampled_df$sm_id)
sampled_df
sampled_df_human <- sampled_df[,c("sm_id","answer_string","text_w_eos")]
colnames(sampled_df)
colnames(sampled_df)[4:22]
sampled_df_human$answer_string_human <- paste0(paste0(colnames(sampled_df)[4:22], collapse = ": 0\n"), ": 0\n")
write.csv(sampled_df_human, "human_data/sampled_posts.csv", row.names = F)
# ------- 4. sample human label data --------
labeled_df_gpt4omini <- merge(labeled_df_gpt4omini, labeled_df_llama8b[,c("sm_id","text_w_eos")])
tmp <- labeled_df_gpt4omini %>%
group_by(sr_name) %>%
summarise(nsm = n_distinct(sm_id)) %>%
filter(nsm>=10) %>% as.data.frame() #
labeled_df <- labeled_df_gpt4omini %>% filter(sr_name %in% tmp$sr_name)
print(setdiff(unique(labeled_df_gpt4omini$sr_name),tmp$sr_name)) # remember to remove these forums from semantic network
set.seed(333)
sampled_df <- labeled_df %>%
group_by(sr_name) %>%
sample_n(size = 10) %>%
ungroup()  # Remove grouping for further analysis
print(sampled_df$sm_id)
sampled_df_human <- sampled_df[,c("sm_id","text_w_eos","answer_string")]
sampled_df_human$answer_string_human <- paste0(paste0(colnames(sampled_df)[4:22], collapse = ": 0\n"), ": 0\n")
write.csv(sampled_df_human, "human_data/sampled_posts.csv", row.names = F)
# ------- 4. sample human label data --------
labeled_df_gpt4omini <- merge(labeled_df_gpt4omini, labeled_df_llama8b[,c("sm_id","text_w_eos")])
tmp <- labeled_df_gpt4omini %>%
group_by(sr_name) %>%
summarise(nsm = n_distinct(sm_id)) %>%
filter(nsm>=10) %>% as.data.frame() #
labeled_df <- labeled_df_gpt4omini %>% filter(sr_name %in% tmp$sr_name)
print(setdiff(unique(labeled_df_gpt4omini$sr_name),tmp$sr_name)) # remember to remove these forums from semantic network
set.seed(333)
sampled_df <- labeled_df %>%
group_by(sr_name) %>%
sample_n(size = 10) %>%
ungroup()  # Remove grouping for further analysis
print(sampled_df$sm_id)
sampled_df_human <- sampled_df[,c("sm_id","text_w_eos","answer_string")]
colnames(sampled_df)[4:22]
colnames(sampled_df)[5:23]
# ------- 4. sample human label data --------
labeled_df_gpt4omini <- merge(labeled_df_gpt4omini, labeled_df_llama8b[,c("sm_id","text_w_eos")])
tmp <- labeled_df_gpt4omini %>%
group_by(sr_name) %>%
summarise(nsm = n_distinct(sm_id)) %>%
filter(nsm>=10) %>% as.data.frame() #
labeled_df <- labeled_df_gpt4omini %>% filter(sr_name %in% tmp$sr_name)
print(setdiff(unique(labeled_df_gpt4omini$sr_name),tmp$sr_name)) # remember to remove these forums from semantic network
set.seed(333)
sampled_df <- labeled_df %>%
group_by(sr_name) %>%
sample_n(size = 10) %>%
ungroup()  # Remove grouping for further analysis
print(sampled_df$sm_id)
sampled_df_human <- sampled_df[,c("sm_id","text_w_eos","answer_string")]
sampled_df_human$answer_string_human <- paste0(paste0(colnames(sampled_df)[5:23], collapse = ": 0\n"), ": 0\n")
write.csv(sampled_df_human, "human_data/sampled_posts.csv", row.names = F)
sampled_df_human$answer_string_human
write.csv(sampled_df_human, "human_data/sampled_posts.csv", row.names = F)
