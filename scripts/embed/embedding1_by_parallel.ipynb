{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb06901",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install sentence_transformers==3.0.1\n",
    "# %pip install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d610d23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jq2uw/.local/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "\n",
    "# Load the pre-trained Sentence Transformer model\n",
    "# mdl_name = 'stella_en_1.5B_v5' # oom\n",
    "# mdl_name = 'stella_en_400M_v5'\n",
    "mdl_name = 'all-mpnet-base-v2'\n",
    "# mdl_name = 'all-MiniLM-L6-v2'\n",
    "\n",
    "# model = SentenceTransformer(\"dunzhang/\"+mdl_name, trust_remote_code=True).cuda()\n",
    "model = SentenceTransformer(mdl_name, trust_remote_code=True).cuda()\n",
    "\n",
    "# Function to generate embeddings\n",
    "def get_embeddings(text):\n",
    "    # Generate embeddings\n",
    "    embedding = model.encode(text)\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4902e7ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "folder = \"qwen_data\"\n",
    "res_df = pd.read_csv(\"../../\"+folder+\"/results.csv\")\n",
    "res_df = res_df.fillna(\"\")\n",
    "fea_df = pd.read_csv(\"../../data/fea_df.csv\")\n",
    "\n",
    "fea_df['description'] = fea_df['description'].apply(\n",
    "    lambda x: re.sub(r\"Must related to [^(]*\\(?.*?\\)?\\.\", \"\", x).strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb3de30c-4696-43d6-9c1d-d96cf4ec948a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wearing baggy clothes (0.3213268220424652);  feeling scared to talk (0.17658159136772156);\n"
     ]
    }
   ],
   "source": [
    "# example sm_id\n",
    "\n",
    "sm_id = \"104a474\"\n",
    "topic = \"bodyhate\"\n",
    "\n",
    "res_str = ''\n",
    "refer_str = fea_df.loc[fea_df.fea==topic, 'description'].tolist()[0]\n",
    "returned_str = res_df.loc[res_df.sm_id==sm_id, topic+\"_phrases\"].tolist()[0]\n",
    "\n",
    "returned_str_ls = returned_str.split(\";\")\n",
    "query_embeddings = model.encode([refer_str])\n",
    "doc_embeddings = model.encode(returned_str_ls)\n",
    "cos_scores = cosine_similarity(query_embeddings, doc_embeddings)[0]\n",
    "# get the dot product similarity\n",
    "dot_scores = np.dot(query_embeddings, doc_embeddings.T)[0]\n",
    "res_str = \"; \".join([f\"{returned_str_ls[i]} ({cos_scores[i]})\" for i in range(len(returned_str_ls))]) + \";\"\n",
    "                \n",
    "print(res_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5301b818",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_batch(res_df_batch, fea_df, folder, mdl_name, model):\n",
    "    res_df_with_cos_batch = res_df_batch.copy()\n",
    "    sm_id_counter = 0  # Counter to track the number of processed sm_id\n",
    "    \n",
    "    for sm_id in tqdm(res_df_batch.sm_id.unique(), desc=\"Processing sm_id\"):\n",
    "        for topic in fea_df.fea.unique():\n",
    "            refer_str = fea_df.loc[fea_df.fea == topic, 'description'].tolist()[0]\n",
    "            returned_str = res_df_batch.loc[res_df_batch.sm_id == sm_id, f\"{topic}_phrases\"].tolist()[0]\n",
    "            \n",
    "            if returned_str:\n",
    "                returned_str_ls = returned_str.split(\";\")\n",
    "                query_embeddings = model.encode([refer_str])\n",
    "                doc_embeddings = model.encode(returned_str_ls)\n",
    "                cos_scores = cosine_similarity(query_embeddings, doc_embeddings)[0]\n",
    "                res_str = \"; \".join([f\"{returned_str_ls[i]} ({cos_scores[i]})\" for i in range(len(returned_str_ls))]) + \";\"\n",
    "                res_df_with_cos_batch.loc[res_df_with_cos_batch.sm_id == sm_id, f\"{topic}_phrases\"] = res_str\n",
    "        \n",
    "        # # Increment the counter and check if 1000 sm_id have been processed\n",
    "        # sm_id_counter += 1\n",
    "        # if sm_id_counter % 1000 == 0:\n",
    "        #     # Write intermediate results to CSV\n",
    "        #     output_path = os.path.join(\"../../\", folder, f\"results_with_cos_{mdl_name}.csv\")\n",
    "        #     res_df_with_cos_batch.to_csv(output_path, index=False)\n",
    "        #     print(f\"Intermediate results written to {output_path} at {sm_id_counter} sm_id\")\n",
    "    \n",
    "    # # Final write to ensure all data is saved at the end\n",
    "    # output_path = os.path.join(\"../../\", folder, f\"results_with_cos_{mdl_name}.csv\")\n",
    "    # res_df_with_cos_batch.to_csv(output_path, index=False)\n",
    "    # print(f\"Final results written to {output_path}\")\n",
    "\n",
    "    return res_df_with_cos_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f9872",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sm_id:  73%|███████▎  | 14077/19294 [16:18<05:49, 14.94it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "# process_batch(res_df, fea_df, folder, mdl_name, model)\n",
    "\n",
    "\n",
    "# Split res_df into 10 batches\n",
    "res_df_batches = np.array_split(res_df, 4)\n",
    "\n",
    "# Run each batch in parallel using joblib\n",
    "results = Parallel(n_jobs=4)(delayed(process_batch)(batch, fea_df, folder, mdl_name, model) for batch in res_df_batches)\n",
    "\n",
    "# Combine results back into the main DataFrame\n",
    "res_df_with_cos = pd.concat(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3175b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_with_cos.to_csv(\"../../\"+folder+\"/results_with_cos_\"+mdl_name+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0f2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
