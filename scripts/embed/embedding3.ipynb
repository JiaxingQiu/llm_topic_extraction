{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb06901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sentence_transformers==3.0.1\n",
    "#%pip install xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e97652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# query_prompt_name = \"s2p_query\"\n",
    "\n",
    "# # for each post, per topic, queries is []\n",
    "# queries = [\n",
    "#     \"What are some ways to reduce stress?\",\n",
    "#     \"What are the benefits of drinking green tea?\",\n",
    "# ]\n",
    "# # \n",
    "# docs = [\n",
    "#     \"There are many effective ways to reduce stress. Some common techniques include deep breathing, meditation, and physical activity. Engaging in hobbies, spending time in nature, and connecting with loved ones can also help alleviate stress. Additionally, setting boundaries, practicing self-care, and learning to say no can prevent stress from building up.\",\n",
    "#     \"Green tea has been consumed for centuries and is known for its potential health benefits. It contains antioxidants that may help protect the body against damage caused by free radicals. Regular consumption of green tea has been associated with improved heart health, enhanced cognitive function, and a reduced risk of certain types of cancer. The polyphenols in green tea may also have anti-inflammatory and weight loss properties.\",\n",
    "# ]\n",
    "\n",
    "# # ！The default dimension is 1024, if you need other dimensions, please clone the model and modify `modules.json` to replace `2_Dense_1024` with another dimension, e.g. `2_Dense_256` or `2_Dense_8192` !\n",
    "# model = SentenceTransformer(\"dunzhang/stella_en_1.5B_v5\", trust_remote_code=True)\n",
    "# query_embeddings = model.encode(queries, prompt_name=query_prompt_name)\n",
    "# doc_embeddings = model.encode(docs)\n",
    "# print(query_embeddings.shape, doc_embeddings.shape)\n",
    "\n",
    "\n",
    "# similarities = model.similarity(query_embeddings, doc_embeddings)\n",
    "# print(similarities)\n",
    "# # tensor([[0.8179, 0.2958],\n",
    "# #         [0.3194, 0.7854]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d610d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yg9bq/miniconda3/envs/embed/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dunzhang/stella_en_400M_v5 were not used when initializing NewModel: ['new.pooler.dense.bias', 'new.pooler.dense.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "\n",
    "# Load the pre-trained Sentence Transformer model\n",
    "# mdl_name = 'stella_en_1.5B_v5' # oom\n",
    "mdl_name = 'stella_en_400M_v5'\n",
    "model = SentenceTransformer(\"dunzhang/\"+mdl_name, trust_remote_code=True).cuda()\n",
    "\n",
    "# Function to generate embeddings\n",
    "def get_embeddings(text):\n",
    "    # Generate embeddings\n",
    "    embedding = model.encode(text)\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4902e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"llama_data\"\n",
    "res_df = pd.read_csv(\"../../\"+folder+\"/results.csv\")\n",
    "res_df = res_df.fillna(\"\")\n",
    "fea_df = pd.read_csv(\"../../data/fea_df.csv\")\n",
    "\n",
    "fea_df['description'] = fea_df['description'].apply(\n",
    "    lambda x: re.sub(r\"Must related to [^(]*\\(?.*?\\)?\\.\", \"\", x).strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "671e0b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i wear baggy clothes to hide what i look like (0.4440997242927551);  people have noticed (0.2869022488594055);'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "\n",
    "# loop through each sm_id in res_df.sm_id\n",
    "# loop through each topic in fea_df.fea\n",
    "sm_id = \"104a474\"\n",
    "topic = \"bodyhate\"\n",
    "\n",
    "\n",
    "refer_str = fea_df.loc[fea_df.fea==topic, 'description'].tolist()[0]\n",
    "returned_str = res_df.loc[res_df.sm_id==sm_id, topic+\"_phrases\"].tolist()[0]\n",
    "returned_str_ls = returned_str.split(\";\") # split returned_str by \";\"[\"i wear baggy clothes to hide what i look like.\"]#\n",
    "query_prompt_name = \"s2p_query\"\n",
    "query_embeddings = model.encode([refer_str], prompt_name=query_prompt_name)\n",
    "doc_embeddings = model.encode(returned_str_ls)\n",
    "# print(query_embeddings.shape, doc_embeddings.shape)\n",
    "cos_scores = cosine_similarity(query_embeddings, doc_embeddings)[0]\n",
    "res_str = \"; \".join([f\"{returned_str_ls[i]} ({cos_scores[i]})\" for i in range(len(returned_str_ls))]) + \";\"\n",
    "\n",
    "res_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d6d552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import os\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# # Define the function to process each batch of res_df\n",
    "# def process_batch(res_df_batch, fea_df):\n",
    "#     res_df_with_cos_batch = res_df_batch.copy()\n",
    "#     for sm_id in tqdm(res_df_batch.sm_id.unique(), desc=\"Processing sm_id\"):\n",
    "#         for topic in fea_df.fea.unique():\n",
    "#             refer_str = fea_df.loc[fea_df.fea == topic, 'description'].tolist()[0]\n",
    "#             returned_str = res_df_batch.loc[res_df_batch.sm_id == sm_id, f\"{topic}_phrases\"].tolist()[0]\n",
    "            \n",
    "#             if returned_str:\n",
    "#                 returned_str_ls = returned_str.split(\";\")\n",
    "#                 query_prompt_name = \"s2p_query\"\n",
    "#                 query_embeddings = model.encode([refer_str], prompt_name=query_prompt_name)\n",
    "#                 doc_embeddings = model.encode(returned_str_ls)\n",
    "#                 cos_scores = cosine_similarity(query_embeddings, doc_embeddings)[0]\n",
    "#                 res_str = \"; \".join([f\"{returned_str_ls[i]} ({cos_scores[i]})\" for i in range(len(returned_str_ls))]) + \";\"\n",
    "#                 res_df_with_cos_batch.loc[res_df_with_cos_batch.sm_id == sm_id, f\"{topic}_phrases\"] = res_str\n",
    "#     return res_df_with_cos_batch\n",
    "\n",
    "# # # Split res_df into 10 batches\n",
    "# # res_df_batches = np.array_split(res_df, 1)\n",
    "\n",
    "# # # Run each batch in parallel using joblib\n",
    "# # results = Parallel(n_jobs=1)(delayed(process_batch)(batch, fea_df) for batch in res_df_batches)\n",
    "\n",
    "# # # Combine results back into the main DataFrame\n",
    "# # res_df_with_cos = pd.concat(results)\n",
    "\n",
    "# # res_df_with_cos = process_batch(res_df, fea_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5301b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_batch(res_df_batch, fea_df, folder, mdl_name, model):\n",
    "    res_df_with_cos_batch = res_df_batch.copy()\n",
    "    sm_id_counter = 0  # Counter to track the number of processed sm_id\n",
    "    \n",
    "    for sm_id in tqdm(res_df_batch.sm_id.unique(), desc=\"Processing sm_id\"):\n",
    "        for topic in fea_df.fea.unique():\n",
    "            refer_str = fea_df.loc[fea_df.fea == topic, 'description'].tolist()[0]\n",
    "            returned_str = res_df_batch.loc[res_df_batch.sm_id == sm_id, f\"{topic}_phrases\"].tolist()[0]\n",
    "            \n",
    "            if returned_str:\n",
    "                returned_str_ls = returned_str.split(\";\")\n",
    "                query_prompt_name = \"s2p_query\"\n",
    "                query_embeddings = model.encode([refer_str], prompt_name=query_prompt_name)\n",
    "                doc_embeddings = model.encode(returned_str_ls)\n",
    "                cos_scores = cosine_similarity(query_embeddings, doc_embeddings)[0]\n",
    "                res_str = \"; \".join([f\"{returned_str_ls[i]} ({cos_scores[i]})\" for i in range(len(returned_str_ls))]) + \";\"\n",
    "                res_df_with_cos_batch.loc[res_df_with_cos_batch.sm_id == sm_id, f\"{topic}_phrases\"] = res_str\n",
    "        \n",
    "        # Increment the counter and check if 1000 sm_id have been processed\n",
    "        sm_id_counter += 1\n",
    "        if sm_id_counter % 1000 == 0:\n",
    "            # Write intermediate results to CSV\n",
    "            output_path = os.path.join(\"../../\", folder, f\"results_with_cos_{mdl_name}.csv\")\n",
    "            res_df_with_cos_batch.to_csv(output_path, index=False)\n",
    "            print(f\"Intermediate results written to {output_path} at {sm_id_counter} sm_id\")\n",
    "    \n",
    "    # Final write to ensure all data is saved at the end\n",
    "    output_path = os.path.join(\"../../\", folder, f\"results_with_cos_{mdl_name}.csv\")\n",
    "    res_df_with_cos_batch.to_csv(output_path, index=False)\n",
    "    print(f\"Final results written to {output_path}\")\n",
    "\n",
    "    #return res_df_with_cos_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2f9872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sm_id:   1%|▏         | 1000/77175 [05:52<30:24:11,  1.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate results written to ../../llama_data/results_with_cos_stella_en_400M_v5.csv at 1000 sm_id\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sm_id:   2%|▏         | 1691/77175 [10:02<10:22:25,  2.02it/s]"
     ]
    }
   ],
   "source": [
    "process_batch(res_df, fea_df, folder, mdl_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3175b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df_with_cos.to_csv(\"../../\"+folder+\"/results_with_cos_\"+mdl_name+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0f2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
