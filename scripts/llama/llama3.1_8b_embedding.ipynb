{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yg9bq/miniconda/ENTER/envs/llama/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"  # Replace with exact path for 8B model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yg9bq/miniconda/ENTER/envs/llama/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:777: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:31<00:00,  7.91s/it]\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (1, 4096)\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,       \n",
    "    output_hidden_states=True,   \n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,     # Use float16 for efficient memory usage on GPU\n",
    "    device_map=None,  # Automatically distribute across devices or use CPU\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# # Example sentence\n",
    "# sentence = \"This is an example sentence.\"\n",
    "\n",
    "# # Tokenize the input sentence\n",
    "# inputs = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "# # Forward pass through the model to get hidden states\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(**inputs)\n",
    "\n",
    "# # Extract the hidden states (embeddings)\n",
    "# hidden_states = outputs.hidden_states  # This returns a tuple with hidden states for each layer\n",
    "\n",
    "# # Get the final layer embeddings (usually the last layer's hidden state)\n",
    "# # hidden_states[-1] gives the final layer's hidden states\n",
    "# sentence_embedding = hidden_states[-1][:, 0, :]  # Usually, the [CLS] token embedding is at position 0\n",
    "\n",
    "# # Convert to numpy or keep as tensor for further processing\n",
    "# embedding = sentence_embedding.cpu().numpy()\n",
    "# print(\"Embedding shape:\", embedding.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "answer_df = pd.read_csv(\"answer_df_new.csv\")\n",
    "query_df = pd.read_csv(\"query_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2.6512e-04, -4.9973e-04, -5.8365e-04,  ...,  3.8147e-03,\n",
       "            6.3419e-05,  1.1902e-03],\n",
       "          [ 1.4191e-03, -3.0212e-03, -2.4414e-03,  ..., -4.7913e-03,\n",
       "            3.8605e-03,  7.4768e-03],\n",
       "          [-1.4404e-02,  1.4526e-02, -1.1597e-02,  ..., -4.2725e-03,\n",
       "           -3.1586e-03, -3.8528e-04],\n",
       "          [-7.0801e-03, -5.4321e-03, -1.3275e-03,  ..., -2.1973e-03,\n",
       "            1.5717e-03,  1.3504e-03]]], dtype=torch.float16),\n",
       " tensor([[[ 0.0022,  0.0041, -0.0007,  ...,  0.0190, -0.0042, -0.0026],\n",
       "          [-0.0166,  0.0094,  0.0166,  ..., -0.0391,  0.0065,  0.0098],\n",
       "          [-0.0106,  0.0027, -0.0029,  ..., -0.0298, -0.0054, -0.0198],\n",
       "          [-0.0007, -0.0083,  0.0069,  ..., -0.0025,  0.0087,  0.0082]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-1.0358e-01,  7.1167e-02, -7.1655e-02,  ...,  8.3691e-01,\n",
       "            1.8140e-01,  1.1584e-01],\n",
       "          [-6.5002e-03,  2.0065e-02,  7.7972e-03,  ..., -3.9368e-02,\n",
       "           -7.5951e-03,  6.3171e-03],\n",
       "          [-9.3918e-03,  1.1475e-02, -3.2539e-03,  ...,  1.1444e-04,\n",
       "            2.5940e-03, -2.8564e-02],\n",
       "          [-1.2466e-02, -2.6947e-02,  1.0025e-02,  ..., -2.5787e-02,\n",
       "            3.1464e-02,  4.7974e-02]]], dtype=torch.float16),\n",
       " tensor([[[-0.1107,  0.0760, -0.0665,  ...,  0.8501,  0.1958,  0.1111],\n",
       "          [-0.0175,  0.0268, -0.0101,  ..., -0.0285, -0.0249, -0.0089],\n",
       "          [ 0.0620, -0.0311, -0.0218,  ...,  0.0398, -0.0307, -0.0626],\n",
       "          [-0.0142, -0.0248,  0.0198,  ...,  0.0569,  0.0365,  0.0282]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-9.0027e-02,  8.8989e-02, -4.6875e-02,  ...,  9.0088e-01,\n",
       "            1.9507e-01,  1.1212e-01],\n",
       "          [-2.7618e-03,  2.5101e-02, -1.8356e-02,  ..., -9.2041e-02,\n",
       "           -2.6794e-02, -1.0889e-01],\n",
       "          [ 6.3721e-02, -3.1281e-03, -6.3629e-03,  ...,  3.7506e-02,\n",
       "           -8.5449e-04, -9.8999e-02],\n",
       "          [ 4.9988e-02,  5.3497e-02,  1.9104e-02,  ...,  6.9885e-02,\n",
       "            2.2659e-02, -1.3184e-02]]], dtype=torch.float16),\n",
       " tensor([[[-0.1133,  0.0892, -0.0452,  ...,  0.8750,  0.2292,  0.1224],\n",
       "          [ 0.0237,  0.0302,  0.0058,  ..., -0.0771, -0.0176, -0.0942],\n",
       "          [ 0.0775,  0.0250, -0.0037,  ...,  0.0149, -0.0178, -0.0758],\n",
       "          [ 0.0685,  0.1011,  0.0395,  ...,  0.0873, -0.0552,  0.0596]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1066,  0.0953, -0.0308,  ...,  0.8657,  0.2460,  0.1300],\n",
       "          [-0.0287,  0.0244,  0.0019,  ..., -0.1461, -0.0096, -0.1010],\n",
       "          [ 0.1313,  0.0096, -0.0718,  ...,  0.0274, -0.0379, -0.0488],\n",
       "          [ 0.0917,  0.0464,  0.0107,  ...,  0.0559, -0.0643,  0.0318]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1127,  0.1150, -0.0218,  ...,  0.8242,  0.2554,  0.1262],\n",
       "          [-0.0283,  0.0144,  0.0565,  ..., -0.1010,  0.0288, -0.0769],\n",
       "          [ 0.1494,  0.0227,  0.0029,  ...,  0.0352, -0.0266, -0.0513],\n",
       "          [ 0.1545,  0.0009,  0.0368,  ...,  0.0144, -0.0079, -0.0211]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.0977,  0.1722, -0.0462,  ...,  0.7607,  0.2494,  0.1537],\n",
       "          [-0.0269, -0.0246,  0.0073,  ..., -0.1328, -0.0897, -0.0840],\n",
       "          [ 0.1143, -0.0447, -0.0291,  ..., -0.0213, -0.0396,  0.0441],\n",
       "          [ 0.1809,  0.0823,  0.0233,  ...,  0.0055,  0.0480,  0.0435]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1060,  0.2051, -0.0317,  ...,  0.6934,  0.2578,  0.1591],\n",
       "          [-0.0413,  0.0319,  0.0401,  ..., -0.1068, -0.0887, -0.1063],\n",
       "          [ 0.1740,  0.0575, -0.0823,  ...,  0.0238, -0.1166, -0.0148],\n",
       "          [ 0.0941,  0.1265, -0.0066,  ..., -0.0345, -0.0514,  0.0277]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-9.3079e-02,  2.2864e-01, -6.0791e-02,  ...,  6.4502e-01,\n",
       "            2.7710e-01,  1.8958e-01],\n",
       "          [-1.1267e-01,  2.1530e-02,  2.2018e-02,  ..., -1.1163e-01,\n",
       "           -2.5574e-02, -1.0815e-01],\n",
       "          [ 1.0187e-01, -3.9673e-04, -5.6122e-02,  ..., -3.9062e-02,\n",
       "           -1.0748e-01, -2.4597e-02],\n",
       "          [-6.0974e-02,  6.6162e-02,  3.1494e-02,  ...,  5.4016e-03,\n",
       "            1.4297e-02,  1.7883e-02]]], dtype=torch.float16),\n",
       " tensor([[[-0.0282,  0.3120, -0.0476,  ...,  0.5269,  0.3083,  0.2068],\n",
       "          [-0.0679, -0.0153,  0.0472,  ..., -0.1061, -0.0020, -0.0696],\n",
       "          [ 0.0264, -0.0808, -0.0074,  ..., -0.1414, -0.0861,  0.0528],\n",
       "          [-0.0776,  0.0283,  0.0446,  ..., -0.0513,  0.0501,  0.0061]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.0387,  0.3384, -0.0891,  ...,  0.5015,  0.3198,  0.2062],\n",
       "          [-0.0414, -0.0116,  0.0077,  ..., -0.1733, -0.0133, -0.0627],\n",
       "          [ 0.0838, -0.0016, -0.0025,  ..., -0.1957,  0.0278,  0.0218],\n",
       "          [-0.0696,  0.0837,  0.0625,  ..., -0.0942,  0.0117, -0.0316]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.0260,  0.3577, -0.0736,  ...,  0.4324,  0.3052,  0.1958],\n",
       "          [-0.0125, -0.0399,  0.0425,  ..., -0.1215, -0.0745,  0.0046],\n",
       "          [ 0.0980,  0.0090, -0.0116,  ..., -0.1249, -0.0043,  0.0687],\n",
       "          [ 0.0112,  0.0230,  0.0870,  ...,  0.0120, -0.0045, -0.0159]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-2.9648e-02,  3.3789e-01, -1.1621e-01,  ...,  3.6108e-01,\n",
       "            2.9395e-01,  2.0435e-01],\n",
       "          [-8.8196e-02, -6.7017e-02,  2.5177e-04,  ..., -1.0980e-01,\n",
       "           -9.4116e-02, -1.6815e-02],\n",
       "          [ 5.5206e-02, -2.9877e-02, -4.2114e-03,  ..., -1.2042e-01,\n",
       "            1.6617e-02,  6.1981e-02],\n",
       "          [-5.1025e-02,  4.4617e-02,  1.4600e-01,  ..., -9.1797e-02,\n",
       "            2.0172e-02,  6.3477e-02]]], dtype=torch.float16),\n",
       " tensor([[[-0.0562,  0.2966, -0.1053,  ...,  0.3625,  0.3315,  0.1210],\n",
       "          [-0.0103, -0.1281, -0.0119,  ..., -0.1555, -0.0591, -0.1547],\n",
       "          [ 0.0051, -0.0585, -0.0369,  ..., -0.1407,  0.0182, -0.0054],\n",
       "          [-0.0611,  0.0472,  0.1276,  ..., -0.0147, -0.0550,  0.1053]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1097,  0.1626, -0.0397,  ...,  0.2827,  0.3721,  0.0828],\n",
       "          [-0.0773, -0.1026,  0.0116,  ..., -0.0800,  0.0108, -0.1704],\n",
       "          [-0.0751, -0.0918, -0.0863,  ..., -0.0844, -0.0442, -0.0423],\n",
       "          [-0.1576,  0.0454,  0.1245,  ...,  0.0712, -0.1294,  0.1188]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1223,  0.1609, -0.0304,  ...,  0.2700,  0.3938,  0.0678],\n",
       "          [-0.1359, -0.1479,  0.0144,  ..., -0.0535, -0.1213, -0.1571],\n",
       "          [ 0.0634, -0.0780, -0.0302,  ..., -0.0025, -0.0731, -0.0922],\n",
       "          [-0.1389,  0.1057,  0.0435,  ...,  0.1462, -0.2886,  0.0893]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1539,  0.1219, -0.0263,  ...,  0.2607,  0.4866,  0.0460],\n",
       "          [-0.0118, -0.1812, -0.0283,  ..., -0.1838, -0.2300, -0.2581],\n",
       "          [-0.0618, -0.0785, -0.0042,  ..., -0.0342, -0.0720, -0.2206],\n",
       "          [-0.1685,  0.1633,  0.1503,  ...,  0.0557, -0.3345,  0.0157]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1727,  0.1170, -0.0122,  ...,  0.2739,  0.4229,  0.0198],\n",
       "          [ 0.0078, -0.1405,  0.0847,  ..., -0.0757, -0.2135, -0.3447],\n",
       "          [-0.1010,  0.0101,  0.0790,  ..., -0.0846,  0.1075, -0.2534],\n",
       "          [-0.1532,  0.1317,  0.1396,  ...,  0.0400, -0.3281,  0.0616]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1814,  0.1221,  0.0140,  ...,  0.2795,  0.4192,  0.0715],\n",
       "          [-0.1089, -0.0557,  0.0845,  ..., -0.1196, -0.2152, -0.5117],\n",
       "          [-0.1597,  0.0093,  0.1779,  ..., -0.1227,  0.1720, -0.1442],\n",
       "          [-0.3247,  0.0682,  0.1465,  ..., -0.0316, -0.3506,  0.1493]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1753,  0.1005,  0.0114,  ...,  0.2668,  0.3713,  0.0851],\n",
       "          [-0.2280,  0.0357, -0.0157,  ..., -0.0443, -0.2776, -0.4465],\n",
       "          [-0.1669, -0.0029,  0.2156,  ..., -0.1102,  0.0722, -0.0586],\n",
       "          [-0.2712,  0.0959,  0.1274,  ..., -0.0157, -0.2622,  0.1013]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1597,  0.0858,  0.0366,  ...,  0.2957,  0.3723,  0.0958],\n",
       "          [-0.3010, -0.0094,  0.0862,  ..., -0.1205, -0.2135, -0.5913],\n",
       "          [-0.2356, -0.0765,  0.3115,  ..., -0.1116, -0.0386, -0.1697],\n",
       "          [-0.3562,  0.0808,  0.1178,  ...,  0.1321, -0.1692, -0.0239]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1294,  0.0717,  0.0328,  ...,  0.3093,  0.3792,  0.0925],\n",
       "          [-0.2673, -0.1354, -0.0621,  ..., -0.2610, -0.2366, -0.5986],\n",
       "          [-0.2805, -0.0051,  0.4133,  ..., -0.2301,  0.0613, -0.1154],\n",
       "          [-0.2920,  0.1426,  0.1609,  ...,  0.1026, -0.1412, -0.0127]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1359,  0.0564, -0.0087,  ...,  0.2925,  0.3364,  0.0728],\n",
       "          [-0.2661, -0.1232,  0.0512,  ..., -0.5176, -0.2114, -0.6768],\n",
       "          [-0.2686, -0.0039,  0.3860,  ..., -0.2161,  0.0194, -0.0582],\n",
       "          [-0.2073,  0.2749,  0.1444,  ...,  0.1727, -0.2341,  0.0305]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1244,  0.0482, -0.0026,  ...,  0.2869,  0.3267,  0.0731],\n",
       "          [-0.3794, -0.1003, -0.0414,  ..., -0.5493, -0.1655, -0.6079],\n",
       "          [-0.2751,  0.1498,  0.3606,  ..., -0.3118,  0.0513, -0.1109],\n",
       "          [-0.2720,  0.4854,  0.2744,  ..., -0.0024, -0.2290,  0.0414]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1276,  0.0256, -0.0354,  ...,  0.3013,  0.3093,  0.0765],\n",
       "          [-0.4404, -0.0344, -0.1354,  ..., -0.4387, -0.0173, -0.5425],\n",
       "          [-0.3264,  0.1460,  0.2661,  ..., -0.3645,  0.1731, -0.0523],\n",
       "          [-0.4814,  0.4875,  0.2722,  ...,  0.1956, -0.0396, -0.0178]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1115,  0.0392, -0.0677,  ...,  0.2749,  0.3499,  0.0597],\n",
       "          [-0.2812, -0.1123, -0.1617,  ..., -0.4431, -0.0529, -0.4744],\n",
       "          [-0.3604,  0.1418,  0.3027,  ..., -0.3164,  0.2126,  0.0117],\n",
       "          [-0.4944,  0.6450,  0.2664,  ...,  0.2317, -0.0912,  0.0763]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1043,  0.0510, -0.0098,  ...,  0.3059,  0.3914,  0.0903],\n",
       "          [-0.0920, -0.0451, -0.0413,  ..., -0.3618,  0.0526, -0.6084],\n",
       "          [-0.4182,  0.0588,  0.2620,  ..., -0.5088,  0.3296, -0.1741],\n",
       "          [-0.4836,  0.6553,  0.3184,  ...,  0.0840, -0.2450, -0.1171]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.0663,  0.1077, -0.0153,  ...,  0.3149,  0.3853,  0.1373],\n",
       "          [-0.1683, -0.0192,  0.0759,  ..., -0.5991,  0.2590, -0.5347],\n",
       "          [-0.5771, -0.1246,  0.4075,  ..., -0.5977,  0.4951, -0.1365],\n",
       "          [-0.6650,  0.4424,  0.2693,  ...,  0.2048,  0.2178,  0.0879]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[ 0.0542,  0.1689,  0.1012,  ...,  0.2432,  0.2373,  0.1093],\n",
       "          [-0.1619,  0.0695,  0.0333,  ..., -0.4944,  0.3477, -0.4729],\n",
       "          [-0.6592, -0.2803,  0.3286,  ..., -0.5015,  0.5229, -0.1182],\n",
       "          [-0.8560,  0.3997,  0.2457,  ...,  0.1398, -0.0139,  0.2368]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[ 0.1638,  0.4131,  0.1747,  ...,  0.2773, -0.0859,  0.2839],\n",
       "          [-0.3518, -0.1389, -0.1600,  ...,  0.0081, -0.0265, -1.1172],\n",
       "          [-0.7881, -0.4717,  0.2625,  ..., -0.9946,  0.8745, -0.5640],\n",
       "          [-0.6084,  0.5503,  0.0481,  ..., -0.3389, -0.0092, -0.3850]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[ 1.3340,  2.7812,  1.6416,  ..., -1.9473,  2.7539,  1.9336],\n",
       "          [-2.1016, -0.3083, -2.6211,  ..., -0.4199,  1.4199,  0.0174],\n",
       "          [-0.8735, -0.8325, -0.0764,  ..., -3.2598,  2.0352,  0.6479],\n",
       "          [-1.2490, -0.4902,  1.0850,  ..., -1.6309,  0.7241,  0.2242]]],\n",
       "        dtype=torch.float16))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"i hate you\"\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "hidden_states = outputs.hidden_states  # This returns a tuple with hidden states for each layer\n",
    "hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2.6512e-04, -4.9973e-04, -5.8365e-04,  ...,  3.8147e-03,\n",
       "            6.3419e-05,  1.1902e-03],\n",
       "          [ 1.4191e-03, -3.0212e-03, -2.4414e-03,  ..., -4.7913e-03,\n",
       "            3.8605e-03,  7.4768e-03],\n",
       "          [-6.3477e-03, -6.7139e-03, -1.5945e-03,  ..., -5.3711e-03,\n",
       "           -7.0801e-03, -2.3079e-04],\n",
       "          [-7.0801e-03, -5.4321e-03, -1.3275e-03,  ..., -2.1973e-03,\n",
       "            1.5717e-03,  1.3504e-03],\n",
       "          [-1.5442e-02, -1.7929e-04,  5.8899e-03,  ..., -5.7068e-03,\n",
       "           -1.1719e-02, -6.7444e-03]]], dtype=torch.float16),\n",
       " tensor([[[ 0.0022,  0.0041, -0.0007,  ...,  0.0190, -0.0042, -0.0026],\n",
       "          [-0.0166,  0.0094,  0.0166,  ..., -0.0391,  0.0065,  0.0098],\n",
       "          [-0.0013,  0.0057,  0.0136,  ..., -0.0254, -0.0064, -0.0138],\n",
       "          [-0.0037,  0.0010,  0.0025,  ...,  0.0082,  0.0029,  0.0141],\n",
       "          [-0.0346, -0.0188, -0.0007,  ..., -0.0074,  0.0012,  0.0092]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-1.0358e-01,  7.1167e-02, -7.1655e-02,  ...,  8.3691e-01,\n",
       "            1.8140e-01,  1.1584e-01],\n",
       "          [-6.5002e-03,  2.0065e-02,  7.7972e-03,  ..., -3.9368e-02,\n",
       "           -7.5951e-03,  6.3171e-03],\n",
       "          [ 2.8442e-02, -1.0910e-03,  4.4250e-02,  ...,  1.1551e-02,\n",
       "           -7.6599e-03, -3.9673e-03],\n",
       "          [-1.5839e-02, -1.3931e-02,  1.3779e-02,  ...,  2.3468e-02,\n",
       "            1.8463e-02,  5.4535e-02],\n",
       "          [-4.1229e-02, -1.2512e-02, -4.1428e-03,  ...,  2.7130e-02,\n",
       "            2.9564e-04,  2.8564e-02]]], dtype=torch.float16),\n",
       " tensor([[[-0.1107,  0.0760, -0.0665,  ...,  0.8501,  0.1958,  0.1111],\n",
       "          [-0.0175,  0.0268, -0.0101,  ..., -0.0285, -0.0249, -0.0089],\n",
       "          [ 0.0455, -0.0460,  0.0482,  ...,  0.0555, -0.0445,  0.0021],\n",
       "          [ 0.0022,  0.0219,  0.0675,  ...,  0.1141,  0.0240,  0.0276],\n",
       "          [-0.0966,  0.0144,  0.0138,  ...,  0.0904, -0.0145,  0.0168]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.0900,  0.0890, -0.0469,  ...,  0.9009,  0.1951,  0.1121],\n",
       "          [-0.0028,  0.0251, -0.0184,  ..., -0.0920, -0.0268, -0.1089],\n",
       "          [ 0.0765, -0.0453,  0.0640,  ...,  0.0871, -0.0367, -0.0637],\n",
       "          [ 0.0609,  0.0685,  0.0696,  ...,  0.1196, -0.0020, -0.0284],\n",
       "          [-0.1208,  0.0175, -0.0547,  ...,  0.0908, -0.0968, -0.0410]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1133,  0.0892, -0.0452,  ...,  0.8750,  0.2292,  0.1224],\n",
       "          [ 0.0237,  0.0302,  0.0058,  ..., -0.0771, -0.0176, -0.0942],\n",
       "          [ 0.0550, -0.0078,  0.0329,  ...,  0.1057, -0.0443, -0.0534],\n",
       "          [ 0.0667,  0.1163,  0.1075,  ...,  0.2025, -0.1025,  0.0137],\n",
       "          [-0.0951,  0.0936, -0.0316,  ...,  0.1396, -0.1301,  0.0057]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1066,  0.0953, -0.0308,  ...,  0.8657,  0.2460,  0.1300],\n",
       "          [-0.0287,  0.0244,  0.0019,  ..., -0.1461, -0.0096, -0.1010],\n",
       "          [ 0.1125, -0.0172, -0.0010,  ...,  0.0968, -0.0444,  0.0031],\n",
       "          [ 0.1207,  0.1294,  0.0648,  ...,  0.2532, -0.0538,  0.0447],\n",
       "          [-0.0590,  0.0875, -0.0335,  ...,  0.1304, -0.0577,  0.0318]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1127,  0.1150, -0.0218,  ...,  0.8242,  0.2554,  0.1262],\n",
       "          [-0.0283,  0.0144,  0.0565,  ..., -0.1010,  0.0288, -0.0769],\n",
       "          [ 0.1514, -0.0073,  0.0267,  ...,  0.1116, -0.0502,  0.0239],\n",
       "          [ 0.1549,  0.0671,  0.1218,  ...,  0.2654, -0.0154,  0.0231],\n",
       "          [ 0.0403,  0.0804,  0.0369,  ...,  0.1669, -0.0940, -0.0402]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.0977,  0.1722, -0.0462,  ...,  0.7607,  0.2494,  0.1537],\n",
       "          [-0.0269, -0.0246,  0.0073,  ..., -0.1328, -0.0897, -0.0840],\n",
       "          [ 0.1367, -0.0539,  0.0048,  ...,  0.0289, -0.0623,  0.0817],\n",
       "          [ 0.2067,  0.1296,  0.0825,  ...,  0.2192,  0.0171,  0.0836],\n",
       "          [ 0.1113, -0.0009,  0.0377,  ...,  0.0403, -0.1544,  0.0775]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1060,  0.2051, -0.0317,  ...,  0.6934,  0.2578,  0.1591],\n",
       "          [-0.0413,  0.0319,  0.0401,  ..., -0.1068, -0.0887, -0.1063],\n",
       "          [ 0.1548,  0.0026,  0.0063,  ...,  0.0637, -0.1263,  0.0038],\n",
       "          [ 0.1903,  0.1774,  0.0131,  ...,  0.2074, -0.0182,  0.0520],\n",
       "          [ 0.0707,  0.0614, -0.0475,  ...,  0.0440, -0.0902,  0.0257]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.0931,  0.2286, -0.0608,  ...,  0.6450,  0.2771,  0.1896],\n",
       "          [-0.1127,  0.0215,  0.0220,  ..., -0.1116, -0.0256, -0.1082],\n",
       "          [ 0.1620, -0.0809,  0.0412,  ..., -0.0112, -0.1023, -0.0368],\n",
       "          [ 0.0898,  0.1365,  0.0609,  ...,  0.1804, -0.0511,  0.0034],\n",
       "          [-0.0065,  0.0919,  0.0737,  ...,  0.1016, -0.1085, -0.0161]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.0282,  0.3120, -0.0476,  ...,  0.5269,  0.3083,  0.2068],\n",
       "          [-0.0679, -0.0153,  0.0472,  ..., -0.1061, -0.0020, -0.0696],\n",
       "          [ 0.1720, -0.1372,  0.0856,  ..., -0.0654, -0.1042,  0.0095],\n",
       "          [ 0.0488,  0.0138,  0.0557,  ...,  0.1008, -0.0626, -0.0582],\n",
       "          [-0.0053,  0.0584,  0.0021,  ..., -0.0064, -0.0723, -0.0087]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.0387,  0.3384, -0.0891,  ...,  0.5015,  0.3198,  0.2062],\n",
       "          [-0.0414, -0.0116,  0.0077,  ..., -0.1733, -0.0133, -0.0627],\n",
       "          [ 0.1848, -0.1006,  0.0325,  ..., -0.1108, -0.0317, -0.0180],\n",
       "          [-0.0123,  0.0262,  0.0220,  ...,  0.0374, -0.0627, -0.1116],\n",
       "          [ 0.0252,  0.1235,  0.0344,  ..., -0.1019, -0.0508,  0.0385]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.0260,  0.3577, -0.0736,  ...,  0.4324,  0.3052,  0.1958],\n",
       "          [-0.0125, -0.0399,  0.0425,  ..., -0.1215, -0.0745,  0.0046],\n",
       "          [ 0.1389, -0.0971,  0.0342,  ..., -0.0646, -0.0343,  0.0482],\n",
       "          [ 0.1062,  0.0385,  0.0518,  ...,  0.0851, -0.0588, -0.0479],\n",
       "          [-0.0215,  0.0504,  0.0150,  ..., -0.0610, -0.1143, -0.0007]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-2.9648e-02,  3.3789e-01, -1.1621e-01,  ...,  3.6108e-01,\n",
       "            2.9395e-01,  2.0435e-01],\n",
       "          [-8.8196e-02, -6.7017e-02,  2.5177e-04,  ..., -1.0980e-01,\n",
       "           -9.4116e-02, -1.6815e-02],\n",
       "          [ 7.8247e-02, -6.1615e-02, -1.1871e-02,  ..., -1.4496e-02,\n",
       "           -6.9427e-04,  1.9165e-02],\n",
       "          [ 8.0566e-03,  5.3528e-02,  1.0413e-01,  ...,  4.5959e-02,\n",
       "           -4.1626e-02,  5.9814e-03],\n",
       "          [-6.2866e-02,  7.1106e-02,  4.2328e-02,  ..., -3.6011e-03,\n",
       "           -1.7004e-01,  4.6997e-02]]], dtype=torch.float16),\n",
       " tensor([[[-0.0562,  0.2966, -0.1053,  ...,  0.3625,  0.3315,  0.1210],\n",
       "          [-0.0103, -0.1281, -0.0119,  ..., -0.1555, -0.0591, -0.1547],\n",
       "          [ 0.0415, -0.0657, -0.0450,  ...,  0.0177,  0.0166, -0.0697],\n",
       "          [ 0.0246,  0.0278,  0.0439,  ...,  0.1021, -0.0950,  0.0321],\n",
       "          [-0.1031,  0.0235,  0.0980,  ...,  0.0743, -0.1144, -0.0110]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-1.0974e-01,  1.6260e-01, -3.9734e-02,  ...,  2.8271e-01,\n",
       "            3.7207e-01,  8.2764e-02],\n",
       "          [-7.7271e-02, -1.0260e-01,  1.1627e-02,  ..., -8.0017e-02,\n",
       "            1.0834e-02, -1.7041e-01],\n",
       "          [-1.7242e-02, -2.2388e-01, -4.3579e-02,  ...,  2.8412e-02,\n",
       "           -6.8726e-02, -2.7328e-02],\n",
       "          [-2.5940e-04, -1.3931e-02,  1.1963e-02,  ...,  1.5723e-01,\n",
       "           -1.7542e-01,  8.0750e-02],\n",
       "          [-7.3242e-02, -4.5074e-02,  9.9121e-02,  ...,  1.2006e-01,\n",
       "           -2.6074e-01,  1.3965e-01]]], dtype=torch.float16),\n",
       " tensor([[[-0.1223,  0.1609, -0.0304,  ...,  0.2700,  0.3938,  0.0678],\n",
       "          [-0.1359, -0.1479,  0.0144,  ..., -0.0535, -0.1213, -0.1571],\n",
       "          [ 0.0473, -0.2756, -0.1087,  ...,  0.1136, -0.1313, -0.0571],\n",
       "          [-0.0059, -0.0382, -0.1713,  ...,  0.3013, -0.3491,  0.0201],\n",
       "          [-0.0175, -0.1992, -0.0402,  ...,  0.1997, -0.4358,  0.1920]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1539,  0.1219, -0.0263,  ...,  0.2607,  0.4866,  0.0460],\n",
       "          [-0.0118, -0.1812, -0.0283,  ..., -0.1838, -0.2300, -0.2581],\n",
       "          [-0.0241, -0.3010, -0.0336,  ...,  0.0479, -0.2036, -0.2208],\n",
       "          [ 0.0511,  0.0433,  0.0024,  ...,  0.1635, -0.4785,  0.0362],\n",
       "          [-0.1578, -0.0759,  0.0318,  ...,  0.2632, -0.4297,  0.1862]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1727,  0.1170, -0.0122,  ...,  0.2739,  0.4229,  0.0198],\n",
       "          [ 0.0078, -0.1405,  0.0847,  ..., -0.0757, -0.2135, -0.3447],\n",
       "          [-0.0627, -0.3337,  0.0235,  ...,  0.0909, -0.0837, -0.3174],\n",
       "          [ 0.0396,  0.0074, -0.0442,  ...,  0.1309, -0.4395, -0.0133],\n",
       "          [-0.1193, -0.1052, -0.1577,  ...,  0.1973, -0.3008,  0.2881]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1814,  0.1221,  0.0140,  ...,  0.2795,  0.4192,  0.0715],\n",
       "          [-0.1089, -0.0557,  0.0845,  ..., -0.1196, -0.2152, -0.5117],\n",
       "          [ 0.0139, -0.3035,  0.0892,  ...,  0.0836, -0.0398, -0.2773],\n",
       "          [-0.0272, -0.0517,  0.1078,  ...,  0.0263, -0.4783, -0.0853],\n",
       "          [-0.1113, -0.1160, -0.0873,  ...,  0.2551, -0.3682,  0.3210]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1753,  0.1005,  0.0114,  ...,  0.2668,  0.3713,  0.0851],\n",
       "          [-0.2280,  0.0357, -0.0157,  ..., -0.0443, -0.2776, -0.4465],\n",
       "          [-0.0656, -0.4380,  0.1412,  ...,  0.0786, -0.0804, -0.1769],\n",
       "          [-0.1239, -0.0360,  0.0061,  ...,  0.0547, -0.4404, -0.0406],\n",
       "          [-0.2939, -0.0327, -0.1484,  ...,  0.2390, -0.3228,  0.2959]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1597,  0.0858,  0.0366,  ...,  0.2957,  0.3723,  0.0958],\n",
       "          [-0.3010, -0.0094,  0.0862,  ..., -0.1205, -0.2135, -0.5913],\n",
       "          [-0.0892, -0.5747,  0.2039,  ...,  0.1332, -0.1068, -0.3103],\n",
       "          [-0.2390, -0.0714,  0.0198,  ...,  0.1193, -0.4927, -0.0183],\n",
       "          [-0.3418, -0.1399, -0.0663,  ...,  0.0875, -0.4697,  0.2864]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1294,  0.0717,  0.0328,  ...,  0.3093,  0.3792,  0.0925],\n",
       "          [-0.2673, -0.1354, -0.0621,  ..., -0.2610, -0.2366, -0.5986],\n",
       "          [-0.0950, -0.5234,  0.2427,  ...,  0.0511, -0.0325, -0.2056],\n",
       "          [-0.1749, -0.1311,  0.1469,  ...,  0.0267, -0.3994, -0.1043],\n",
       "          [-0.1038, -0.1471,  0.1334,  ...,  0.0411, -0.3230,  0.2793]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1359,  0.0564, -0.0087,  ...,  0.2925,  0.3364,  0.0728],\n",
       "          [-0.2661, -0.1232,  0.0512,  ..., -0.5176, -0.2114, -0.6768],\n",
       "          [-0.0817, -0.5078,  0.2749,  ...,  0.0766, -0.0683, -0.0874],\n",
       "          [-0.1191, -0.0691,  0.1062,  ...,  0.1592, -0.5605, -0.0747],\n",
       "          [-0.2798, -0.2161,  0.1943,  ...,  0.1027, -0.3765,  0.2725]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1244,  0.0482, -0.0026,  ...,  0.2869,  0.3267,  0.0731],\n",
       "          [-0.3794, -0.1003, -0.0414,  ..., -0.5493, -0.1655, -0.6079],\n",
       "          [-0.2393, -0.4136,  0.2747,  ...,  0.0133, -0.0187, -0.1074],\n",
       "          [-0.3137,  0.0554,  0.1548,  ...,  0.0739, -0.5537,  0.0223],\n",
       "          [-0.3945,  0.0391,  0.3525,  ...,  0.0359, -0.4470,  0.3137]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1276,  0.0256, -0.0354,  ...,  0.3013,  0.3093,  0.0765],\n",
       "          [-0.4404, -0.0344, -0.1354,  ..., -0.4387, -0.0173, -0.5425],\n",
       "          [-0.3167, -0.3459,  0.2386,  ..., -0.0298,  0.1194, -0.1031],\n",
       "          [-0.5376, -0.0133, -0.0203,  ...,  0.1807, -0.3516,  0.0472],\n",
       "          [-0.5176,  0.1129,  0.2512,  ...,  0.0838, -0.4097,  0.3320]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1115,  0.0392, -0.0677,  ...,  0.2749,  0.3499,  0.0597],\n",
       "          [-0.2812, -0.1123, -0.1617,  ..., -0.4431, -0.0529, -0.4744],\n",
       "          [-0.2262, -0.2744,  0.2869,  ...,  0.0233,  0.0828, -0.1328],\n",
       "          [-0.6084,  0.1710,  0.0224,  ...,  0.2959, -0.3850, -0.0652],\n",
       "          [-0.6875,  0.3584,  0.3459,  ...,  0.0599, -0.3745,  0.3093]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.1043,  0.0510, -0.0098,  ...,  0.3059,  0.3914,  0.0903],\n",
       "          [-0.0920, -0.0451, -0.0413,  ..., -0.3618,  0.0526, -0.6084],\n",
       "          [-0.2361, -0.3413,  0.1670,  ..., -0.0480,  0.0201, -0.2749],\n",
       "          [-0.5317,  0.2422, -0.1157,  ...,  0.3052, -0.6045, -0.1382],\n",
       "          [-0.7256,  0.3530,  0.4443,  ...,  0.2200, -0.5552,  0.2377]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[-0.0663,  0.1077, -0.0153,  ...,  0.3149,  0.3853,  0.1373],\n",
       "          [-0.1683, -0.0192,  0.0759,  ..., -0.5991,  0.2590, -0.5347],\n",
       "          [-0.4824, -0.4321,  0.3308,  ..., -0.1232,  0.1534, -0.1996],\n",
       "          [-0.7930,  0.0883,  0.0542,  ...,  0.4199, -0.1963, -0.1068],\n",
       "          [-0.9214,  0.3599,  0.6836,  ...,  0.3286, -0.3169,  0.3506]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[ 0.0542,  0.1689,  0.1012,  ...,  0.2432,  0.2373,  0.1093],\n",
       "          [-0.1619,  0.0695,  0.0333,  ..., -0.4944,  0.3477, -0.4729],\n",
       "          [-0.4863, -0.5889,  0.2351,  ..., -0.0828,  0.1255, -0.1274],\n",
       "          [-0.9805, -0.0211,  0.0401,  ...,  0.6934, -0.3237,  0.0165],\n",
       "          [-0.9097,  0.2390,  0.3372,  ...,  0.5273, -0.3750,  0.5503]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[ 0.1638,  0.4131,  0.1747,  ...,  0.2773, -0.0859,  0.2839],\n",
       "          [-0.3518, -0.1389, -0.1600,  ...,  0.0081, -0.0265, -1.1172],\n",
       "          [-0.6533, -0.9116,  0.0151,  ..., -0.5024,  0.2808, -0.4272],\n",
       "          [-0.5947,  0.0716, -0.0874,  ...,  0.2197, -0.2041, -0.6797],\n",
       "          [-0.6445,  0.1707,  0.2766,  ...,  0.0244, -0.0908, -0.2061]]],\n",
       "        dtype=torch.float16),\n",
       " tensor([[[ 1.3340,  2.7812,  1.6416,  ..., -1.9473,  2.7539,  1.9336],\n",
       "          [-2.1016, -0.3083, -2.6211,  ..., -0.4199,  1.4199,  0.0174],\n",
       "          [-0.4412, -1.7256,  0.3630,  ..., -1.7695,  1.0332, -0.6167],\n",
       "          [-1.4561, -0.2412,  2.7539,  ..., -0.1048,  0.3694, -1.0039],\n",
       "          [-1.7520, -0.0274,  2.4023,  ...,  0.5679, -0.4932,  0.5752]]],\n",
       "        dtype=torch.float16))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"i love you too\"\n",
    "inputs = tokenizer(text, return_tensors='pt')\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "hidden_states = outputs.hidden_states  # This returns a tuple with hidden states for each layer\n",
    "hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 4096])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding = hidden_states[-1][:, :, :]  #  each word has an embedding vector\n",
    "sentence_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.334  ,  2.781  ,  1.642  , ..., -1.947  ,  2.754  ,  1.934  ],\n",
       "       [-2.102  , -0.3083 , -2.621  , ..., -0.42   ,  1.42   ,  0.01744],\n",
       "       [-0.4412 , -1.726  ,  0.363  , ..., -1.77   ,  1.033  , -0.6167 ],\n",
       "       [-1.456  , -0.2412 ,  2.754  , ..., -0.1048 ,  0.3694 , -1.004  ]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embedding = hidden_states[-1][:, :, :]  # Usually, the [CLS] token embedding is at position 0\n",
    "\n",
    "# print the shape of sentence_embedding\n",
    "\n",
    "    # Convert to numpy or keep as tensor for further processing\n",
    "embedding = sentence_embedding.cpu().numpy()\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.333984375,\n",
       " 2.78125,\n",
       " 1.6416015625,\n",
       " 2.822265625,\n",
       " 3.421875,\n",
       " 1.892578125,\n",
       " -1.2197265625,\n",
       " -0.6943359375,\n",
       " -1.8876953125,\n",
       " 1.5185546875,\n",
       " -0.8837890625,\n",
       " -0.218505859375,\n",
       " 2.1484375,\n",
       " -2.9375,\n",
       " -0.88134765625,\n",
       " -1.1103515625,\n",
       " 0.85302734375,\n",
       " 0.98291015625,\n",
       " -2.69921875,\n",
       " -3.388671875,\n",
       " -2.541015625,\n",
       " 0.94091796875,\n",
       " -3.53125,\n",
       " 3.23828125,\n",
       " 0.77001953125,\n",
       " -0.33984375,\n",
       " 0.33984375,\n",
       " 1.39453125,\n",
       " -2.09375,\n",
       " 0.48095703125,\n",
       " -0.035400390625,\n",
       " -0.397705078125,\n",
       " 2.55859375,\n",
       " -3.021484375,\n",
       " -3.400390625,\n",
       " -0.274658203125,\n",
       " 0.11468505859375,\n",
       " -2.0234375,\n",
       " 1.0048828125,\n",
       " -4.5234375,\n",
       " 3.62109375,\n",
       " -2.140625,\n",
       " 1.4072265625,\n",
       " 1.3134765625,\n",
       " -0.99755859375,\n",
       " 3.08203125,\n",
       " 2.177734375,\n",
       " -0.66455078125,\n",
       " 2.8671875,\n",
       " -0.2113037109375,\n",
       " -2.9921875,\n",
       " 1.447265625,\n",
       " 1.4169921875,\n",
       " -0.240478515625,\n",
       " -1.1865234375,\n",
       " 1.2724609375,\n",
       " -1.6123046875,\n",
       " -0.830078125,\n",
       " 0.58544921875,\n",
       " -1.13671875,\n",
       " 1.1943359375,\n",
       " -1.552734375,\n",
       " -0.54541015625,\n",
       " -1.421875,\n",
       " 3.421875,\n",
       " 2.59375,\n",
       " -1.3896484375,\n",
       " -2.201171875,\n",
       " -0.05712890625,\n",
       " 0.438232421875,\n",
       " 1.103515625,\n",
       " 1.9111328125,\n",
       " 1.318359375,\n",
       " -1.5751953125,\n",
       " -2.775390625,\n",
       " 1.212890625,\n",
       " 2.5078125,\n",
       " -2.3359375,\n",
       " -0.171875,\n",
       " 2.44140625,\n",
       " 1.8408203125,\n",
       " 2.716796875,\n",
       " 0.07098388671875,\n",
       " 1.41015625,\n",
       " -3.990234375,\n",
       " 0.74267578125,\n",
       " -2.029296875,\n",
       " 1.62109375,\n",
       " -3.041015625,\n",
       " -1.1767578125,\n",
       " -1.5166015625,\n",
       " -4.0625,\n",
       " 0.352783203125,\n",
       " -0.697265625,\n",
       " -1.37109375,\n",
       " -0.43310546875,\n",
       " -3.595703125,\n",
       " -2.1796875,\n",
       " -1.013671875,\n",
       " -2.279296875,\n",
       " -5.2734375,\n",
       " -2.86328125,\n",
       " 0.6962890625,\n",
       " 4.09765625,\n",
       " -0.83349609375,\n",
       " 1.017578125,\n",
       " 1.8193359375,\n",
       " 0.25048828125,\n",
       " -0.8349609375,\n",
       " 2.08203125,\n",
       " 3.5859375,\n",
       " 3.923828125,\n",
       " -0.8134765625,\n",
       " -2.673828125,\n",
       " 0.35107421875,\n",
       " -1.1591796875,\n",
       " -0.51220703125,\n",
       " 0.126953125,\n",
       " -2.015625,\n",
       " 2.34375,\n",
       " 2.939453125,\n",
       " 0.90673828125,\n",
       " 1.0830078125,\n",
       " -2.642578125,\n",
       " -0.145751953125,\n",
       " -2.521484375,\n",
       " 0.96435546875,\n",
       " 0.47802734375,\n",
       " -1.3623046875,\n",
       " -1.6806640625,\n",
       " 0.64306640625,\n",
       " 0.0745849609375,\n",
       " -1.7763671875,\n",
       " 3.38671875,\n",
       " -1.9150390625,\n",
       " -3.15625,\n",
       " -3.435546875,\n",
       " 3.91015625,\n",
       " -0.040069580078125,\n",
       " -1.392578125,\n",
       " 1.4033203125,\n",
       " -0.77294921875,\n",
       " 0.281982421875,\n",
       " -2.728515625,\n",
       " -0.005626678466796875,\n",
       " 1.044921875,\n",
       " -1.4921875,\n",
       " -0.020477294921875,\n",
       " -1.3037109375,\n",
       " 1.59765625,\n",
       " 0.359375,\n",
       " 0.83056640625,\n",
       " 2.72265625,\n",
       " 1.21875,\n",
       " 2.236328125,\n",
       " 0.248046875,\n",
       " -1.2353515625,\n",
       " 4.16015625,\n",
       " -0.841796875,\n",
       " -3.01953125,\n",
       " -0.54833984375,\n",
       " -2.71484375,\n",
       " -0.52099609375,\n",
       " -1.3388671875,\n",
       " -0.7001953125,\n",
       " -0.51318359375,\n",
       " -2.205078125,\n",
       " 2.404296875,\n",
       " 0.8701171875,\n",
       " -3.3203125,\n",
       " 0.6240234375,\n",
       " -4.015625,\n",
       " 3.939453125,\n",
       " -0.62060546875,\n",
       " 1.1240234375,\n",
       " 0.1055908203125,\n",
       " 0.580078125,\n",
       " -0.86083984375,\n",
       " -1.8349609375,\n",
       " 0.11370849609375,\n",
       " -0.978515625,\n",
       " 2.85546875,\n",
       " 0.0310821533203125,\n",
       " 1.9951171875,\n",
       " 5.015625,\n",
       " -0.744140625,\n",
       " -1.22265625,\n",
       " -2.55859375,\n",
       " 1.24609375,\n",
       " 0.005809783935546875,\n",
       " -2.537109375,\n",
       " 2.353515625,\n",
       " -1.9072265625,\n",
       " -3.408203125,\n",
       " 3.7109375,\n",
       " 1.849609375,\n",
       " -3.837890625,\n",
       " -1.3349609375,\n",
       " -1.3505859375,\n",
       " -0.6484375,\n",
       " -1.0712890625,\n",
       " 1.474609375,\n",
       " -0.360595703125,\n",
       " 3.07421875,\n",
       " -3.49609375,\n",
       " -5.5546875,\n",
       " -1.9697265625,\n",
       " -2.22265625,\n",
       " -3.611328125,\n",
       " -1.17578125,\n",
       " -2.275390625,\n",
       " 1.80078125,\n",
       " -0.1971435546875,\n",
       " -0.57861328125,\n",
       " -10.78125,\n",
       " -0.62158203125,\n",
       " -0.2607421875,\n",
       " 1.9150390625,\n",
       " 0.95947265625,\n",
       " -0.79931640625,\n",
       " -0.14990234375,\n",
       " 0.7255859375,\n",
       " -1.0009765625,\n",
       " 0.634765625,\n",
       " -0.44677734375,\n",
       " -2.240234375,\n",
       " 4.83203125,\n",
       " -1.7568359375,\n",
       " 1.634765625,\n",
       " -4.58203125,\n",
       " 1.501953125,\n",
       " -1.5791015625,\n",
       " 2.037109375,\n",
       " -2.28515625,\n",
       " -2.56640625,\n",
       " -2.296875,\n",
       " 1.298828125,\n",
       " 1.70703125,\n",
       " 0.76171875,\n",
       " -2.841796875,\n",
       " 0.9755859375,\n",
       " 1.5,\n",
       " 1.2880859375,\n",
       " -1.037109375,\n",
       " -0.2041015625,\n",
       " -0.33544921875,\n",
       " 3.60546875,\n",
       " -1.9716796875,\n",
       " 2.05078125,\n",
       " 0.6689453125,\n",
       " -3.3671875,\n",
       " 3.412109375,\n",
       " -3.74609375,\n",
       " 1.2119140625,\n",
       " 1.095703125,\n",
       " 0.84521484375,\n",
       " -2.232421875,\n",
       " -1.685546875,\n",
       " 0.6533203125,\n",
       " -1.755859375,\n",
       " 2.33203125,\n",
       " -0.666015625,\n",
       " -5.015625,\n",
       " -4.45703125,\n",
       " -0.5078125,\n",
       " 3.6171875,\n",
       " -0.400634765625,\n",
       " -2.896484375,\n",
       " 1.041015625,\n",
       " -1.216796875,\n",
       " -1.046875,\n",
       " -0.255126953125,\n",
       " -2.87890625,\n",
       " 0.5869140625,\n",
       " -0.0616455078125,\n",
       " -2.25390625,\n",
       " -2.826171875,\n",
       " -3.935546875,\n",
       " -0.8408203125,\n",
       " 1.4228515625,\n",
       " 0.196533203125,\n",
       " 3.67578125,\n",
       " -2.634765625,\n",
       " -0.564453125,\n",
       " -3.1953125,\n",
       " -2.908203125,\n",
       " 4.40234375,\n",
       " 3.630859375,\n",
       " -0.355712890625,\n",
       " 0.6044921875,\n",
       " 1.630859375,\n",
       " -0.92138671875,\n",
       " 2.6875,\n",
       " 1.3818359375,\n",
       " 4.50390625,\n",
       " -0.68310546875,\n",
       " 0.1097412109375,\n",
       " -2.25390625,\n",
       " -2.0,\n",
       " -0.50146484375,\n",
       " -1.2392578125,\n",
       " -0.052215576171875,\n",
       " 0.6435546875,\n",
       " 1.640625,\n",
       " 0.72998046875,\n",
       " -2.544921875,\n",
       " -2.771484375,\n",
       " 0.489013671875,\n",
       " 0.85400390625,\n",
       " 2.619140625,\n",
       " -1.9521484375,\n",
       " -1.8203125,\n",
       " 0.1405029296875,\n",
       " -0.9443359375,\n",
       " -1.365234375,\n",
       " -1.1943359375,\n",
       " 2.439453125,\n",
       " 3.765625,\n",
       " -1.775390625,\n",
       " 4.34375,\n",
       " -0.1956787109375,\n",
       " 1.9658203125,\n",
       " -1.568359375,\n",
       " -0.1910400390625,\n",
       " -3.818359375,\n",
       " -0.8916015625,\n",
       " 3.501953125,\n",
       " 2.138671875,\n",
       " -2.0078125,\n",
       " -0.2481689453125,\n",
       " -0.83447265625,\n",
       " 1.5927734375,\n",
       " 3.158203125,\n",
       " 1.42578125,\n",
       " -0.59033203125,\n",
       " 0.45458984375,\n",
       " 0.8857421875,\n",
       " 2.337890625,\n",
       " -0.265625,\n",
       " -2.6328125,\n",
       " 0.496337890625,\n",
       " -0.5791015625,\n",
       " -1.5322265625,\n",
       " -1.5,\n",
       " 0.67626953125,\n",
       " -2.26171875,\n",
       " -1.6708984375,\n",
       " 4.40625,\n",
       " 1.2109375,\n",
       " -0.1925048828125,\n",
       " 2.310546875,\n",
       " -0.6337890625,\n",
       " -1.291015625,\n",
       " 1.4189453125,\n",
       " -0.51318359375,\n",
       " -3.638671875,\n",
       " 0.52978515625,\n",
       " 1.5380859375,\n",
       " -1.373046875,\n",
       " 1.373046875,\n",
       " -2.240234375,\n",
       " 2.13671875,\n",
       " 0.54833984375,\n",
       " 2.1953125,\n",
       " 0.8046875,\n",
       " 1.333984375,\n",
       " -2.216796875,\n",
       " -0.59912109375,\n",
       " 0.57861328125,\n",
       " -1.3095703125,\n",
       " 1.9072265625,\n",
       " 0.205322265625,\n",
       " 2.84765625,\n",
       " 0.233642578125,\n",
       " -0.572265625,\n",
       " 2.212890625,\n",
       " -5.078125,\n",
       " -0.93505859375,\n",
       " -1.5166015625,\n",
       " 1.4365234375,\n",
       " -1.490234375,\n",
       " 1.8017578125,\n",
       " 2.986328125,\n",
       " 1.6142578125,\n",
       " 2.90234375,\n",
       " 1.849609375,\n",
       " -1.166015625,\n",
       " -2.5546875,\n",
       " 3.69921875,\n",
       " -0.06512451171875,\n",
       " -1.515625,\n",
       " -0.712890625,\n",
       " -1.1865234375,\n",
       " 1.619140625,\n",
       " -1.4951171875,\n",
       " 3.2890625,\n",
       " -0.5166015625,\n",
       " -0.458251953125,\n",
       " -3.033203125,\n",
       " 1.0361328125,\n",
       " -2.2421875,\n",
       " -1.21484375,\n",
       " -4.89453125,\n",
       " 2.505859375,\n",
       " 2.93359375,\n",
       " -0.81005859375,\n",
       " -3.732421875,\n",
       " -0.63037109375,\n",
       " 0.94580078125,\n",
       " -0.4150390625,\n",
       " 1.984375,\n",
       " -0.818359375,\n",
       " 2.962890625,\n",
       " -1.3212890625,\n",
       " 3.193359375,\n",
       " -2.08203125,\n",
       " 0.603515625,\n",
       " -5.1171875,\n",
       " -0.382080078125,\n",
       " 2.31640625,\n",
       " 1.384765625,\n",
       " 1.7373046875,\n",
       " -0.8798828125,\n",
       " 1.0322265625,\n",
       " 0.3095703125,\n",
       " 1.189453125,\n",
       " 0.054840087890625,\n",
       " -0.31787109375,\n",
       " -2.705078125,\n",
       " 2.25390625,\n",
       " 0.80322265625,\n",
       " 2.208984375,\n",
       " -2.712890625,\n",
       " -1.5625,\n",
       " -1.837890625,\n",
       " 3.8984375,\n",
       " 0.456298828125,\n",
       " 2.439453125,\n",
       " 5.1640625,\n",
       " 1.5146484375,\n",
       " -2.580078125,\n",
       " -0.364013671875,\n",
       " 4.2890625,\n",
       " 1.62890625,\n",
       " 1.728515625,\n",
       " -2.00390625,\n",
       " -2.07421875,\n",
       " -2.171875,\n",
       " 1.3701171875,\n",
       " 0.26220703125,\n",
       " 3.11328125,\n",
       " 0.69873046875,\n",
       " 2.279296875,\n",
       " -3.224609375,\n",
       " -3.6640625,\n",
       " -0.5830078125,\n",
       " -0.98828125,\n",
       " 0.1871337890625,\n",
       " -14.0078125,\n",
       " 4.16015625,\n",
       " 1.818359375,\n",
       " -0.3759765625,\n",
       " -3.40625,\n",
       " 0.042572021484375,\n",
       " -1.10546875,\n",
       " 4.45703125,\n",
       " 1.298828125,\n",
       " 1.767578125,\n",
       " -0.0538330078125,\n",
       " -0.01161956787109375,\n",
       " -2.162109375,\n",
       " -0.7470703125,\n",
       " 3.931640625,\n",
       " -0.4296875,\n",
       " -2.2265625,\n",
       " 1.4140625,\n",
       " -4.6875,\n",
       " 1.25390625,\n",
       " -1.6005859375,\n",
       " 1.04296875,\n",
       " -1.189453125,\n",
       " -0.7119140625,\n",
       " 1.9404296875,\n",
       " -0.62890625,\n",
       " 3.228515625,\n",
       " 2.642578125,\n",
       " 0.250244140625,\n",
       " -0.5439453125,\n",
       " 1.955078125,\n",
       " -2.1953125,\n",
       " -1.2509765625,\n",
       " -0.4150390625,\n",
       " 0.441162109375,\n",
       " -3.18359375,\n",
       " 2.36328125,\n",
       " 3.896484375,\n",
       " 0.7529296875,\n",
       " -0.5302734375,\n",
       " 0.421142578125,\n",
       " -0.87158203125,\n",
       " 0.4091796875,\n",
       " 0.69140625,\n",
       " -1.25,\n",
       " -1.03125,\n",
       " 0.2171630859375,\n",
       " 1.533203125,\n",
       " 3.228515625,\n",
       " 1.8671875,\n",
       " 0.0880126953125,\n",
       " 1.359375,\n",
       " -0.6259765625,\n",
       " 1.767578125,\n",
       " -0.9814453125,\n",
       " 1.359375,\n",
       " 1.908203125,\n",
       " -4.70703125,\n",
       " -0.38818359375,\n",
       " -0.61328125,\n",
       " -0.21826171875,\n",
       " 3.888671875,\n",
       " 1.8251953125,\n",
       " -0.7255859375,\n",
       " -0.56005859375,\n",
       " 2.345703125,\n",
       " -1.23828125,\n",
       " 2.171875,\n",
       " -1.6796875,\n",
       " -0.1771240234375,\n",
       " -1.9912109375,\n",
       " 0.481201171875,\n",
       " -4.0625,\n",
       " 5.1328125,\n",
       " 1.802734375,\n",
       " 0.56005859375,\n",
       " -1.4482421875,\n",
       " 1.4169921875,\n",
       " -2.869140625,\n",
       " -2.107421875,\n",
       " -2.578125,\n",
       " -1.189453125,\n",
       " -2.07421875,\n",
       " 0.8876953125,\n",
       " -2.044921875,\n",
       " -3.080078125,\n",
       " -0.6015625,\n",
       " 1.134765625,\n",
       " -1.98046875,\n",
       " 1.296875,\n",
       " -3.1171875,\n",
       " 1.287109375,\n",
       " 1.998046875,\n",
       " -0.386962890625,\n",
       " 0.14208984375,\n",
       " 0.1527099609375,\n",
       " -0.2122802734375,\n",
       " -3.1953125,\n",
       " -4.01171875,\n",
       " -0.13330078125,\n",
       " 0.51416015625,\n",
       " 2.197265625,\n",
       " -1.8037109375,\n",
       " -0.5390625,\n",
       " 0.1326904296875,\n",
       " -0.904296875,\n",
       " 0.8603515625,\n",
       " -0.371826171875,\n",
       " -2.20703125,\n",
       " -0.83349609375,\n",
       " 0.35986328125,\n",
       " 1.7607421875,\n",
       " 2.724609375,\n",
       " -1.853515625,\n",
       " 0.12646484375,\n",
       " 5.875,\n",
       " 2.3125,\n",
       " -0.455810546875,\n",
       " -2.5390625,\n",
       " -1.8623046875,\n",
       " 1.2509765625,\n",
       " 0.79833984375,\n",
       " 0.763671875,\n",
       " 2.9296875,\n",
       " 3.69921875,\n",
       " -0.818359375,\n",
       " -1.7216796875,\n",
       " 0.8583984375,\n",
       " 2.126953125,\n",
       " -1.9140625,\n",
       " 0.2440185546875,\n",
       " -0.265869140625,\n",
       " 1.076171875,\n",
       " -2.04296875,\n",
       " 1.1982421875,\n",
       " 9.8359375,\n",
       " -0.379638671875,\n",
       " 4.46875,\n",
       " -3.8359375,\n",
       " -0.0253753662109375,\n",
       " 1.3330078125,\n",
       " 0.578125,\n",
       " 1.953125,\n",
       " 0.51416015625,\n",
       " -0.732421875,\n",
       " 1.556640625,\n",
       " 0.5654296875,\n",
       " 1.076171875,\n",
       " 3.990234375,\n",
       " -2.8828125,\n",
       " 0.52978515625,\n",
       " -3.021484375,\n",
       " -1.9912109375,\n",
       " 0.7060546875,\n",
       " -0.72119140625,\n",
       " -0.28955078125,\n",
       " 1.990234375,\n",
       " 4.40625,\n",
       " -1.2744140625,\n",
       " -2.6640625,\n",
       " 2.470703125,\n",
       " -0.6240234375,\n",
       " -1.3798828125,\n",
       " -0.259033203125,\n",
       " -1.677734375,\n",
       " -0.8935546875,\n",
       " 1.2802734375,\n",
       " 1.5927734375,\n",
       " -0.13623046875,\n",
       " 0.048126220703125,\n",
       " 0.321044921875,\n",
       " -2.884765625,\n",
       " 2.1328125,\n",
       " 1.9072265625,\n",
       " -1.1435546875,\n",
       " -0.470703125,\n",
       " -0.740234375,\n",
       " -0.42626953125,\n",
       " 0.9443359375,\n",
       " 2.31640625,\n",
       " -3.3359375,\n",
       " -1.779296875,\n",
       " 3.09765625,\n",
       " 2.658203125,\n",
       " 1.537109375,\n",
       " 0.431884765625,\n",
       " 1.4384765625,\n",
       " -2.169921875,\n",
       " -1.74609375,\n",
       " -3.251953125,\n",
       " -0.1590576171875,\n",
       " 1.6884765625,\n",
       " 2.314453125,\n",
       " -1.3291015625,\n",
       " -3.4609375,\n",
       " -3.67578125,\n",
       " -2.59375,\n",
       " 1.7587890625,\n",
       " -2.953125,\n",
       " -1.0634765625,\n",
       " -0.287353515625,\n",
       " 0.52880859375,\n",
       " -2.06640625,\n",
       " -4.15625,\n",
       " -0.2171630859375,\n",
       " 1.509765625,\n",
       " 0.6904296875,\n",
       " -0.802734375,\n",
       " -2.310546875,\n",
       " -0.135009765625,\n",
       " 3.3828125,\n",
       " 2.080078125,\n",
       " 3.02734375,\n",
       " 3.349609375,\n",
       " -2.296875,\n",
       " -2.3046875,\n",
       " -0.2213134765625,\n",
       " 0.81298828125,\n",
       " 1.2294921875,\n",
       " -0.5908203125,\n",
       " 2.376953125,\n",
       " -0.5634765625,\n",
       " 1.4677734375,\n",
       " 2.041015625,\n",
       " -1.017578125,\n",
       " -2.251953125,\n",
       " -0.315673828125,\n",
       " -0.0994873046875,\n",
       " -0.314453125,\n",
       " 0.837890625,\n",
       " 2.70703125,\n",
       " -2.271484375,\n",
       " 5.02734375,\n",
       " 0.25439453125,\n",
       " -1.837890625,\n",
       " -3.76171875,\n",
       " -3.408203125,\n",
       " 0.39990234375,\n",
       " 2.828125,\n",
       " 0.8857421875,\n",
       " 1.666015625,\n",
       " -0.484130859375,\n",
       " -2.71875,\n",
       " -1.6591796875,\n",
       " -2.849609375,\n",
       " -2.775390625,\n",
       " -0.27978515625,\n",
       " 2.150390625,\n",
       " 0.349365234375,\n",
       " -0.513671875,\n",
       " 0.462646484375,\n",
       " -2.744140625,\n",
       " -2.1875,\n",
       " -1.3486328125,\n",
       " 0.97900390625,\n",
       " -1.9560546875,\n",
       " -1.3544921875,\n",
       " 3.58203125,\n",
       " -0.475341796875,\n",
       " 3.08203125,\n",
       " 1.0986328125,\n",
       " 0.58935546875,\n",
       " -2.0859375,\n",
       " -0.83544921875,\n",
       " -3.203125,\n",
       " -1.0185546875,\n",
       " -2.9921875,\n",
       " -0.0117340087890625,\n",
       " 1.5302734375,\n",
       " 1.169921875,\n",
       " 1.115234375,\n",
       " 2.38671875,\n",
       " 1.1494140625,\n",
       " 1.384765625,\n",
       " -0.0977783203125,\n",
       " -2.060546875,\n",
       " 2.646484375,\n",
       " 1.671875,\n",
       " 0.0084381103515625,\n",
       " -0.73583984375,\n",
       " -2.759765625,\n",
       " 2.486328125,\n",
       " 0.74072265625,\n",
       " -1.275390625,\n",
       " -1.7822265625,\n",
       " 0.369384765625,\n",
       " -4.421875,\n",
       " -4.08203125,\n",
       " 2.46875,\n",
       " 1.6376953125,\n",
       " 0.403564453125,\n",
       " 2.212890625,\n",
       " -4.125,\n",
       " 1.453125,\n",
       " 0.90966796875,\n",
       " 1.1025390625,\n",
       " -1.251953125,\n",
       " 3.2265625,\n",
       " -0.406494140625,\n",
       " 0.68115234375,\n",
       " 3.86328125,\n",
       " 1.0869140625,\n",
       " 2.04296875,\n",
       " -0.71630859375,\n",
       " 4.33984375,\n",
       " 0.98583984375,\n",
       " -0.67578125,\n",
       " 2.626953125,\n",
       " -1.3388671875,\n",
       " 0.5673828125,\n",
       " -4.59765625,\n",
       " 3.05078125,\n",
       " -0.267822265625,\n",
       " -1.5390625,\n",
       " -1.1044921875,\n",
       " 2.75390625,\n",
       " -0.78955078125,\n",
       " -1.021484375,\n",
       " 0.947265625,\n",
       " -2.373046875,\n",
       " 1.2548828125,\n",
       " -1.5859375,\n",
       " -0.90576171875,\n",
       " 3.708984375,\n",
       " -8.28125,\n",
       " 0.267822265625,\n",
       " 1.333984375,\n",
       " -0.9541015625,\n",
       " 2.455078125,\n",
       " -1.1142578125,\n",
       " 1.931640625,\n",
       " -2.28515625,\n",
       " -0.50390625,\n",
       " 1.19140625,\n",
       " -2.00390625,\n",
       " -1.8359375,\n",
       " 1.677734375,\n",
       " -2.33203125,\n",
       " -1.759765625,\n",
       " -1.837890625,\n",
       " -3.076171875,\n",
       " 1.9970703125,\n",
       " 2.39453125,\n",
       " -1.294921875,\n",
       " 0.953125,\n",
       " -1.1669921875,\n",
       " 0.137451171875,\n",
       " 3.232421875,\n",
       " 1.7099609375,\n",
       " -3.771484375,\n",
       " 2.138671875,\n",
       " 2.130859375,\n",
       " -2.720703125,\n",
       " 3.353515625,\n",
       " 1.27734375,\n",
       " -2.84765625,\n",
       " 3.265625,\n",
       " -2.109375,\n",
       " 2.236328125,\n",
       " -0.287353515625,\n",
       " -2.822265625,\n",
       " -0.005290985107421875,\n",
       " -1.41796875,\n",
       " 2.255859375,\n",
       " -0.1728515625,\n",
       " 0.36376953125,\n",
       " 1.248046875,\n",
       " 0.018402099609375,\n",
       " 2.205078125,\n",
       " 0.421875,\n",
       " 1.376953125,\n",
       " 2.33203125,\n",
       " 2.572265625,\n",
       " -1.17578125,\n",
       " 2.984375,\n",
       " 1.3525390625,\n",
       " -3.12890625,\n",
       " 2.6796875,\n",
       " 1.490234375,\n",
       " -1.17578125,\n",
       " 1.837890625,\n",
       " -2.572265625,\n",
       " -1.3203125,\n",
       " 1.47265625,\n",
       " 0.197509765625,\n",
       " -2.001953125,\n",
       " -3.4140625,\n",
       " 3.400390625,\n",
       " 0.486328125,\n",
       " -0.195556640625,\n",
       " -4.90234375,\n",
       " 2.060546875,\n",
       " 1.01171875,\n",
       " -3.974609375,\n",
       " 1.2109375,\n",
       " 1.6005859375,\n",
       " 0.277099609375,\n",
       " -2.107421875,\n",
       " 0.263671875,\n",
       " 3.025390625,\n",
       " 0.129150390625,\n",
       " -0.304443359375,\n",
       " -2.521484375,\n",
       " -0.73974609375,\n",
       " -0.8671875,\n",
       " -4.65625,\n",
       " -1.5693359375,\n",
       " 0.95751953125,\n",
       " 2.234375,\n",
       " -1.84765625,\n",
       " -1.78125,\n",
       " -1.6103515625,\n",
       " -0.6796875,\n",
       " 0.1395263671875,\n",
       " -0.32958984375,\n",
       " -1.1748046875,\n",
       " -1.5205078125,\n",
       " 3.0546875,\n",
       " -2.439453125,\n",
       " 2.552734375,\n",
       " 0.47265625,\n",
       " -1.4169921875,\n",
       " 3.48828125,\n",
       " -1.7841796875,\n",
       " -0.1270751953125,\n",
       " 0.8603515625,\n",
       " 0.0548095703125,\n",
       " 0.38427734375,\n",
       " 1.6669921875,\n",
       " -0.5791015625,\n",
       " 1.7529296875,\n",
       " -0.434326171875,\n",
       " 2.0703125,\n",
       " -0.126953125,\n",
       " 2.193359375,\n",
       " -3.111328125,\n",
       " 2.80859375,\n",
       " -2.974609375,\n",
       " 1.0185546875,\n",
       " 0.58642578125,\n",
       " 1.6708984375,\n",
       " -2.01171875,\n",
       " -0.90625,\n",
       " -2.166015625,\n",
       " -4.4609375,\n",
       " -1.38671875,\n",
       " -0.99658203125,\n",
       " 0.91162109375,\n",
       " -3.294921875,\n",
       " 2.681640625,\n",
       " 5.87109375,\n",
       " 2.451171875,\n",
       " -9.2890625,\n",
       " -2.029296875,\n",
       " 1.013671875,\n",
       " 0.8193359375,\n",
       " 0.258544921875,\n",
       " -1.177734375,\n",
       " -1.01171875,\n",
       " -0.07049560546875,\n",
       " 2.814453125,\n",
       " 1.830078125,\n",
       " -0.3173828125,\n",
       " 0.485595703125,\n",
       " -0.73388671875,\n",
       " 3.734375,\n",
       " -3.05859375,\n",
       " 3.94921875,\n",
       " 0.740234375,\n",
       " 1.3310546875,\n",
       " -1.212890625,\n",
       " -1.9775390625,\n",
       " 0.437255859375,\n",
       " 1.6298828125,\n",
       " -0.330810546875,\n",
       " 1.568359375,\n",
       " 0.68994140625,\n",
       " 0.1087646484375,\n",
       " 1.0654296875,\n",
       " -2.36328125,\n",
       " 2.431640625,\n",
       " -1.2890625,\n",
       " 2.052734375,\n",
       " -0.58935546875,\n",
       " 0.4375,\n",
       " -1.109375,\n",
       " -1.4677734375,\n",
       " -2.294921875,\n",
       " 0.2213134765625,\n",
       " -3.091796875,\n",
       " 3.53515625,\n",
       " -1.728515625,\n",
       " -0.90771484375,\n",
       " 0.68798828125,\n",
       " 0.07720947265625,\n",
       " -0.9033203125,\n",
       " 0.457763671875,\n",
       " -1.744140625,\n",
       " -2.48046875,\n",
       " 2.9609375,\n",
       " 0.84130859375,\n",
       " -1.7734375,\n",
       " -1.42578125,\n",
       " -1.4892578125,\n",
       " -3.904296875,\n",
       " 1.83984375,\n",
       " -4.109375,\n",
       " 0.33642578125,\n",
       " 2.259765625,\n",
       " -0.0711669921875,\n",
       " -0.5791015625,\n",
       " -3.908203125,\n",
       " 2.20703125,\n",
       " -2.0703125,\n",
       " -2.837890625,\n",
       " 1.416015625,\n",
       " 1.376953125,\n",
       " 0.394775390625,\n",
       " 0.209228515625,\n",
       " 10.5625,\n",
       " -0.81494140625,\n",
       " 1.76953125,\n",
       " 2.146484375,\n",
       " -3.873046875,\n",
       " -1.6357421875,\n",
       " -2.494140625,\n",
       " -0.138671875,\n",
       " -2.158203125,\n",
       " 0.8818359375,\n",
       " -0.67236328125,\n",
       " 0.50341796875,\n",
       " 2.046875,\n",
       " -3.453125,\n",
       " -1.73046875,\n",
       " 3.537109375,\n",
       " 0.59619140625,\n",
       " -0.278076171875,\n",
       " -3.037109375,\n",
       " 3.421875,\n",
       " -1.4697265625,\n",
       " -3.634765625,\n",
       " -3.3828125,\n",
       " ...]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embeddings(text):\n",
    "    # Tokenize the input sentence\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "    # Forward pass through the model to get hidden states\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Extract the hidden states (embeddings)\n",
    "    hidden_states = outputs.hidden_states  # This returns a tuple with hidden states for each layer\n",
    "\n",
    "    # Get the final layer embeddings (usually the last layer's hidden state)\n",
    "    # hidden_states[-1] gives the final layer's hidden states\n",
    "    sentence_embedding = hidden_states[-1][:, 0, :]  # Usually, the [CLS] token embedding is at position 0\n",
    "\n",
    "    # Convert to numpy or keep as tensor for further processing\n",
    "    embedding = sentence_embedding.cpu().numpy()\n",
    "\n",
    "    return embedding[0].tolist()\n",
    "\n",
    "# example usage :\n",
    "get_embeddings(\"Family and social relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query_text = \"i hate my body\"\n",
    "query_embeddings = [get_embeddings(query_text)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "piece_text = \"i love my body\"\n",
    "piece_embeddings = [get_embeddings(piece_text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piece_embeddings == query_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.33398438,  2.78125   ,  1.64160156, ..., -1.94726562,\n",
       "        2.75390625,  1.93359375])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(query_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.33398438,  2.78125   ,  1.64160156, ..., -1.94726562,\n",
       "        2.75390625,  1.93359375])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(piece_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20543.570416974533]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.dot(np.array(piece_embeddings[i]), np.array(query_embeddings[i]).T).item() for i in range(len(piece_embeddings))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0000000000000004]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %pip install scikit-learn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def get_similarities(piece_text, query_text):\n",
    "    piece_embeddings = [get_embeddings(piece_text)]\n",
    "    query_embeddings = [get_embeddings(query_text)]\n",
    "    cosine_similarities = [cosine_similarity([piece_embeddings[i]], [query_embeddings[i]])[0][0] for i in range(len(piece_embeddings))]\n",
    "    inner_products = [np.dot(piece_embeddings[i], query_embeddings[i].T).item() for i in range(len(piece_embeddings))]\n",
    "    \n",
    "    return cosine_similarities, inner_products\n",
    "\n",
    "get_cosine_similarities(\"body dissatisfaction\", \"i hate my body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarities(piece_text, query_text):\n",
    "    piece_embeddings = [get_embeddings(piece_text)]\n",
    "    query_embeddings = [get_embeddings(query_text)]\n",
    "    cosine_similarities = [cosine_similarity([piece_embeddings[i]], [query_embeddings[i]])[0][0] for i in range(len(piece_embeddings))]\n",
    "    return cosine_similarities\n",
    "\n",
    "def get_inner_products(piece_text, query_text):\n",
    "    piece_embeddings = [get_embeddings(piece_text, model) for model in mdl_ls]\n",
    "    query_embeddings = [get_embeddings(query_text, model) for model in mdl_ls]\n",
    "    inner_products = [np.dot(piece_embeddings[i], query_embeddings[i].T).item() for i in range(len(piece_embeddings))]\n",
    "    \n",
    "    return inner_products\n",
    "\n",
    "def process_paragraph(text):\n",
    "    # Split the text by the \" EOS \" marker\n",
    "    sentences = re.split(r'\\. ', text) # split by period \n",
    "    \n",
    "    # Remove any sentences with fewer than two words\n",
    "    filtered_sentences = [sentence.strip() for sentence in sentences if len(sentence.split()) >= 2]\n",
    "    \n",
    "    return filtered_sentences\n",
    "\n",
    "def get_paragraph_sim(text, query_text, plot=False, sim_by=\"MIP\"):\n",
    "    # MIP: maximum inner product\n",
    "    # MCS: maximum cosine similarity\n",
    "    \n",
    "    pieces = process_paragraph(text)\n",
    "    results = []  # List to hold results\n",
    "    for piece_text in pieces:\n",
    "        if sim_by == \"MCS\":\n",
    "            result = get_cosine_similarities(piece_text, query_text)\n",
    "        if sim_by == \"MIP\":\n",
    "            result = get_inner_products(piece_text, query_text)\n",
    "            \n",
    "        results.append(result)\n",
    "        \n",
    "        \n",
    "    results = np.array(results)\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        for i in range(results.shape[1]):\n",
    "            plt.plot(results[:, i], label=f'Model {i+1}')\n",
    "\n",
    "        # Add labels and title\n",
    "        plt.ylim(-1,1)\n",
    "        plt.xlabel(\"sentence order\")\n",
    "        plt.ylabel(\"Similarity\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    return results, pieces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (1, 4096)\n"
     ]
    }
   ],
   "source": [
    "# Example sentence\n",
    "sentence = query_df.description[0]\n",
    "\n",
    "# Tokenize the input sentence\n",
    "inputs = tokenizer(sentence, return_tensors='pt')\n",
    "\n",
    "# Forward pass through the model to get hidden states\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Extract the hidden states (embeddings)\n",
    "hidden_states = outputs.hidden_states  # This returns a tuple with hidden states for each layer\n",
    "\n",
    "# Get the final layer embeddings (usually the last layer's hidden state)\n",
    "# hidden_states[-1] gives the final layer's hidden states\n",
    "sentence_embedding = hidden_states[-1][:, 0, :]  # Usually, the [CLS] token embedding is at position 0\n",
    "\n",
    "# Convert to numpy or keep as tensor for further processing\n",
    "embedding = sentence_embedding.cpu().numpy()\n",
    "print(\"Embedding shape:\", embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.333984375,\n",
       " 2.78125,\n",
       " 1.6416015625,\n",
       " 2.822265625,\n",
       " 3.421875,\n",
       " 1.892578125,\n",
       " -1.2197265625,\n",
       " -0.6943359375,\n",
       " -1.8876953125,\n",
       " 1.5185546875,\n",
       " -0.8837890625,\n",
       " -0.218505859375,\n",
       " 2.1484375,\n",
       " -2.9375,\n",
       " -0.88134765625,\n",
       " -1.1103515625,\n",
       " 0.85302734375,\n",
       " 0.98291015625,\n",
       " -2.69921875,\n",
       " -3.388671875,\n",
       " -2.541015625,\n",
       " 0.94091796875,\n",
       " -3.53125,\n",
       " 3.23828125,\n",
       " 0.77001953125,\n",
       " -0.33984375,\n",
       " 0.33984375,\n",
       " 1.39453125,\n",
       " -2.09375,\n",
       " 0.48095703125,\n",
       " -0.035400390625,\n",
       " -0.397705078125,\n",
       " 2.55859375,\n",
       " -3.021484375,\n",
       " -3.400390625,\n",
       " -0.274658203125,\n",
       " 0.11468505859375,\n",
       " -2.0234375,\n",
       " 1.0048828125,\n",
       " -4.5234375,\n",
       " 3.62109375,\n",
       " -2.140625,\n",
       " 1.4072265625,\n",
       " 1.3134765625,\n",
       " -0.99755859375,\n",
       " 3.08203125,\n",
       " 2.177734375,\n",
       " -0.66455078125,\n",
       " 2.8671875,\n",
       " -0.2113037109375,\n",
       " -2.9921875,\n",
       " 1.447265625,\n",
       " 1.4169921875,\n",
       " -0.240478515625,\n",
       " -1.1865234375,\n",
       " 1.2724609375,\n",
       " -1.6123046875,\n",
       " -0.830078125,\n",
       " 0.58544921875,\n",
       " -1.13671875,\n",
       " 1.1943359375,\n",
       " -1.552734375,\n",
       " -0.54541015625,\n",
       " -1.421875,\n",
       " 3.421875,\n",
       " 2.59375,\n",
       " -1.3896484375,\n",
       " -2.201171875,\n",
       " -0.05712890625,\n",
       " 0.438232421875,\n",
       " 1.103515625,\n",
       " 1.9111328125,\n",
       " 1.318359375,\n",
       " -1.5751953125,\n",
       " -2.775390625,\n",
       " 1.212890625,\n",
       " 2.5078125,\n",
       " -2.3359375,\n",
       " -0.171875,\n",
       " 2.44140625,\n",
       " 1.8408203125,\n",
       " 2.716796875,\n",
       " 0.07098388671875,\n",
       " 1.41015625,\n",
       " -3.990234375,\n",
       " 0.74267578125,\n",
       " -2.029296875,\n",
       " 1.62109375,\n",
       " -3.041015625,\n",
       " -1.1767578125,\n",
       " -1.5166015625,\n",
       " -4.0625,\n",
       " 0.352783203125,\n",
       " -0.697265625,\n",
       " -1.37109375,\n",
       " -0.43310546875,\n",
       " -3.595703125,\n",
       " -2.1796875,\n",
       " -1.013671875,\n",
       " -2.279296875,\n",
       " -5.2734375,\n",
       " -2.86328125,\n",
       " 0.6962890625,\n",
       " 4.09765625,\n",
       " -0.83349609375,\n",
       " 1.017578125,\n",
       " 1.8193359375,\n",
       " 0.25048828125,\n",
       " -0.8349609375,\n",
       " 2.08203125,\n",
       " 3.5859375,\n",
       " 3.923828125,\n",
       " -0.8134765625,\n",
       " -2.673828125,\n",
       " 0.35107421875,\n",
       " -1.1591796875,\n",
       " -0.51220703125,\n",
       " 0.126953125,\n",
       " -2.015625,\n",
       " 2.34375,\n",
       " 2.939453125,\n",
       " 0.90673828125,\n",
       " 1.0830078125,\n",
       " -2.642578125,\n",
       " -0.145751953125,\n",
       " -2.521484375,\n",
       " 0.96435546875,\n",
       " 0.47802734375,\n",
       " -1.3623046875,\n",
       " -1.6806640625,\n",
       " 0.64306640625,\n",
       " 0.0745849609375,\n",
       " -1.7763671875,\n",
       " 3.38671875,\n",
       " -1.9150390625,\n",
       " -3.15625,\n",
       " -3.435546875,\n",
       " 3.91015625,\n",
       " -0.040069580078125,\n",
       " -1.392578125,\n",
       " 1.4033203125,\n",
       " -0.77294921875,\n",
       " 0.281982421875,\n",
       " -2.728515625,\n",
       " -0.005626678466796875,\n",
       " 1.044921875,\n",
       " -1.4921875,\n",
       " -0.020477294921875,\n",
       " -1.3037109375,\n",
       " 1.59765625,\n",
       " 0.359375,\n",
       " 0.83056640625,\n",
       " 2.72265625,\n",
       " 1.21875,\n",
       " 2.236328125,\n",
       " 0.248046875,\n",
       " -1.2353515625,\n",
       " 4.16015625,\n",
       " -0.841796875,\n",
       " -3.01953125,\n",
       " -0.54833984375,\n",
       " -2.71484375,\n",
       " -0.52099609375,\n",
       " -1.3388671875,\n",
       " -0.7001953125,\n",
       " -0.51318359375,\n",
       " -2.205078125,\n",
       " 2.404296875,\n",
       " 0.8701171875,\n",
       " -3.3203125,\n",
       " 0.6240234375,\n",
       " -4.015625,\n",
       " 3.939453125,\n",
       " -0.62060546875,\n",
       " 1.1240234375,\n",
       " 0.1055908203125,\n",
       " 0.580078125,\n",
       " -0.86083984375,\n",
       " -1.8349609375,\n",
       " 0.11370849609375,\n",
       " -0.978515625,\n",
       " 2.85546875,\n",
       " 0.0310821533203125,\n",
       " 1.9951171875,\n",
       " 5.015625,\n",
       " -0.744140625,\n",
       " -1.22265625,\n",
       " -2.55859375,\n",
       " 1.24609375,\n",
       " 0.005809783935546875,\n",
       " -2.537109375,\n",
       " 2.353515625,\n",
       " -1.9072265625,\n",
       " -3.408203125,\n",
       " 3.7109375,\n",
       " 1.849609375,\n",
       " -3.837890625,\n",
       " -1.3349609375,\n",
       " -1.3505859375,\n",
       " -0.6484375,\n",
       " -1.0712890625,\n",
       " 1.474609375,\n",
       " -0.360595703125,\n",
       " 3.07421875,\n",
       " -3.49609375,\n",
       " -5.5546875,\n",
       " -1.9697265625,\n",
       " -2.22265625,\n",
       " -3.611328125,\n",
       " -1.17578125,\n",
       " -2.275390625,\n",
       " 1.80078125,\n",
       " -0.1971435546875,\n",
       " -0.57861328125,\n",
       " -10.78125,\n",
       " -0.62158203125,\n",
       " -0.2607421875,\n",
       " 1.9150390625,\n",
       " 0.95947265625,\n",
       " -0.79931640625,\n",
       " -0.14990234375,\n",
       " 0.7255859375,\n",
       " -1.0009765625,\n",
       " 0.634765625,\n",
       " -0.44677734375,\n",
       " -2.240234375,\n",
       " 4.83203125,\n",
       " -1.7568359375,\n",
       " 1.634765625,\n",
       " -4.58203125,\n",
       " 1.501953125,\n",
       " -1.5791015625,\n",
       " 2.037109375,\n",
       " -2.28515625,\n",
       " -2.56640625,\n",
       " -2.296875,\n",
       " 1.298828125,\n",
       " 1.70703125,\n",
       " 0.76171875,\n",
       " -2.841796875,\n",
       " 0.9755859375,\n",
       " 1.5,\n",
       " 1.2880859375,\n",
       " -1.037109375,\n",
       " -0.2041015625,\n",
       " -0.33544921875,\n",
       " 3.60546875,\n",
       " -1.9716796875,\n",
       " 2.05078125,\n",
       " 0.6689453125,\n",
       " -3.3671875,\n",
       " 3.412109375,\n",
       " -3.74609375,\n",
       " 1.2119140625,\n",
       " 1.095703125,\n",
       " 0.84521484375,\n",
       " -2.232421875,\n",
       " -1.685546875,\n",
       " 0.6533203125,\n",
       " -1.755859375,\n",
       " 2.33203125,\n",
       " -0.666015625,\n",
       " -5.015625,\n",
       " -4.45703125,\n",
       " -0.5078125,\n",
       " 3.6171875,\n",
       " -0.400634765625,\n",
       " -2.896484375,\n",
       " 1.041015625,\n",
       " -1.216796875,\n",
       " -1.046875,\n",
       " -0.255126953125,\n",
       " -2.87890625,\n",
       " 0.5869140625,\n",
       " -0.0616455078125,\n",
       " -2.25390625,\n",
       " -2.826171875,\n",
       " -3.935546875,\n",
       " -0.8408203125,\n",
       " 1.4228515625,\n",
       " 0.196533203125,\n",
       " 3.67578125,\n",
       " -2.634765625,\n",
       " -0.564453125,\n",
       " -3.1953125,\n",
       " -2.908203125,\n",
       " 4.40234375,\n",
       " 3.630859375,\n",
       " -0.355712890625,\n",
       " 0.6044921875,\n",
       " 1.630859375,\n",
       " -0.92138671875,\n",
       " 2.6875,\n",
       " 1.3818359375,\n",
       " 4.50390625,\n",
       " -0.68310546875,\n",
       " 0.1097412109375,\n",
       " -2.25390625,\n",
       " -2.0,\n",
       " -0.50146484375,\n",
       " -1.2392578125,\n",
       " -0.052215576171875,\n",
       " 0.6435546875,\n",
       " 1.640625,\n",
       " 0.72998046875,\n",
       " -2.544921875,\n",
       " -2.771484375,\n",
       " 0.489013671875,\n",
       " 0.85400390625,\n",
       " 2.619140625,\n",
       " -1.9521484375,\n",
       " -1.8203125,\n",
       " 0.1405029296875,\n",
       " -0.9443359375,\n",
       " -1.365234375,\n",
       " -1.1943359375,\n",
       " 2.439453125,\n",
       " 3.765625,\n",
       " -1.775390625,\n",
       " 4.34375,\n",
       " -0.1956787109375,\n",
       " 1.9658203125,\n",
       " -1.568359375,\n",
       " -0.1910400390625,\n",
       " -3.818359375,\n",
       " -0.8916015625,\n",
       " 3.501953125,\n",
       " 2.138671875,\n",
       " -2.0078125,\n",
       " -0.2481689453125,\n",
       " -0.83447265625,\n",
       " 1.5927734375,\n",
       " 3.158203125,\n",
       " 1.42578125,\n",
       " -0.59033203125,\n",
       " 0.45458984375,\n",
       " 0.8857421875,\n",
       " 2.337890625,\n",
       " -0.265625,\n",
       " -2.6328125,\n",
       " 0.496337890625,\n",
       " -0.5791015625,\n",
       " -1.5322265625,\n",
       " -1.5,\n",
       " 0.67626953125,\n",
       " -2.26171875,\n",
       " -1.6708984375,\n",
       " 4.40625,\n",
       " 1.2109375,\n",
       " -0.1925048828125,\n",
       " 2.310546875,\n",
       " -0.6337890625,\n",
       " -1.291015625,\n",
       " 1.4189453125,\n",
       " -0.51318359375,\n",
       " -3.638671875,\n",
       " 0.52978515625,\n",
       " 1.5380859375,\n",
       " -1.373046875,\n",
       " 1.373046875,\n",
       " -2.240234375,\n",
       " 2.13671875,\n",
       " 0.54833984375,\n",
       " 2.1953125,\n",
       " 0.8046875,\n",
       " 1.333984375,\n",
       " -2.216796875,\n",
       " -0.59912109375,\n",
       " 0.57861328125,\n",
       " -1.3095703125,\n",
       " 1.9072265625,\n",
       " 0.205322265625,\n",
       " 2.84765625,\n",
       " 0.233642578125,\n",
       " -0.572265625,\n",
       " 2.212890625,\n",
       " -5.078125,\n",
       " -0.93505859375,\n",
       " -1.5166015625,\n",
       " 1.4365234375,\n",
       " -1.490234375,\n",
       " 1.8017578125,\n",
       " 2.986328125,\n",
       " 1.6142578125,\n",
       " 2.90234375,\n",
       " 1.849609375,\n",
       " -1.166015625,\n",
       " -2.5546875,\n",
       " 3.69921875,\n",
       " -0.06512451171875,\n",
       " -1.515625,\n",
       " -0.712890625,\n",
       " -1.1865234375,\n",
       " 1.619140625,\n",
       " -1.4951171875,\n",
       " 3.2890625,\n",
       " -0.5166015625,\n",
       " -0.458251953125,\n",
       " -3.033203125,\n",
       " 1.0361328125,\n",
       " -2.2421875,\n",
       " -1.21484375,\n",
       " -4.89453125,\n",
       " 2.505859375,\n",
       " 2.93359375,\n",
       " -0.81005859375,\n",
       " -3.732421875,\n",
       " -0.63037109375,\n",
       " 0.94580078125,\n",
       " -0.4150390625,\n",
       " 1.984375,\n",
       " -0.818359375,\n",
       " 2.962890625,\n",
       " -1.3212890625,\n",
       " 3.193359375,\n",
       " -2.08203125,\n",
       " 0.603515625,\n",
       " -5.1171875,\n",
       " -0.382080078125,\n",
       " 2.31640625,\n",
       " 1.384765625,\n",
       " 1.7373046875,\n",
       " -0.8798828125,\n",
       " 1.0322265625,\n",
       " 0.3095703125,\n",
       " 1.189453125,\n",
       " 0.054840087890625,\n",
       " -0.31787109375,\n",
       " -2.705078125,\n",
       " 2.25390625,\n",
       " 0.80322265625,\n",
       " 2.208984375,\n",
       " -2.712890625,\n",
       " -1.5625,\n",
       " -1.837890625,\n",
       " 3.8984375,\n",
       " 0.456298828125,\n",
       " 2.439453125,\n",
       " 5.1640625,\n",
       " 1.5146484375,\n",
       " -2.580078125,\n",
       " -0.364013671875,\n",
       " 4.2890625,\n",
       " 1.62890625,\n",
       " 1.728515625,\n",
       " -2.00390625,\n",
       " -2.07421875,\n",
       " -2.171875,\n",
       " 1.3701171875,\n",
       " 0.26220703125,\n",
       " 3.11328125,\n",
       " 0.69873046875,\n",
       " 2.279296875,\n",
       " -3.224609375,\n",
       " -3.6640625,\n",
       " -0.5830078125,\n",
       " -0.98828125,\n",
       " 0.1871337890625,\n",
       " -14.0078125,\n",
       " 4.16015625,\n",
       " 1.818359375,\n",
       " -0.3759765625,\n",
       " -3.40625,\n",
       " 0.042572021484375,\n",
       " -1.10546875,\n",
       " 4.45703125,\n",
       " 1.298828125,\n",
       " 1.767578125,\n",
       " -0.0538330078125,\n",
       " -0.01161956787109375,\n",
       " -2.162109375,\n",
       " -0.7470703125,\n",
       " 3.931640625,\n",
       " -0.4296875,\n",
       " -2.2265625,\n",
       " 1.4140625,\n",
       " -4.6875,\n",
       " 1.25390625,\n",
       " -1.6005859375,\n",
       " 1.04296875,\n",
       " -1.189453125,\n",
       " -0.7119140625,\n",
       " 1.9404296875,\n",
       " -0.62890625,\n",
       " 3.228515625,\n",
       " 2.642578125,\n",
       " 0.250244140625,\n",
       " -0.5439453125,\n",
       " 1.955078125,\n",
       " -2.1953125,\n",
       " -1.2509765625,\n",
       " -0.4150390625,\n",
       " 0.441162109375,\n",
       " -3.18359375,\n",
       " 2.36328125,\n",
       " 3.896484375,\n",
       " 0.7529296875,\n",
       " -0.5302734375,\n",
       " 0.421142578125,\n",
       " -0.87158203125,\n",
       " 0.4091796875,\n",
       " 0.69140625,\n",
       " -1.25,\n",
       " -1.03125,\n",
       " 0.2171630859375,\n",
       " 1.533203125,\n",
       " 3.228515625,\n",
       " 1.8671875,\n",
       " 0.0880126953125,\n",
       " 1.359375,\n",
       " -0.6259765625,\n",
       " 1.767578125,\n",
       " -0.9814453125,\n",
       " 1.359375,\n",
       " 1.908203125,\n",
       " -4.70703125,\n",
       " -0.38818359375,\n",
       " -0.61328125,\n",
       " -0.21826171875,\n",
       " 3.888671875,\n",
       " 1.8251953125,\n",
       " -0.7255859375,\n",
       " -0.56005859375,\n",
       " 2.345703125,\n",
       " -1.23828125,\n",
       " 2.171875,\n",
       " -1.6796875,\n",
       " -0.1771240234375,\n",
       " -1.9912109375,\n",
       " 0.481201171875,\n",
       " -4.0625,\n",
       " 5.1328125,\n",
       " 1.802734375,\n",
       " 0.56005859375,\n",
       " -1.4482421875,\n",
       " 1.4169921875,\n",
       " -2.869140625,\n",
       " -2.107421875,\n",
       " -2.578125,\n",
       " -1.189453125,\n",
       " -2.07421875,\n",
       " 0.8876953125,\n",
       " -2.044921875,\n",
       " -3.080078125,\n",
       " -0.6015625,\n",
       " 1.134765625,\n",
       " -1.98046875,\n",
       " 1.296875,\n",
       " -3.1171875,\n",
       " 1.287109375,\n",
       " 1.998046875,\n",
       " -0.386962890625,\n",
       " 0.14208984375,\n",
       " 0.1527099609375,\n",
       " -0.2122802734375,\n",
       " -3.1953125,\n",
       " -4.01171875,\n",
       " -0.13330078125,\n",
       " 0.51416015625,\n",
       " 2.197265625,\n",
       " -1.8037109375,\n",
       " -0.5390625,\n",
       " 0.1326904296875,\n",
       " -0.904296875,\n",
       " 0.8603515625,\n",
       " -0.371826171875,\n",
       " -2.20703125,\n",
       " -0.83349609375,\n",
       " 0.35986328125,\n",
       " 1.7607421875,\n",
       " 2.724609375,\n",
       " -1.853515625,\n",
       " 0.12646484375,\n",
       " 5.875,\n",
       " 2.3125,\n",
       " -0.455810546875,\n",
       " -2.5390625,\n",
       " -1.8623046875,\n",
       " 1.2509765625,\n",
       " 0.79833984375,\n",
       " 0.763671875,\n",
       " 2.9296875,\n",
       " 3.69921875,\n",
       " -0.818359375,\n",
       " -1.7216796875,\n",
       " 0.8583984375,\n",
       " 2.126953125,\n",
       " -1.9140625,\n",
       " 0.2440185546875,\n",
       " -0.265869140625,\n",
       " 1.076171875,\n",
       " -2.04296875,\n",
       " 1.1982421875,\n",
       " 9.8359375,\n",
       " -0.379638671875,\n",
       " 4.46875,\n",
       " -3.8359375,\n",
       " -0.0253753662109375,\n",
       " 1.3330078125,\n",
       " 0.578125,\n",
       " 1.953125,\n",
       " 0.51416015625,\n",
       " -0.732421875,\n",
       " 1.556640625,\n",
       " 0.5654296875,\n",
       " 1.076171875,\n",
       " 3.990234375,\n",
       " -2.8828125,\n",
       " 0.52978515625,\n",
       " -3.021484375,\n",
       " -1.9912109375,\n",
       " 0.7060546875,\n",
       " -0.72119140625,\n",
       " -0.28955078125,\n",
       " 1.990234375,\n",
       " 4.40625,\n",
       " -1.2744140625,\n",
       " -2.6640625,\n",
       " 2.470703125,\n",
       " -0.6240234375,\n",
       " -1.3798828125,\n",
       " -0.259033203125,\n",
       " -1.677734375,\n",
       " -0.8935546875,\n",
       " 1.2802734375,\n",
       " 1.5927734375,\n",
       " -0.13623046875,\n",
       " 0.048126220703125,\n",
       " 0.321044921875,\n",
       " -2.884765625,\n",
       " 2.1328125,\n",
       " 1.9072265625,\n",
       " -1.1435546875,\n",
       " -0.470703125,\n",
       " -0.740234375,\n",
       " -0.42626953125,\n",
       " 0.9443359375,\n",
       " 2.31640625,\n",
       " -3.3359375,\n",
       " -1.779296875,\n",
       " 3.09765625,\n",
       " 2.658203125,\n",
       " 1.537109375,\n",
       " 0.431884765625,\n",
       " 1.4384765625,\n",
       " -2.169921875,\n",
       " -1.74609375,\n",
       " -3.251953125,\n",
       " -0.1590576171875,\n",
       " 1.6884765625,\n",
       " 2.314453125,\n",
       " -1.3291015625,\n",
       " -3.4609375,\n",
       " -3.67578125,\n",
       " -2.59375,\n",
       " 1.7587890625,\n",
       " -2.953125,\n",
       " -1.0634765625,\n",
       " -0.287353515625,\n",
       " 0.52880859375,\n",
       " -2.06640625,\n",
       " -4.15625,\n",
       " -0.2171630859375,\n",
       " 1.509765625,\n",
       " 0.6904296875,\n",
       " -0.802734375,\n",
       " -2.310546875,\n",
       " -0.135009765625,\n",
       " 3.3828125,\n",
       " 2.080078125,\n",
       " 3.02734375,\n",
       " 3.349609375,\n",
       " -2.296875,\n",
       " -2.3046875,\n",
       " -0.2213134765625,\n",
       " 0.81298828125,\n",
       " 1.2294921875,\n",
       " -0.5908203125,\n",
       " 2.376953125,\n",
       " -0.5634765625,\n",
       " 1.4677734375,\n",
       " 2.041015625,\n",
       " -1.017578125,\n",
       " -2.251953125,\n",
       " -0.315673828125,\n",
       " -0.0994873046875,\n",
       " -0.314453125,\n",
       " 0.837890625,\n",
       " 2.70703125,\n",
       " -2.271484375,\n",
       " 5.02734375,\n",
       " 0.25439453125,\n",
       " -1.837890625,\n",
       " -3.76171875,\n",
       " -3.408203125,\n",
       " 0.39990234375,\n",
       " 2.828125,\n",
       " 0.8857421875,\n",
       " 1.666015625,\n",
       " -0.484130859375,\n",
       " -2.71875,\n",
       " -1.6591796875,\n",
       " -2.849609375,\n",
       " -2.775390625,\n",
       " -0.27978515625,\n",
       " 2.150390625,\n",
       " 0.349365234375,\n",
       " -0.513671875,\n",
       " 0.462646484375,\n",
       " -2.744140625,\n",
       " -2.1875,\n",
       " -1.3486328125,\n",
       " 0.97900390625,\n",
       " -1.9560546875,\n",
       " -1.3544921875,\n",
       " 3.58203125,\n",
       " -0.475341796875,\n",
       " 3.08203125,\n",
       " 1.0986328125,\n",
       " 0.58935546875,\n",
       " -2.0859375,\n",
       " -0.83544921875,\n",
       " -3.203125,\n",
       " -1.0185546875,\n",
       " -2.9921875,\n",
       " -0.0117340087890625,\n",
       " 1.5302734375,\n",
       " 1.169921875,\n",
       " 1.115234375,\n",
       " 2.38671875,\n",
       " 1.1494140625,\n",
       " 1.384765625,\n",
       " -0.0977783203125,\n",
       " -2.060546875,\n",
       " 2.646484375,\n",
       " 1.671875,\n",
       " 0.0084381103515625,\n",
       " -0.73583984375,\n",
       " -2.759765625,\n",
       " 2.486328125,\n",
       " 0.74072265625,\n",
       " -1.275390625,\n",
       " -1.7822265625,\n",
       " 0.369384765625,\n",
       " -4.421875,\n",
       " -4.08203125,\n",
       " 2.46875,\n",
       " 1.6376953125,\n",
       " 0.403564453125,\n",
       " 2.212890625,\n",
       " -4.125,\n",
       " 1.453125,\n",
       " 0.90966796875,\n",
       " 1.1025390625,\n",
       " -1.251953125,\n",
       " 3.2265625,\n",
       " -0.406494140625,\n",
       " 0.68115234375,\n",
       " 3.86328125,\n",
       " 1.0869140625,\n",
       " 2.04296875,\n",
       " -0.71630859375,\n",
       " 4.33984375,\n",
       " 0.98583984375,\n",
       " -0.67578125,\n",
       " 2.626953125,\n",
       " -1.3388671875,\n",
       " 0.5673828125,\n",
       " -4.59765625,\n",
       " 3.05078125,\n",
       " -0.267822265625,\n",
       " -1.5390625,\n",
       " -1.1044921875,\n",
       " 2.75390625,\n",
       " -0.78955078125,\n",
       " -1.021484375,\n",
       " 0.947265625,\n",
       " -2.373046875,\n",
       " 1.2548828125,\n",
       " -1.5859375,\n",
       " -0.90576171875,\n",
       " 3.708984375,\n",
       " -8.28125,\n",
       " 0.267822265625,\n",
       " 1.333984375,\n",
       " -0.9541015625,\n",
       " 2.455078125,\n",
       " -1.1142578125,\n",
       " 1.931640625,\n",
       " -2.28515625,\n",
       " -0.50390625,\n",
       " 1.19140625,\n",
       " -2.00390625,\n",
       " -1.8359375,\n",
       " 1.677734375,\n",
       " -2.33203125,\n",
       " -1.759765625,\n",
       " -1.837890625,\n",
       " -3.076171875,\n",
       " 1.9970703125,\n",
       " 2.39453125,\n",
       " -1.294921875,\n",
       " 0.953125,\n",
       " -1.1669921875,\n",
       " 0.137451171875,\n",
       " 3.232421875,\n",
       " 1.7099609375,\n",
       " -3.771484375,\n",
       " 2.138671875,\n",
       " 2.130859375,\n",
       " -2.720703125,\n",
       " 3.353515625,\n",
       " 1.27734375,\n",
       " -2.84765625,\n",
       " 3.265625,\n",
       " -2.109375,\n",
       " 2.236328125,\n",
       " -0.287353515625,\n",
       " -2.822265625,\n",
       " -0.005290985107421875,\n",
       " -1.41796875,\n",
       " 2.255859375,\n",
       " -0.1728515625,\n",
       " 0.36376953125,\n",
       " 1.248046875,\n",
       " 0.018402099609375,\n",
       " 2.205078125,\n",
       " 0.421875,\n",
       " 1.376953125,\n",
       " 2.33203125,\n",
       " 2.572265625,\n",
       " -1.17578125,\n",
       " 2.984375,\n",
       " 1.3525390625,\n",
       " -3.12890625,\n",
       " 2.6796875,\n",
       " 1.490234375,\n",
       " -1.17578125,\n",
       " 1.837890625,\n",
       " -2.572265625,\n",
       " -1.3203125,\n",
       " 1.47265625,\n",
       " 0.197509765625,\n",
       " -2.001953125,\n",
       " -3.4140625,\n",
       " 3.400390625,\n",
       " 0.486328125,\n",
       " -0.195556640625,\n",
       " -4.90234375,\n",
       " 2.060546875,\n",
       " 1.01171875,\n",
       " -3.974609375,\n",
       " 1.2109375,\n",
       " 1.6005859375,\n",
       " 0.277099609375,\n",
       " -2.107421875,\n",
       " 0.263671875,\n",
       " 3.025390625,\n",
       " 0.129150390625,\n",
       " -0.304443359375,\n",
       " -2.521484375,\n",
       " -0.73974609375,\n",
       " -0.8671875,\n",
       " -4.65625,\n",
       " -1.5693359375,\n",
       " 0.95751953125,\n",
       " 2.234375,\n",
       " -1.84765625,\n",
       " -1.78125,\n",
       " -1.6103515625,\n",
       " -0.6796875,\n",
       " 0.1395263671875,\n",
       " -0.32958984375,\n",
       " -1.1748046875,\n",
       " -1.5205078125,\n",
       " 3.0546875,\n",
       " -2.439453125,\n",
       " 2.552734375,\n",
       " 0.47265625,\n",
       " -1.4169921875,\n",
       " 3.48828125,\n",
       " -1.7841796875,\n",
       " -0.1270751953125,\n",
       " 0.8603515625,\n",
       " 0.0548095703125,\n",
       " 0.38427734375,\n",
       " 1.6669921875,\n",
       " -0.5791015625,\n",
       " 1.7529296875,\n",
       " -0.434326171875,\n",
       " 2.0703125,\n",
       " -0.126953125,\n",
       " 2.193359375,\n",
       " -3.111328125,\n",
       " 2.80859375,\n",
       " -2.974609375,\n",
       " 1.0185546875,\n",
       " 0.58642578125,\n",
       " 1.6708984375,\n",
       " -2.01171875,\n",
       " -0.90625,\n",
       " -2.166015625,\n",
       " -4.4609375,\n",
       " -1.38671875,\n",
       " -0.99658203125,\n",
       " 0.91162109375,\n",
       " -3.294921875,\n",
       " 2.681640625,\n",
       " 5.87109375,\n",
       " 2.451171875,\n",
       " -9.2890625,\n",
       " -2.029296875,\n",
       " 1.013671875,\n",
       " 0.8193359375,\n",
       " 0.258544921875,\n",
       " -1.177734375,\n",
       " -1.01171875,\n",
       " -0.07049560546875,\n",
       " 2.814453125,\n",
       " 1.830078125,\n",
       " -0.3173828125,\n",
       " 0.485595703125,\n",
       " -0.73388671875,\n",
       " 3.734375,\n",
       " -3.05859375,\n",
       " 3.94921875,\n",
       " 0.740234375,\n",
       " 1.3310546875,\n",
       " -1.212890625,\n",
       " -1.9775390625,\n",
       " 0.437255859375,\n",
       " 1.6298828125,\n",
       " -0.330810546875,\n",
       " 1.568359375,\n",
       " 0.68994140625,\n",
       " 0.1087646484375,\n",
       " 1.0654296875,\n",
       " -2.36328125,\n",
       " 2.431640625,\n",
       " -1.2890625,\n",
       " 2.052734375,\n",
       " -0.58935546875,\n",
       " 0.4375,\n",
       " -1.109375,\n",
       " -1.4677734375,\n",
       " -2.294921875,\n",
       " 0.2213134765625,\n",
       " -3.091796875,\n",
       " 3.53515625,\n",
       " -1.728515625,\n",
       " -0.90771484375,\n",
       " 0.68798828125,\n",
       " 0.07720947265625,\n",
       " -0.9033203125,\n",
       " 0.457763671875,\n",
       " -1.744140625,\n",
       " -2.48046875,\n",
       " 2.9609375,\n",
       " 0.84130859375,\n",
       " -1.7734375,\n",
       " -1.42578125,\n",
       " -1.4892578125,\n",
       " -3.904296875,\n",
       " 1.83984375,\n",
       " -4.109375,\n",
       " 0.33642578125,\n",
       " 2.259765625,\n",
       " -0.0711669921875,\n",
       " -0.5791015625,\n",
       " -3.908203125,\n",
       " 2.20703125,\n",
       " -2.0703125,\n",
       " -2.837890625,\n",
       " 1.416015625,\n",
       " 1.376953125,\n",
       " 0.394775390625,\n",
       " 0.209228515625,\n",
       " 10.5625,\n",
       " -0.81494140625,\n",
       " 1.76953125,\n",
       " 2.146484375,\n",
       " -3.873046875,\n",
       " -1.6357421875,\n",
       " -2.494140625,\n",
       " -0.138671875,\n",
       " -2.158203125,\n",
       " 0.8818359375,\n",
       " -0.67236328125,\n",
       " 0.50341796875,\n",
       " 2.046875,\n",
       " -3.453125,\n",
       " -1.73046875,\n",
       " 3.537109375,\n",
       " 0.59619140625,\n",
       " -0.278076171875,\n",
       " -3.037109375,\n",
       " 3.421875,\n",
       " -1.4697265625,\n",
       " -3.634765625,\n",
       " -3.3828125,\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
